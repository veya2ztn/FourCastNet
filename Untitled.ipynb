{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "953d10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "366df484",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn(3)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fade0e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0084, -0.0062, -0.0009,  0.0000,  0.0009,  0.0062,  0.0084])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.cat([-torch.flip(weight,(0,)),F.pad(weight,(1,0))])\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1f69c07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0112, -0.0137, -0.0133,  0.0000,  0.0133,  0.0137,  0.0112])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0477ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"SH-IDC1-10-140-0-[151,170],SH-IDC1-10-140-0-[3,SH-IDC1-10-14,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94dd5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = string.split(',')\n",
    "string_list_new = []\n",
    "i = 0\n",
    "while i < len(string_list):\n",
    "    string_now = string_list[i]\n",
    "    if ('[' in string_now) and ((i+1)<len(string_list)) and (']' in string_list[i+1]):\n",
    "        ip_first,ip_last = string_now.split('[')\n",
    "        string_list_new.append(f\"{ip_first}{ip_last}\")\n",
    "        string_next = string_list[i+1]\n",
    "        string_list_new.append(f\"{ip_first}{string_next.split(']')[0]}\")\n",
    "        i+=2\n",
    "    else:\n",
    "        string_list_new.append(string_now)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b582fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SH-IDC1-10-140-0-151',\n",
       " 'SH-IDC1-10-140-0-170',\n",
       " 'SH-IDC1-10-140-0-[3',\n",
       " 'SH-IDC1-10-14',\n",
       " '']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d87cf7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151,170],SH-IDC1-10-140-0-[3,SH-IDC1-10-14,\n",
      "18\n",
      "SH-IDC1-10-140-0-[151.170].SH-IDC1-10-140-0-[3.SH-IDC1-10-14.\n"
     ]
    }
   ],
   "source": [
    "string = \"SH-IDC1-10-140-0-[151,170],SH-IDC1-10-140-0-[3,SH-IDC1-10-14,\"\n",
    "ip_tuple = r.findall(string)\n",
    "string = string\n",
    "for ip_flag in ip_tuple:\n",
    "    print(ip_flag)\n",
    "    print(string.index(ip_flag))\n",
    "    string = string.replace(ip_flag,ip_flag.replace(\",\",'.'))\n",
    "print(string)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15c2e3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IDC1-10-14,SH-IDC1-10-140-0']\n"
     ]
    }
   ],
   "source": [
    "ip_list=[]\n",
    "first_ip_list = re.findall(r'(SH-.*?)-\\[', string)\n",
    "for first_ip in first_ip_list:\n",
    "    pattern = f\"{first_ip}-\\[(.*?)\\]\"\n",
    "    last_ip_list = (re.findall(pattern, string))[0].split(',')\n",
    "    for last_ip in last_ip_list:\n",
    "        ip_list.append(f\"{first_ip}-{last_ip}\")\n",
    "for ip in string.split(','):\n",
    "    if '[' in ip:continue\n",
    "    if ']' in ip:continue\n",
    "    ip_list.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e6891d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SH-IDC1-10-14,SH-IDC1-10-140-0-151',\n",
       " 'SH-IDC1-10-14,SH-IDC1-10-140-0-170',\n",
       " 'SH-IDC1-10-14']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e8ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f430c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69ce99f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CplxAdaptiveModReLU(nn.Module):\n",
    "    r\"\"\"Applies soft thresholding to the complex modulus:\n",
    "    $$\n",
    "        F\n",
    "        \\colon \\mathbb{C}^d \\to \\mathbb{C}^d\n",
    "        \\colon z \\mapsto (\\lvert z_j \\rvert - \\tau_j)_+\n",
    "                        \\tfrac{z_j}{\\lvert z_j \\rvert}\n",
    "        \\,, $$\n",
    "    with $\\tau_j \\in \\mathbb{R}$ being the $j$-th learnable threshold. Torch's\n",
    "    broadcasting rules apply and the passed dimensions must conform with the\n",
    "    upstream input. `CplxChanneledModReLU(1)` learns a common threshold for all\n",
    "    features of the $d$-dim complex vector, and `CplxChanneledModReLU(d)` lets\n",
    "    each dimension have its own threshold.\n",
    "    \"\"\"\n",
    "    def __init__(self, *dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim if dim else (1,)\n",
    "        self.threshold = torch.nn.Parameter(torch.randn(*self.dim) * 0.02)\n",
    "\n",
    "    def forward(self, input):\n",
    "        modulus = torch.clamp(abs(input), min=1e-5)\n",
    "        return input * torch.relu(1. - self.threshold / modulus)\n",
    "        \n",
    "\n",
    "    def __repr__(self):\n",
    "        body = repr(self.dim)[1:-1] if len(self.dim) > 1 else repr(self.dim[0])\n",
    "        return f\"{self.__class__.__name__}({body})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd75f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,2,3,dtype=torch.cfloat\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d28408",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = CplxAdaptiveModReLU(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "088ca34f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [3], line 22\u001b[0m, in \u001b[0;36mCplxAdaptiveModReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     21\u001b[0m     modulus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28minput\u001b[39m), \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodulus\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "layer(a).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
