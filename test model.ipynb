{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "317f6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74121e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.Embedding(32*64, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77a9e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.LongTensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7515c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55f6031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 25])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fec282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import PatchOverLapWrapper\n",
    "from model.afnonet import AFNONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb398673",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "W = 8\n",
    "H = 16\n",
    "P = 2\n",
    "PS= 5\n",
    "x = torch.arange(B*W*H*P*PS*PS).reshape(B,W,H,P,PS,PS).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5fd46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import AutoPatchModel2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15585146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoPatchModel2D((12,16),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b07d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.arange(12*16).reshape(1,1,12,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbe6f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.image_to_patches(y)\n",
    "x = x.reshape(1,8,16,1,\n",
    "              5,5)\n",
    "x=torch.nn.functional.pad(x,(0,0,0,0,0,0,0,0,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcf8d067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 16, 1, 5, 5])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff752ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W= 8\n",
    "H=16\n",
    "L= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55a07840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11ff25e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 5, 12, 16])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5fed7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "L =  W+4\n",
    "w_idx = np.arange(0,L)\n",
    "wes   = np.stack([w_idx, w_idx+1,w_idx+2, w_idx-1, w_idx-2],1)%L\n",
    "yes = np.array([[2,  1,  0,  3,  4]])\n",
    "x_idx = np.arange(H)\n",
    "xes = np.stack([x_idx, x_idx+1,x_idx+2, x_idx-1, x_idx-2],1)%H\n",
    "line  = x[:, wes, :,:,yes,:].sum(1) #(4,B, H, P, PS)\n",
    "line  = line[:, :, xes,:,yes].sum(1)#(H,B,P)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f0caf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_matrix = torch.ones(L,H)\n",
    "counting_matrix[0]*=5\n",
    "counting_matrix[1]*=10\n",
    "counting_matrix[2]*=15\n",
    "counting_matrix[3]*=20\n",
    "counting_matrix[4:W]*=25\n",
    "counting_matrix[W]*=20\n",
    "counting_matrix[W+1]*=15\n",
    "counting_matrix[W+2]*=10\n",
    "counting_matrix[W+3]*=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca7ae001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15]\n",
      " [ 16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31]\n",
      " [ 32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47]\n",
      " [ 48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63]\n",
      " [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79]\n",
      " [ 80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95]\n",
      " [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111]\n",
      " [112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      " [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143]\n",
      " [144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]\n",
      " [160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175]\n",
      " [176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191]]\n"
     ]
    }
   ],
   "source": [
    "print(y[0,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "833c831c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15]\n",
      " [ 16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31]\n",
      " [ 32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47]\n",
      " [ 48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63]\n",
      " [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79]\n",
      " [ 80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95]\n",
      " [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111]\n",
      " [112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      " [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143]\n",
      " [144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]\n",
      " [160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175]\n",
      " [176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(line.permute(2,3,1,0)[0,0]/counting_matrix).astype('uint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35a7ecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125440"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*64*70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c25a422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143360"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*64*70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90d3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = ViTDirect((32,64),2,70,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5469e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:pass\n",
    "args = Config()\n",
    "args.img_size=(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efcb1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AFNONet((5,5),1,2,2)\n",
    "model = PatchOverLapWrapper(args,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36716e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc086d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,W,H,P = self.input_shape_tmp\n",
    "# (28, 32)\n",
    "x = x.reshape(B,W,H,P,self.patch_range,self.patch_range)\n",
    "assert self.patch_range==5\n",
    "assert not self.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c7246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d62d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40935eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e4a80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.vit import repeat,pair,Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a49547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,2,16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8569ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 16, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.ra\n",
    "model(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e17c4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(32,64)\n",
    "patch_size=(2,2)\n",
    "channels  =70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "550a48fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0111e-06)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(a, model.patches_to_image(model.image_to_patches(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57d35652",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height, image_width = pair(image_size)\n",
    "patch_height, patch_width = pair(patch_size)\n",
    "num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "patch_dim   = channels * patch_height * patch_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61cf313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b87d60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 280])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fde186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a1525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cephdataset import WeathBench7066PatchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4aee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use dataset in datasets/weatherbench_6hour\n",
      "load data from datasets/weatherbench_6hour/test.npy\n"
     ]
    }
   ],
   "source": [
    "test_dataset = WeathBench7066PatchDataset(split='test',dataset_flag='2D70N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c00fbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.vnames.index('500hPa_geopotential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f98b4fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.vnames.index('850hPa_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56e6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcastresult =torch.load(\"checkpoints/WeathBench7066PatchDataset/PatchWrapper-AFNONet/time_step_2_pretrain-2D70N_every_1_step_random_dataset/test/fourcastresult.gpu_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e919fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 513, 768])\n",
      "torch.Size([1, 513, 768])\n",
      "torch.Size([1, 513, 768])\n",
      "torch.Size([1, 513, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(1,70,32,64)\n",
    "x = model.backbone.to_patch_embedding(img);print(x.shape)\n",
    "b, n, _ = x.shape\n",
    "\n",
    "cls_tokens = repeat(model.backbone.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "x = torch.cat((cls_tokens, x), dim=1);print(x.shape)\n",
    "x += model.backbone.pos_embedding[:, :(n + 1)];print(x.shape)\n",
    "x = model.backbone.dropout(x);print(x.shape)\n",
    "\n",
    "x = model.backbone.transformer(x);print(x.shape)\n",
    "\n",
    "x = x.mean(dim = 1) if model.backbone.pool == 'mean' else x[:, 0];print(x.shape)\n",
    "\n",
    "x = model.backbone.to_latent(x);print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da9e4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e8b7fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, -1, 32, 64]' is invalid for input of size 70",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/afnonet.py:507\u001b[0m, in \u001b[0;36mViTDirect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    505\u001b[0m     ot_shape\u001b[38;5;241m=\u001b[39mot_shape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m#timer.record('head',level=0)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mot_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,pad:\u001b[38;5;241m-\u001b[39mpad,:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, -1, 32, 64]' is invalid for input of size 70"
     ]
    }
   ],
   "source": [
    "model(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc61b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2fadd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0944)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa16fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_names = test_dataset.vnames\n",
    "accu_list = torch.stack([p['accu'] for p in fourcastresult.values() if 'accu' in p]).numpy()\n",
    "total_num = len(accu_list)\n",
    "accu_list = accu_list.mean(0)# (fourcast_num,property_num)\n",
    "real_times = [(predict_time+1)*test_dataset.time_intervel*test_dataset.time_unit for predict_time in range(len(accu_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffa91ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_tables=[]\n",
    "snap_index = fourcastresult['snap_index']\n",
    "select_snap_start_time_point = snap_index[0]\n",
    "select_snap_show_property_id = snap_index[1]\n",
    "select_snap_property_name    = [property_names[iidd] for iidd in select_snap_show_property_id]\n",
    "for select_time_point in select_snap_start_time_point:\n",
    "    timestamp = test_dataset.datatimelist_pool['test'][select_time_point]\n",
    "    if select_time_point in fourcastresult: # in case do not record\n",
    "        linedata = fourcastresult[select_time_point]['snap_line']\n",
    "        for predict_time_point, tensor, label in linedata:\n",
    "            for name, value in zip(select_snap_property_name,tensor):\n",
    "                predict_timestamp = 0 if predict_time_point==0 else real_times[predict_time_point-1]\n",
    "                snap_tables.append([timestamp, name, predict_timestamp, value.item(), label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80baabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_rmse_map = fourcastresult['global_rmse_map']\n",
    "mean_global_rmse_map = [t/total_num for t in global_rmse_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbcbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb,os\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a55e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f\"szztn951357/WeathBench7066PatchDataset/runs/90618f2abf217a23937cf86ab5ae9c08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d213d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nvme/zhangtianning/projects_local/FourCastNet/wandb/run-20221122_132237-90618f2abf217a23937cf86ab5ae9c084</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://10.140.0.184:8080/szztn951357/WeathBench7066PatchDataset/runs/90618f2abf217a23937cf86ab5ae9c084\" target=\"_blank\">90618f2abf217a23937cf86ab5ae9c084</a></strong> to <a href=\"http://10.140.0.184:8080/szztn951357/WeathBench7066PatchDataset\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"http://10.140.0.184:8080/szztn951357/WeathBench7066PatchDataset/runs/90618f2abf217a23937cf86ab5ae9c084?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc9e4b9ec40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(entity='szztn951357',project='WeathBench7066PatchDataset', id=\"90618f2abf217a23937cf86ab5ae9c084\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f36f9934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 5, 2],\n",
       "       [0, 1, 2, 5, 2],\n",
       "       [0, 1, 2, 5, 2],\n",
       "       [0, 1, 2, 5, 2],\n",
       "       [0, 1, 2, 5, 2],\n",
       "       [1, 2, 3, 0, 3],\n",
       "       [1, 2, 3, 0, 3],\n",
       "       [1, 2, 3, 0, 3],\n",
       "       [1, 2, 3, 0, 3],\n",
       "       [1, 2, 3, 0, 3],\n",
       "       [2, 3, 4, 1, 4],\n",
       "       [2, 3, 4, 1, 4],\n",
       "       [2, 3, 4, 1, 4],\n",
       "       [2, 3, 4, 1, 4],\n",
       "       [2, 3, 4, 1, 4],\n",
       "       [3, 4, 5, 2, 5],\n",
       "       [3, 4, 5, 2, 5],\n",
       "       [3, 4, 5, 2, 5],\n",
       "       [3, 4, 5, 2, 5],\n",
       "       [3, 4, 5, 2, 5],\n",
       "       [4, 5, 0, 3, 0],\n",
       "       [4, 5, 0, 3, 0],\n",
       "       [4, 5, 0, 3, 0],\n",
       "       [4, 5, 0, 3, 0],\n",
       "       [4, 5, 0, 3, 0],\n",
       "       [5, 0, 1, 4, 1],\n",
       "       [5, 0, 1, 4, 1],\n",
       "       [5, 0, 1, 4, 1],\n",
       "       [5, 0, 1, 4, 1],\n",
       "       [5, 0, 1, 4, 1]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a41c21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,prop_name in enumerate(property_names): \n",
    "    if prop_name in ['500hPa_geopotential','850hPa_temperature']:\n",
    "        for i in range(4):\n",
    "            images = wandb.Image(mean_global_rmse_map[i][...,j], caption='rmse_map')\n",
    "            wandb.log({f\"rmse_map_of_{prop_name}\": images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "214e7465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 5, 4],\n",
       "       [1, 2, 3, 0, 5],\n",
       "       [2, 3, 4, 1, 0],\n",
       "       [3, 4, 5, 2, 1],\n",
       "       [4, 5, 0, 3, 2],\n",
       "       [5, 0, 1, 4, 3]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d5833bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "    \n",
    "def save_plot_and_get():\n",
    "    \n",
    "    return PIL.Image.fromarray(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb1636e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fcdfee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 2, 6,10,28,24) ( 7,11,15, 3,29) (12,16,20, 8, 4) (17,21,25,13, 9) (22,26, 0,18,14) (27, 1, 5,23,19) \n"
     ]
    }
   ],
   "source": [
    "fun(topvalues[xes,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c99500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "895e40b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data>0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0268f155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig= plt.figure()\n",
    "plt.imshow(torch.nn.functional.pad(mean_global_rmse_map[2][...,69],(0,0,6,6),'constant',100),vmin=0,vmax=0.05,cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "fig.savefig(\"debug/test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06105dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAAAUCAAAAAAYHWTjAAAEzklEQVR4nAXBCTSVeRgH4N/7FXJlV5YolDtajMK0+DpkbioUUU1UxnIjJeRoJRNlWkw4J8PQLUSmgyzJLpGtMEoJExNJc2RLiijMf54HtjUr+KWjpnyqjykfbDRtbpPxxdxtwJDX3Z7E87al/Je7z/nd77N4XcM4PtlAk7ccSTS3qvbjO2Mk/MqYRzyn5e+KT86jkO3OY7oeqsQpLKTqXBO8zu2CdbkM3ALmAn8KEGqhA9uyQIiDJyjot/Uw5+ug9GoC3D/aa7FRrhOp5Ru5FEkXbi2bon8dx8n5thnZH2kmkaMf5SaoYo30EvS8H8D15M/gxSvYl8ZbeFpgB64xRp8Z2dazJ4YyzJAPRrVrHPNoj2WCfAc2eSOG1X94zUYtDmKfRx7IKwVO5wlfPV3ox71B6O+dYVxnqQ5dSLHi0sSV4IUBkOjZ4GyFJna+bofkmTY9HpqiyoVSVJakRffd3OnO1lfU+HSc3rXlkUHYco4bSkuGHZ/O0rouwzu0AO25vcho+44UjV2ooVWEm5Lt8N6wF7EYxmRnBaLMxnDVwx1BMuewK0gA7qT/GRKnRFFidwPVbSqneMtikr9/D4rHw7GpXwnt0dbgSnUgVBnAjik5/PHNj7mlybP89jzm/QvPuFcRwOF9S7Ft8Wr8utgYn1r6EdWYg+zaS+jv+ZmpfPbEI4VDSD70EuP13Tjn40qaK71QKBcNqTkNxEnFj+BeRzZ+Wj4E5Ulz5O40QYhWDyYOWEFqczzNXguFyDcVF2W6qcnTnPp6tCk2S8hNXFUhhcOu4M77BuN0QjjCa6rgsT8KzyM/os1DBGnxAWhke2FowznqHwujY9PDKDl1l71cf5PZaxYzjZFZ+CgFEKeumo0iy3qo3TyJJvME3JkMgK+tDzkJ1cDtUURtxjR8+SFIlc1AnJaBooQ9qHM2YaZhYFslWowTXhbCOcISR35XRFibMY7UK1CgZx+z13gAb0EQlhifZgbRjmzR2Fk26NyPWXsxFgykUZW6CQmrR8E1VTggd7smovu2wP04R7tXL0LVZhE9PBRPdWs66Y1bCb1XbyFx5hS9if2e8uIElO46Rn8nO9KqSXfi5ORbSN/0BDlVZ+GYSwSzNg5nw6ZRrLKlmH3NfIzTMyaYn+QA7ao5MNuYDF2bAtRdOQYZURUijdpAKYmpHqPFMrv+Sndbs+qGgerKVrnJxBDB22GDbxNZlkYDBXp7Xw7ufPtuQatAQfQi3dpJhSSL/Z/c7ZC+cj1JaDfGbdG7hsIxeQzGGmF9uQ62HFfGhfkdWN5ZDaXaBNZxyYY9HLdlHqMZTDNQltoq3OgH96NwPaMOcY0ZOFFwBPRnptBaXMhuyzXAYbILU7XmEPMXYNSbTMFqNXQ/8yktCqmmIKsSSHMPoG71kCz6P5Jssz5xak455HVtHz03kUf8zBuWM/MCykUX2a4dcYg82Az/y/PwttcAbOk0vA1rkBMZAo20Ewj1y0RLfCG4vtRAbFObxo5LgWRX6UL+FtZYd3UTrcoSQM+/FQE2NWgqvIfdZiXYkF+KmsEZSIa+4VTldfZhbSa4owcUsOzZKIqalaE6uw698lowmCeN/Vn/QaF0HFKSTHb7TCKzci5Dqew7WETNhWzzR+TnaVGJ8wj7H1hYD6ZBC+ERAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x20>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(data.numpy(), mode=\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0c1aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd93816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f1bf976",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(4,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "20c21145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e664a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "row=[1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2bef85c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[14, 15,  0,  1,  2],\n",
       "          [30, 31, 16, 17, 18],\n",
       "          [46, 47, 32, 33, 34],\n",
       "          [62, 63, 48, 49, 50],\n",
       "          [78, 79, 64, 65, 66]],\n",
       "\n",
       "         [[15,  0,  1,  2,  3],\n",
       "          [31, 16, 17, 18, 19],\n",
       "          [47, 32, 33, 34, 35],\n",
       "          [63, 48, 49, 50, 51],\n",
       "          [79, 64, 65, 66, 67]],\n",
       "\n",
       "         [[ 0,  1,  2,  3,  4],\n",
       "          [16, 17, 18, 19, 20],\n",
       "          [32, 33, 34, 35, 36],\n",
       "          [48, 49, 50, 51, 52],\n",
       "          [64, 65, 66, 67, 68]],\n",
       "\n",
       "         [[ 1,  2,  3,  4,  5],\n",
       "          [17, 18, 19, 20, 21],\n",
       "          [33, 34, 35, 36, 37],\n",
       "          [49, 50, 51, 52, 53],\n",
       "          [65, 66, 67, 68, 69]],\n",
       "\n",
       "         [[ 2,  3,  4,  5,  6],\n",
       "          [18, 19, 20, 21, 22],\n",
       "          [34, 35, 36, 37, 38],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [66, 67, 68, 69, 70]],\n",
       "\n",
       "         [[ 3,  4,  5,  6,  7],\n",
       "          [19, 20, 21, 22, 23],\n",
       "          [35, 36, 37, 38, 39],\n",
       "          [51, 52, 53, 54, 55],\n",
       "          [67, 68, 69, 70, 71]],\n",
       "\n",
       "         [[ 4,  5,  6,  7,  8],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [36, 37, 38, 39, 40],\n",
       "          [52, 53, 54, 55, 56],\n",
       "          [68, 69, 70, 71, 72]],\n",
       "\n",
       "         [[ 5,  6,  7,  8,  9],\n",
       "          [21, 22, 23, 24, 25],\n",
       "          [37, 38, 39, 40, 41],\n",
       "          [53, 54, 55, 56, 57],\n",
       "          [69, 70, 71, 72, 73]],\n",
       "\n",
       "         [[ 6,  7,  8,  9, 10],\n",
       "          [22, 23, 24, 25, 26],\n",
       "          [38, 39, 40, 41, 42],\n",
       "          [54, 55, 56, 57, 58],\n",
       "          [70, 71, 72, 73, 74]],\n",
       "\n",
       "         [[ 7,  8,  9, 10, 11],\n",
       "          [23, 24, 25, 26, 27],\n",
       "          [39, 40, 41, 42, 43],\n",
       "          [55, 56, 57, 58, 59],\n",
       "          [71, 72, 73, 74, 75]],\n",
       "\n",
       "         [[ 8,  9, 10, 11, 12],\n",
       "          [24, 25, 26, 27, 28],\n",
       "          [40, 41, 42, 43, 44],\n",
       "          [56, 57, 58, 59, 60],\n",
       "          [72, 73, 74, 75, 76]],\n",
       "\n",
       "         [[ 9, 10, 11, 12, 13],\n",
       "          [25, 26, 27, 28, 29],\n",
       "          [41, 42, 43, 44, 45],\n",
       "          [57, 58, 59, 60, 61],\n",
       "          [73, 74, 75, 76, 77]],\n",
       "\n",
       "         [[10, 11, 12, 13, 14],\n",
       "          [26, 27, 28, 29, 30],\n",
       "          [42, 43, 44, 45, 46],\n",
       "          [58, 59, 60, 61, 62],\n",
       "          [74, 75, 76, 77, 78]],\n",
       "\n",
       "         [[11, 12, 13, 14, 15],\n",
       "          [27, 28, 29, 30, 31],\n",
       "          [43, 44, 45, 46, 47],\n",
       "          [59, 60, 61, 62, 63],\n",
       "          [75, 76, 77, 78, 79]],\n",
       "\n",
       "         [[12, 13, 14, 15,  0],\n",
       "          [28, 29, 30, 31, 16],\n",
       "          [44, 45, 46, 47, 32],\n",
       "          [60, 61, 62, 63, 48],\n",
       "          [76, 77, 78, 79, 64]],\n",
       "\n",
       "         [[13, 14, 15,  0,  1],\n",
       "          [29, 30, 31, 16, 17],\n",
       "          [45, 46, 47, 32, 33],\n",
       "          [61, 62, 63, 48, 49],\n",
       "          [77, 78, 79, 64, 65]]]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "71e2c507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0, xes,:, 0 ,yes][:,:,0,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a0203d29",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [213], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#print(line.shape)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mlines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(line)\n\u001b[1;32m     25\u001b[0m lines \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(lines,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for line_id in range(W+4): #(0 --> 32)\n",
    "    line = 0\n",
    "    end = W + 4 \n",
    "    if line_id < 4:\n",
    "        for w_id in range(line_id+1):\n",
    "             line += x[:, w_id, xes,:, line_id - w_id,yes].mean(1) #(H,B,P)\n",
    "        line = line/(line_id + 1)\n",
    "        line = line.permute(1,2,0).unsqueeze(2)#(B,P,1,H)      \n",
    "    elif line_id > end - 5:\n",
    "        for w_id in range(line_id - end, 0): #(-3,-2,-1)\n",
    "             line += x[:, w_id, xes,:, line_id - end -1 - w_id,yes].mean(1)#(H,B,P)       \n",
    "        line = line/(line_id + 1)\n",
    "        line = line.permute(1,2,0).unsqueeze(2)#(B,P,1,H)       \n",
    "    elif line_id == 4:\n",
    "        w_idx = np.arange(2,W-2)\n",
    "        wes = np.stack([w_idx, w_idx+1,w_idx+2, w_idx-1, w_idx-2],1)\n",
    "        line = x[:, wes, :,:,yes,:].mean(1) #(4,B, H, P, PS)\n",
    "        line = line[:, :, xes,:,yes].mean(1)#(H,B,P)   \n",
    "        line = line.permute(2,3,1,0)\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "    #print(line.shape)\n",
    "    lines.append(line)\n",
    "lines = torch.cat(lines,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59126614",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = [[a]+b for a,b in zip(row,data.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "713b56b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526984</td>\n",
       "      <td>1.086613</td>\n",
       "      <td>0.280312</td>\n",
       "      <td>1.276958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.080938</td>\n",
       "      <td>1.288048</td>\n",
       "      <td>-0.756077</td>\n",
       "      <td>-0.718399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.578288</td>\n",
       "      <td>1.196766</td>\n",
       "      <td>1.102878</td>\n",
       "      <td>-1.011106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.522461</td>\n",
       "      <td>2.823155</td>\n",
       "      <td>-0.121596</td>\n",
       "      <td>0.030755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.417626</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>-0.786947</td>\n",
       "      <td>0.058597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.040354</td>\n",
       "      <td>0.943858</td>\n",
       "      <td>0.542913</td>\n",
       "      <td>-0.460681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.934706</td>\n",
       "      <td>-0.597524</td>\n",
       "      <td>-0.114265</td>\n",
       "      <td>-1.087731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2.499614</td>\n",
       "      <td>-0.834295</td>\n",
       "      <td>-0.476234</td>\n",
       "      <td>-1.855398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.403065</td>\n",
       "      <td>-0.112838</td>\n",
       "      <td>-1.018460</td>\n",
       "      <td>-1.453632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.586300</td>\n",
       "      <td>-2.146419</td>\n",
       "      <td>0.981555</td>\n",
       "      <td>0.463776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4\n",
       "0   0.526984  1.086613  0.280312  1.276958\n",
       "1   1.080938  1.288048 -0.756077 -0.718399\n",
       "2  -0.578288  1.196766  1.102878 -1.011106\n",
       "3  -0.522461  2.823155 -0.121596  0.030755\n",
       "4   1.417626  0.034181 -0.786947  0.058597\n",
       "..       ...       ...       ...       ...\n",
       "65  0.040354  0.943858  0.542913 -0.460681\n",
       "66  0.934706 -0.597524 -0.114265 -1.087731\n",
       "67  2.499614 -0.834295 -0.476234 -1.855398\n",
       "68 -1.403065 -0.112838 -1.018460 -1.453632\n",
       "69 -0.586300 -2.146419  0.981555  0.463776\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data.transpose(1,0),index=range(70), columns=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b7a7c",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9236442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting empatches\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b4/54/0d423c2f766065bb664fc6cbbee5b73d4d2dedaf343cdac03b3abb622655/empatches-0.2.0.tar.gz (6.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages (from empatches) (1.23.4)\n",
      "Building wheels for collected packages: empatches\n",
      "  Building wheel for empatches (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for empatches: filename=empatches-0.2.0-py3-none-any.whl size=6269 sha256=fc58791b6737f17ec69b3a8208f6e1d00ff6a79b5171ec096dfbf7e013f3836c\n",
      "  Stored in directory: /nas/zhangtianning/pip_cache_share/wheels/c2/6a/1e/91d71b757eeaa6ebc8ecb5713ab91afc000a99405b43c656a4\n",
      "Successfully built empatches\n",
      "Installing collected packages: empatches\n",
      "Successfully installed empatches-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install empatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "02ab525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from empatches import EMPatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6d7b23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = EMPatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4654095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_patches, indices = emp.extract_patches(img, patchsize=512, overlap=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8c6beb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 1, 2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "42a598a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "215c0e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 0, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(topvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8dde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    [i,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b84e136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ae1667b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "       16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,\n",
       "       33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
       "       50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1b252da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(23,70,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx  = np.array([1,2])\n",
    "proper_idx = np.array([3,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a797a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2563)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0][2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec87ad12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2563, -0.5150,  0.2888])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0][[2,3,4],[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f055b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.std(dim=(1,2,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "091b64e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [4]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "torch.gather(t, 1, torch.tensor([[0], [1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9651e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea540e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71032b86",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (709965286.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [64], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    a[*pos]\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a[*pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65329308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5308dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1500,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3e55a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.nbytes//8//1024//1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95c243be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61917ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.afnonet import AFNONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d33f0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec19a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.universal_model_util import get_model_para_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24e26396",
   "metadata": {
    "code_folding": [
     22
    ]
   },
   "outputs": [],
   "source": [
    "class LargeMLP_3D(nn.Module):\n",
    "    '''\n",
    "    input is (B, P, patch_range_1,patch_range_2,patch_range_3)\n",
    "    output is (B,P)\n",
    "    ''' \n",
    "    def __init__(self,img_size=None,patch_range=5,in_chans=20, out_chans=20,p=0.1,**kargs):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_range = 5\n",
    "        if self.patch_range == 5:\n",
    "            cl = [5*5*5*in_chans,5*5*5*10,5*5*5*20,\n",
    "                  5*5*5*30,5*5*5*30,5*5*5*20,\n",
    "                  5*5*5*10,5*5*5*1,out_chans]\n",
    "            nnlist = []\n",
    "            for i in range(len(cl)-2):\n",
    "                nnlist+=[nn.Linear(cl[i],cl[i+1]),nn.Dropout(p=p),nn.Tanh()]\n",
    "            nnlist+=[nn.Linear(cl[-2],cl[-1])]\n",
    "            self.backbone = nn.Sequential(*nnlist)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.center_index,self.around_index=get_center_around_indexes_3D(self.patch_range,self.img_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        The input either (B,P,patch_range,patch_range) or (B,P,w,h)\n",
    "        The output then is  (B,P) or (B,P,w-patch_range//2,h-patch_range//2)\n",
    "        ''' \n",
    "        assert len(x.shape) == 5 #(B,P,Z,W,H)\n",
    "        input_is_full_image = False\n",
    "        if x.shape[-3:] == self.img_size:\n",
    "            input_is_full_image = True\n",
    "            x = x[..., self.around_index[:, :, : , 0],self.around_index[:, :, : , 1],self.around_index[:, :, : , 2]] \n",
    "            # (B,P,Z-2,W-2,H,Patch,Patch,Patch)\n",
    "            x = x.permute(0, 2, 3, 4, 1, 5, 6, 7)\n",
    "            B, Z, W, H, P, _, _, _ = x.shape\n",
    "            x = x.flatten(0, 3)  # (B* Z-2 * W-2 * H, Property, Patch,Patch,Patch)\n",
    "        assert tuple(x.shape[-3:]) == (self.patch_range,self.patch_range,self.patch_range)\n",
    "        x = self.backbone(x.flatten(-4,-1)) # (B* W-4 * H,P)\n",
    "        if input_is_full_image:\n",
    "            x = x.reshape(B, Z, W, H, P).permute(0, 4, 1, 2,3) #(B, Z-2,W-2,H,P)  -> (B,P, Z-2,W-2,H)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f33c4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LargeMLP_3D((14,32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96424c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of Parameters: 42361395, Number of Buffers: 0, Size of Model: 161.5959 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.tools import getModelSize\n",
    "param_sum, buffer_sum, all_size = getModelSize(model)\n",
    "print(f\" Number of Parameters: {param_sum}, Number of Buffers: {buffer_sum}, Size of Model: {all_size:.4f} MB\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074816d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import NaiveConvModel2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad10412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a533b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveConvModel2D((32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35a1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,20,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653c093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import get_center_around_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389817cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape=(32,64)\n",
    "patch_range=5\n",
    "center_index,around_index=get_center_around_indexes(patch_range,img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38dad203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 64, 2, 5, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "around_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20928164",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_range=5\n",
    "delta = [list(range(-(patch_range//2),patch_range//2+1))]*2\n",
    "delta = np.meshgrid(*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92177012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "250fd2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00dc0f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4, 2, 3, 4, 2, 3, 4],\n",
       "       [2, 2, 2, 3, 3, 3, 4, 4, 4]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = [list(range(-(patch_range//2),patch_range//2+1))]*len(center)\n",
    "delta = np.meshgrid(*delta)\n",
    "pos  = [c+dc for c,dc in zip(center,delta)]\n",
    "pos[-1]= pos[-1]%64\n",
    "\n",
    "px = x + dx\n",
    "py = y + dy\n",
    "np.stack([px.flatten(),py.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "004d72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fbeda73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3  4  5]\n",
      "   [ 6  7  8  9 10 11]\n",
      "   [12 13 14 15 16 17]\n",
      "   [18 19 20 21 22 23]\n",
      "   [24 25 26 27 28 29]\n",
      "   [30 31 32 33 34 35]]]]\n"
     ]
    }
   ],
   "source": [
    "coordinate = np.arange(36).reshape(1,1,6,6)\n",
    "print(coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f245c1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2, 3, 3, 6)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinate[:,:,pos].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a71673fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[[14 20 26]\n",
      " [15 21 27]\n",
      " [16 22 28]]\n"
     ]
    }
   ],
   "source": [
    "print(coordinate[:,:,x,y][0,0])\n",
    "print(coordinate[:,:,pos[0],pos[1]][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c7465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.FEDformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66615d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19f42098",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class moving_avg_spacetime(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size)==3\n",
    "        self.kernel_size = np.array(kernel_size)\n",
    "        self.avg         = nn.AvgPool3d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "        self.pad_front   = self.kernel_size - 1-np.floor((self.kernel_size - 1) // 2)\n",
    "        self.pad_end     = np.floor((self.kernel_size - 1) // 2)\n",
    "        self.pad         = np.stack([self.pad_front,self.pad_end],1)[::-1].flatten().astype('int').tolist()\n",
    "        print(self.pad)\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        # the input must be (B,*Space,T,C)， the -1 dim is embed channel, the -2 dim is time channel\n",
    "        shape = x.shape\n",
    "        BSpace_shape = shape[:-2]\n",
    "        C = shape[-1]\n",
    "        permute_order = [0,-1] + list(range(1,len(shape)-1))\n",
    "        x = x.permute(*permute_order)#-->(B, *Space,T, C)-->(B, C, *Space,T)\n",
    "        x = self.avg(F.pad(x,self.pad, mode='replicate'))\n",
    "        permute_order = [0] + list(range(2,len(shape))) + [1]\n",
    "        x = x.permute(*permute_order)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2193e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "layer = moving_avg_spacetime((5,3,2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c937ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 6, 7])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(1,32,64,6,7)\n",
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548cafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.physics_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f35d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.afnonet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245af06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=get_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a877f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = AFNONet((32,64),2,265,20,depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081a6933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h intervel: 32 , w intervel: 64\n",
      "please notice we will using dt= 3600*1 as intertime\n"
     ]
    }
   ],
   "source": [
    "layer = DirectSpace_Feature_Model(args,backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995b4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.randn(1,4,5,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285eced2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5915, grad_fn=<StdMeanBackward0>),\n",
       " tensor(-0.0057, grad_fn=<StdMeanBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(layer(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "119b2ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 64])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = Second_Derivative_Layer()\n",
    "\n",
    "a=torch.randn(1,1,32,64)\n",
    "\n",
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "083c6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=2\n",
    "P=4\n",
    "a=torch.randn(B,P,3,32,64).cuda()\n",
    "layer=  First_Derivative_Layer(dim=3).cuda()\n",
    "runtime_weight=layer.runtime_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a49e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.8 µs ± 130 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.conv3d(a.flatten(0,1).unsqueeze(1),runtime_weight).reshape(*a.shape[:-1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe1a2493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.1 µs ± 1.63 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x2 = torch.conv1d(a.flatten(0,-2).unsqueeze(1),runtime_weight[0,0]).reshape(*a.shape[:-1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55db951f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7120e039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc62104ec40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.scatter(x,y)\n",
    "#plt.scatter([10],[10],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42446069",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_fourier_drive(x, position,pad):\n",
    "\n",
    "    if len(position)==1:position = position[0]\n",
    "    base_len          = np.array(x.shape[position])\n",
    "    interpolate_shape = base_len + (base_len-1)*pad\n",
    "    interpolate_shape = tuple(interpolate_shape)\n",
    "    if isinstance(position,int) or len(position) == 1\n",
    "        x = x.transpose(-1,position)\n",
    "        out_shape = x.shape[:-1]\n",
    "        x = x.reshape(x.size(0),-1,x.size(-1))\n",
    "        b = torch.nn.functional.interpolate(x,interpolate_shape,mode='linear',align_corners=True)\n",
    "        bf = torch.fft.rfft(b,dim=-1)\n",
    "        kbf= bf*torch.fft.rfftfreq(b.size(-1)).reshape(1,1,-1)\n",
    "        kb = torch.fft.irfft(kbf,dim=-1)\n",
    "        index = torch.arange(0,b.size(-1)+1,base_len-1)\n",
    "        kb = kb[...,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0209174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tkinter.messagebox import NO\n",
    "import numpy as np\n",
    "import torch,os,io,socket\n",
    "from torchvision import datasets, transforms\n",
    "hostname = socket.gethostname()\n",
    "from functools import lru_cache\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.timefeatures import time_features\n",
    "import os\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07efc1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatimelist  = np.arange(np.datetime64(\"1979-01-01\"), np.datetime64(\"2016-01-01\"), np.timedelta64(6, \"h\"))\n",
    "timestamp = time_features(pd.to_datetime(datatimelist)).transpose(1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d452ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(np.datetime64(\"1980-12-31\")).dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebb2999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(datatimelist)[0].dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6cc284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       , -0.5       ],\n",
       "       [-0.23913043, -0.5       ],\n",
       "       [ 0.02173913, -0.5       ],\n",
       "       [ 0.2826087 , -0.5       ],\n",
       "       [-0.5       , -0.49726027],\n",
       "       [-0.23913043, -0.49726027],\n",
       "       [ 0.02173913, -0.49726027],\n",
       "       [ 0.2826087 , -0.49726027],\n",
       "       [-0.5       , -0.49452055],\n",
       "       [-0.23913043, -0.49452055]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp[:10,[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b05b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JCmodels.fourcastnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb59fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AFNONet((32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443ac0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,4,5,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c828a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5, 32, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ae080",
   "metadata": {},
   "source": [
    "#### FEDformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55908ea1",
   "metadata": {},
   "source": [
    "#### complex version AdaptiveFourierNeuralOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331c5ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96f64f13",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def multiply(input, weights):\n",
    "    return torch.einsum('...bd,bdk->...bk', input, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "acaf839a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "B=1\n",
    "h=32;w=64;C=2\n",
    "num_blocks=1\n",
    "block_size=2\n",
    "\n",
    "w1 = torch.randn(num_blocks, block_size, block_size, dtype=torch.cfloat)\n",
    "b1 = torch.randn(num_blocks, block_size, dtype=torch.cfloat)\n",
    "w2 = torch.randn(num_blocks, block_size, block_size, dtype=torch.cfloat)\n",
    "b2 = torch.randn(num_blocks, block_size, dtype=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cbfa8d54",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def original_realize(x,w1,b1,w2,b2):\n",
    "    x = torch.fft.rfft2(x, dim=(1, 2), norm='ortho');\n",
    "    x = x.reshape(B, x.shape[1], x.shape[2], num_blocks, block_size)\n",
    "    x_real = F.relu(multiply(x.real, w1.real) - multiply(x.imag, w1.imag) + b1.real, inplace=True)\n",
    "    x_imag = F.relu(multiply(x.real, w1.imag) + multiply(x.imag, w1.real) + b1.imag, inplace=True)\n",
    "    x = torch.stack([x_real, x_imag], dim=-1)\n",
    "    x = torch.view_as_complex(x)\n",
    "    return x\n",
    "\n",
    "def complex_version_realize(x,w1,b1,w2,b2):\n",
    "    x = torch.fft.rfft2(x, dim=(1, 2), norm='ortho');\n",
    "    x = x.reshape(B, x.shape[1], x.shape[2], num_blocks, block_size)\n",
    "    x = multiply(x,w1)+b1\n",
    "    x = nonlinear_activate(x)\n",
    "    return x\n",
    "x  = torch.randn(B, h, w, C)\n",
    "y1 = original_realize(x,w1,b1,w2,b2)\n",
    "y2 = complex_version_realize(x,w1,b1,w2,b2)\n",
    "torch.dist(y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d2f8cb3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from model.afnonet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ccd53",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### AFNONet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "587d11df",
   "metadata": {
    "code_folding": [
     0,
     1,
     6,
     70,
     103,
     132,
     185,
     192,
     203,
     206,
     213,
     223,
     226,
     242
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PartReLU_Complex(nn.Module):\n",
    "    def forward(self,x):\n",
    "        F.relu(x.real, inplace=True)\n",
    "        F.relu(x.imag, inplace=True)\n",
    "        return x\n",
    "\n",
    "class AdaptiveFourierNeuralOperator(nn.Module):\n",
    "    def __init__(self, dim, img_size, fno_blocks=4,fno_bias=True, fno_softshrink=False,nonlinear_activate=PartReLU_Complex()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = dim\n",
    "        self.img_size   = img_size\n",
    "        self.num_blocks = fno_blocks\n",
    "        self.block_size = self.hidden_size // self.num_blocks\n",
    "        assert self.hidden_size % self.num_blocks == 0\n",
    "\n",
    "        self.scale = 0.02\n",
    "        self.w1 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              self.block_size, dtype=torch.cfloat))\n",
    "        self.b1 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              dtype=torch.cfloat))\n",
    "        self.w2 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              self.block_size, dtype=torch.cfloat))\n",
    "        self.b2 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              dtype=torch.cfloat))\n",
    "        self.relu = nonlinear_activate\n",
    "\n",
    "        if fno_bias:\n",
    "            self.bias = nn.Conv1d(self.hidden_size, self.hidden_size, 1)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.softshrink = fno_softshrink\n",
    "\n",
    "    def multiply(self, input, weights):\n",
    "        return torch.einsum('...bd,bdk->...bk', input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape    \n",
    "        bias = self.bias(x.permute(0, 2, 1)).permute(0, 2, 1) if self.bias else 0\n",
    "        #timer.restart(2)\n",
    "        x = x.reshape(B, *self.img_size, C)\n",
    "        fft_dim = tuple(range(1,len(self.img_size)+1))\n",
    "        print(fft_dim)\n",
    "        #timer.record('reshape1','filter',2)\n",
    "        print(x.shape)\n",
    "        x = torch.fft.rfftn(x, dim=fft_dim, norm='ortho');\n",
    "        #timer.record('rfft2','filter',2)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(*x.shape[:-1], self.num_blocks, self.block_size)\n",
    "        #timer.record('reshape2','filter',2)\n",
    "        x = self.multiply(x,self.w1)+self.b1\n",
    "        x = self.relu(x)\n",
    "        x = self.multiply(x,self.w2)+self.b2\n",
    "        x = F.softshrink(x, lambd=self.softshrink) if self.softshrink else x\n",
    "        #with torch.cuda.amp.autocast(enabled=False):\n",
    "        #x = x.float()   \n",
    "        #x = torch.view_as_complex(x)\n",
    "        #timer.record('reset','filter',2)\n",
    "        x = x.flatten(-2,-1)\n",
    "        #timer.record('reshape3','filter',2)\n",
    "        print(x.shape)\n",
    "        x = torch.fft.irfftn(x, s=self.img_size,dim=fft_dim, norm='ortho')\n",
    "        print(x.shape)\n",
    "        #x = x.half()\n",
    "        #timer.record('irfft2','filter',2)\n",
    "        x = x.reshape(B, N, C)\n",
    "        #timer.record('reshape4','filter',2)\n",
    "        return x + bias\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, mlp_ratio=4., drop=0., drop_path=0., act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm, region_shape=(14,8), fno_blocks=3,double_skip=False, fno_bias=False, fno_softshrink=False):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.filter = AdaptiveFourierNeuralOperator(dim, region_shape,fno_blocks=fno_blocks,fno_bias=fno_bias,fno_softshrink=fno_softshrink)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "        self.double_skip = double_skip\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        #timer.restart(1)\n",
    "        x = self.norm1(x)\n",
    "        #timer.record('norm1','forward_features',1)\n",
    "        x = self.filter(x)\n",
    "        #timer.record('filter','forward_features',1)\n",
    "        if self.double_skip:\n",
    "            x += residual\n",
    "            residual = x;\n",
    "        #timer.record('residual','forward_features',1)\n",
    "        x = self.norm2(x)\n",
    "        #timer.record('norm2','forward_features',1)\n",
    "        x = self.mlp(x)\n",
    "        #timer.record('mlp','forward_features',1)\n",
    "        x = self.drop_path(x)\n",
    "        #timer.record('drop_path','forward_features',1)\n",
    "        x += residual\n",
    "        #timer.record('residual','forward_features',1)\n",
    "        return x\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=None, patch_size=8, in_chans=13, embed_dim=768):\n",
    "        super().__init__()\n",
    "\n",
    "        if img_size is None:raise KeyError('img is None')\n",
    "        patch_size   = [patch_size]*len(img_size) if isinstance(patch_size,int) else patch_size\n",
    "        \n",
    "        num_patches=1\n",
    "        out_size=[]\n",
    "        for i_size,p_size in zip(img_size,patch_size):\n",
    "            if p_size%i_size:\n",
    "                num_patches*=i_size// p_size\n",
    "                out_size.append(i_size// p_size)\n",
    "            else:\n",
    "                raise NotImplementedError(f\"the patch size ({patch_size}) cannot divide the img size {img_size}\")\n",
    "        self.img_size    = tuple(img_size)\n",
    "        self.patch_size  = tuple(patch_size)\n",
    "        self.num_patches = num_patches\n",
    "        self.out_size    = tuple(out_size)\n",
    "        conv_engine = [nn.Conv1d,nn.Conv2d,nn.Conv3d]\n",
    "        self.proj   = conv_engine[len(img_size)-1](in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, = x.shape[:2]\n",
    "        inp_size = x.shape[2:]\n",
    "        assert tuple(inp_size) == self.img_size, f\"Input image size ({inp_size}) doesn't match model set size ({self.img_size}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class AFNONet(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, patch_size=8, in_chans=20, out_chans=20, embed_dim=768, depth=12, mlp_ratio=4.,\n",
    "                 uniform_drop=False, drop_rate=0., drop_path_rate=0., norm_layer=None,\n",
    "                 dropcls=0, checkpoint_activations=False, fno_blocks=3,double_skip=False,\n",
    "                 fno_bias=False, fno_softshrink=False,debug_mode=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert img_size is not None\n",
    "        self.checkpoint_activations=checkpoint_activations\n",
    "        self.embed_dim = embed_dim\n",
    "        norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
    "        self.img_size = img_size\n",
    "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches      = self.patch_embed.num_patches\n",
    "        patch_size       = self.patch_embed.patch_size\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        self.final_shape = self.patch_embed.out_size\n",
    "\n",
    "        if uniform_drop:\n",
    "            dpr = [drop_path_rate for _ in range(depth)]  # stochastic depth decay rule\n",
    "        else:\n",
    "            dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "\n",
    "        self.blocks = nn.ModuleList([Block(dim=embed_dim, mlp_ratio=mlp_ratio, drop=drop_rate,\n",
    "                                           drop_path=dpr[i], \n",
    "                                           norm_layer=norm_layer,\n",
    "                                           region_shape=self.final_shape,\n",
    "                                           double_skip=double_skip,\n",
    "                                           fno_blocks=fno_blocks,\n",
    "                                           fno_bias=fno_bias,\n",
    "                                           fno_softshrink=fno_softshrink) for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Representation layer\n",
    "        # self.num_features = out_chans * img_size[0] * img_size[1]\n",
    "        # self.representation_size = self.num_features * 8\n",
    "        # self.pre_logits = nn.Sequential(OrderedDict([\n",
    "        #     ('fc', nn.Linear(embed_dim, self.representation_size)),\n",
    "        #     ('act', nn.Tanh())\n",
    "        # ]))\n",
    "        conf_list = [{'kernel_size':[],'stride':[],'padding':[]},\n",
    "                     {'kernel_size':[],'stride':[],'padding':[]},\n",
    "                     {'kernel_size':[],'stride':[],'padding':[]}]\n",
    "        conv_set = {8:[[2,2,0],[2,2,0],[2,2,0]],\n",
    "                    4:[[2,2,0],[3,1,1],[2,2,0]],\n",
    "                    2:[[3,1,1],[3,1,1],[2,2,0]],\n",
    "                    1:[[3,1,1],[3,1,1],[3,1,1]],\n",
    "                   }\n",
    "        for patch in patch_size:\n",
    "            for slot in range(len(conf_list)):\n",
    "                conf_list[slot]['kernel_size'].append(conv_set[patch][slot][0])\n",
    "                conf_list[slot]['stride'].append(conv_set[patch][slot][1])\n",
    "                conf_list[slot]['padding'].append(conv_set[patch][slot][2])\n",
    "\n",
    "        transposeconv_engine = [nn.ConvTranspose1d,nn.ConvTranspose2d,nn.ConvTranspose3d][len(img_size)-1]\n",
    "        self.pre_logits = nn.Sequential(OrderedDict([\n",
    "            ('conv1', transposeconv_engine(embed_dim, out_chans*16, **conf_list[0])),\n",
    "            ('act1', nn.Tanh()),\n",
    "            ('conv2', transposeconv_engine(out_chans*16, out_chans*4, **conf_list[1])),\n",
    "            ('act2', nn.Tanh())\n",
    "        ]))\n",
    "\n",
    "        # Generator head\n",
    "        # self.head = nn.Linear(self.representation_size, self.num_features)\n",
    "        self.head = transposeconv_engine(out_chans*4, out_chans, **conf_list[2])\n",
    "\n",
    "        if dropcls > 0:\n",
    "            print('dropout %.2f before classifier' % dropcls)\n",
    "            self.final_dropout = nn.Dropout(p=dropcls)\n",
    "        else:\n",
    "            self.final_dropout = nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        self.apply(self._init_weights)\n",
    "        self.debug_mode=debug_mode\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        x += self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        if not self.checkpoint_activations:\n",
    "            for blk in self.blocks:\n",
    "                x = blk(x)\n",
    "        else:\n",
    "            x = checkpoint_sequential(self.blocks, 4, x)\n",
    "\n",
    "        x = self.norm(x).transpose(1, 2);print(x.shape)\n",
    "        x = torch.reshape(x, [-1, self.embed_dim, *self.final_shape])\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### we assume always feed the tensor (B, p*z, h, w)\n",
    "        B, P ,h, w = x.shape\n",
    "        x = x.reshape(B,-1,*self.img_size)\n",
    "        #timer.restart(level=0)\n",
    "        x = self.forward_features(x)\n",
    "        #timer.record('forward_features',level=0)\n",
    "        x = self.final_dropout(x)\n",
    "        #timer.record('final_dropout',level=0)\n",
    "        x = self.pre_logits(x)\n",
    "        #timer.record('pre_logits',level=0)\n",
    "        x = self.head(x)\n",
    "        #timer.record('head',level=0)\n",
    "        x = x.reshape(B,P,h,w)\n",
    "        #timer.show_stat()\n",
    "        #print(\"============================\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "50c91758",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = AFNONet(img_size=[10,32,64],patch_size=(1,8,8),depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "094685c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(1,20,10,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "119f0892",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1,3,4,32,64).flatten(1,2)\n",
    "torch.dist(a.reshape(1,-1,4,32,64).reshape(1,12,32,64),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2fc73c64",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1,12,32,64)\n",
    "torch.dist(a.reshape(1,3,4,32,64).reshape(1,-1,32,64),a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e691946",
   "metadata": {},
   "source": [
    "##### EulerEquationModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce2f336",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class EulerEquationModel2(nn.Module):\n",
    "    def __init__(self, args, backbone):\n",
    "        super().__init__()\n",
    "        self.Dx= First_Derivative_Layer(position=-1, dim=3, mode=2)\n",
    "        self.Dy= First_Derivative_Layer(position=-2, dim=3, mode=2)\n",
    "        self.Dz= First_Derivative_Layer(position=-3, dim=3, mode=1)\n",
    "        self.thermal_factor  = nn.Parameter(torch.randn(3).reshape(1,3,1,1))\n",
    "        self.alpha = nn.Parameter(torch.randn(1))\n",
    "        #self.p_list         = nn.Parameter(torch.Tensor([10,8.5,5]).reshape(1,3,1,1),requires_grad=False)\n",
    "        self.backbone =  backbone\n",
    "        self.monitor = True\n",
    "    def forward(self, Field):\n",
    "        # u^{t+1} &= u^{t} + F_x - \\nabla (Vu)  + u \\nabla\\cdot V - \\partial_x\\phi\\\\\n",
    "        # v^{t+1} &= v^{t} + F_y - \\nabla (Vv)  + v \\nabla\\cdot V - \\partial_y\\phi\\\\\n",
    "        # T^{t+1} &= T^{t} + Q/C_v + \\frac{RT}{C_pp}\\omega  - \\nabla (VT) +T \\nabla\\cdot V\\\\\n",
    "        # \\phi^{t+1}&=\\phi^{t} + wg  - \\nabla (V\\phi)+ \\phi \\nabla\\cdot V \\\\\n",
    "        # 0&\\approx \\nabla\\cdot V\n",
    "        # input -> Field  = [u ,v, T, p] --> (Batch, 4, z, y ,x)\n",
    "        # need generate unknown data [Fx, Fy , Q, W, o]\n",
    "        b, si_z, i_y, i_x = Field.shape\n",
    "        s=4\n",
    "        i_z= si_z//4\n",
    "        MachineLearningPart = self.backbone(Field).reshape(b, s+1, i_z, i_y, i_x) #(Batch, 5, z, y ,x)\n",
    "        ExternalForce = MachineLearningPart[:,:4] #(Batch, 4, z, y ,x)\n",
    "        o = MachineLearningPart[:,4:5] #(Batch, 1, z, y ,x)\n",
    "        Field = Field.reshape(b, s, i_z, i_y,  i_x) #(Batch, 5, z, y ,x)\n",
    "        u = Field[:,0:1]#(Batch, 1, z, y ,x)\n",
    "        v = Field[:,1:2]#(Batch, 1, z, y ,x)\n",
    "        T = Field[:,2:3]#(Batch, 1, z, y ,x)\n",
    "        p = Field[:,3:4]#(Batch, 1, z, y ,x)\n",
    "        V = torch.cat([u,v,o],1)#(Batch, 3, z, y ,x)\n",
    "        Nabla_cdot_V = (self.Dx(u[:,0]) + self.Dy(v[:,0]) + self.Dz(o[:,0])).unsqueeze(1)#(Batch, 1, z, y ,x)\n",
    "        Nabla_V_Field= Nabla_cdot_V*Field #(Batch, 4, z, y ,x)\n",
    "        Vphysics     = torch.stack([V*u,V*v,V*T,V*p],1)#(Batch,4, 3, z, y ,x)\n",
    "        Vphysics_dx = self.Dx(Vphysics[:,:,0].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        Vphysics_dy = self.Dy(Vphysics[:,:,1].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        Vphysics_dz = self.Dz(Vphysics[:,:,2].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        PhysicsPart = -Vphysics_dx - Vphysics_dy - Vphysics_dz + Nabla_V_Field #(Batch,4,z, y ,x)\n",
    "        InteractionPart= torch.stack([self.Dx(p[:,0]),\n",
    "                                      self.Dy(p[:,0]),\n",
    "                                      self.thermal_factor*T[:,0]*o[:,0]],1)#(Batch,3,z, y ,x)\n",
    "        InteractionPart= F.pad(InteractionPart,(0,0,0,0,0,0,0,1)) #(Batch,4,z, y ,x)\n",
    "        Delta_Fd     = ExternalForce + self.alpha*(PhysicsPart + InteractionPart)\n",
    "        Field        = Field+ Delta_Fd\n",
    "        constrain    = Nabla_V_Field\n",
    "        if not self.monitor:\n",
    "            return Field.flatten(1,2),(constrain**2).mean()\n",
    "        else:\n",
    "            return Field.flatten(1,2),(constrain**2).mean(),{\"ExternalForceFactor\":(ExternalForce**2).mean().item(),\n",
    "                                                             \"PhysicsDrivenFactor\":(PhysicsPart**2).mean().item(),\n",
    "                                                             \"InteractionPart\":(InteractionPart**2).mean().item(),\n",
    "                                                             \"alpha\":self.alpha.item()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
