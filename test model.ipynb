{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e023427f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d91d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069f1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f911d4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;lat&#x27; ()&gt;\n",
       "array(2.8125)</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'lat'</div></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-b28c2b74-fa55-45fe-91f0-8fa3aa196153' class='xr-array-in' type='checkbox' checked><label for='section-b28c2b74-fa55-45fe-91f0-8fa3aa196153' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>2.812</span></div><div class='xr-array-data'><pre>array(2.8125)</pre></div></div></li><li class='xr-section-item'><input id='section-8b265132-a057-415f-9c73-b30daf47091b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-8b265132-a057-415f-9c73-b30daf47091b' class='xr-section-summary'  title='Expand/collapse section'>Coordinates: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-0c418c22-0317-4ad2-adef-29140370171b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-0c418c22-0317-4ad2-adef-29140370171b' class='xr-section-summary'  title='Expand/collapse section'>Indexes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-dd6b15e3-e0e4-4137-b91f-493adc22948b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-dd6b15e3-e0e4-4137-b91f-493adc22948b' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'lat' ()>\n",
       "array(2.8125)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lat[1]-data.lat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093ab8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7f230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97134639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "180/2.8125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af72197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;lat&#x27; (lat: 64)&gt;\n",
       "array([  1.40625,   4.21875,   7.03125,   9.84375,  12.65625,  15.46875,\n",
       "        18.28125,  21.09375,  23.90625,  26.71875,  29.53125,  32.34375,\n",
       "        35.15625,  37.96875,  40.78125,  43.59375,  46.40625,  49.21875,\n",
       "        52.03125,  54.84375,  57.65625,  60.46875,  63.28125,  66.09375,\n",
       "        68.90625,  71.71875,  74.53125,  77.34375,  80.15625,  82.96875,\n",
       "        85.78125,  88.59375,  91.40625,  94.21875,  97.03125,  99.84375,\n",
       "       102.65625, 105.46875, 108.28125, 111.09375, 113.90625, 116.71875,\n",
       "       119.53125, 122.34375, 125.15625, 127.96875, 130.78125, 133.59375,\n",
       "       136.40625, 139.21875, 142.03125, 144.84375, 147.65625, 150.46875,\n",
       "       153.28125, 156.09375, 158.90625, 161.71875, 164.53125, 167.34375,\n",
       "       170.15625, 172.96875, 175.78125, 178.59375])\n",
       "Coordinates:\n",
       "  * lat      (lat) float64 -88.59 -85.78 -82.97 -80.16 ... 82.97 85.78 88.59</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'lat'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>lat</span>: 64</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-7a9589d1-a65d-47b8-b36a-cfc979e58c4d' class='xr-array-in' type='checkbox' checked><label for='section-7a9589d1-a65d-47b8-b36a-cfc979e58c4d' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>1.406 4.219 7.031 9.844 12.66 15.47 ... 167.3 170.2 173.0 175.8 178.6</span></div><div class='xr-array-data'><pre>array([  1.40625,   4.21875,   7.03125,   9.84375,  12.65625,  15.46875,\n",
       "        18.28125,  21.09375,  23.90625,  26.71875,  29.53125,  32.34375,\n",
       "        35.15625,  37.96875,  40.78125,  43.59375,  46.40625,  49.21875,\n",
       "        52.03125,  54.84375,  57.65625,  60.46875,  63.28125,  66.09375,\n",
       "        68.90625,  71.71875,  74.53125,  77.34375,  80.15625,  82.96875,\n",
       "        85.78125,  88.59375,  91.40625,  94.21875,  97.03125,  99.84375,\n",
       "       102.65625, 105.46875, 108.28125, 111.09375, 113.90625, 116.71875,\n",
       "       119.53125, 122.34375, 125.15625, 127.96875, 130.78125, 133.59375,\n",
       "       136.40625, 139.21875, 142.03125, 144.84375, 147.65625, 150.46875,\n",
       "       153.28125, 156.09375, 158.90625, 161.71875, 164.53125, 167.34375,\n",
       "       170.15625, 172.96875, 175.78125, 178.59375])</pre></div></div></li><li class='xr-section-item'><input id='section-c57efd01-cad4-4318-a459-2bcce7f92ea6' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c57efd01-cad4-4318-a459-2bcce7f92ea6' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-88.59 -85.78 ... 85.78 88.59</div><input id='attrs-1345ef88-a1c7-4e87-8fbd-ce9bd43b214f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-1345ef88-a1c7-4e87-8fbd-ce9bd43b214f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-af12a974-781c-45e1-b101-3f01250626e9' class='xr-var-data-in' type='checkbox'><label for='data-af12a974-781c-45e1-b101-3f01250626e9' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-88.59375, -85.78125, -82.96875, -80.15625, -77.34375, -74.53125,\n",
       "       -71.71875, -68.90625, -66.09375, -63.28125, -60.46875, -57.65625,\n",
       "       -54.84375, -52.03125, -49.21875, -46.40625, -43.59375, -40.78125,\n",
       "       -37.96875, -35.15625, -32.34375, -29.53125, -26.71875, -23.90625,\n",
       "       -21.09375, -18.28125, -15.46875, -12.65625,  -9.84375,  -7.03125,\n",
       "        -4.21875,  -1.40625,   1.40625,   4.21875,   7.03125,   9.84375,\n",
       "        12.65625,  15.46875,  18.28125,  21.09375,  23.90625,  26.71875,\n",
       "        29.53125,  32.34375,  35.15625,  37.96875,  40.78125,  43.59375,\n",
       "        46.40625,  49.21875,  52.03125,  54.84375,  57.65625,  60.46875,\n",
       "        63.28125,  66.09375,  68.90625,  71.71875,  74.53125,  77.34375,\n",
       "        80.15625,  82.96875,  85.78125,  88.59375])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-5f67551e-7727-49a2-aef7-bb1515b0fa03' class='xr-section-summary-in' type='checkbox'  ><label for='section-5f67551e-7727-49a2-aef7-bb1515b0fa03' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-f6e909c7-9f09-44f7-97be-691899fea0c7' class='xr-index-data-in' type='checkbox'/><label for='index-f6e909c7-9f09-44f7-97be-691899fea0c7' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([-88.59375, -85.78125, -82.96875, -80.15625, -77.34375, -74.53125,\n",
       "              -71.71875, -68.90625, -66.09375, -63.28125, -60.46875, -57.65625,\n",
       "              -54.84375, -52.03125, -49.21875, -46.40625, -43.59375, -40.78125,\n",
       "              -37.96875, -35.15625, -32.34375, -29.53125, -26.71875, -23.90625,\n",
       "              -21.09375, -18.28125, -15.46875, -12.65625,  -9.84375,  -7.03125,\n",
       "               -4.21875,  -1.40625,   1.40625,   4.21875,   7.03125,   9.84375,\n",
       "               12.65625,  15.46875,  18.28125,  21.09375,  23.90625,  26.71875,\n",
       "               29.53125,  32.34375,  35.15625,  37.96875,  40.78125,  43.59375,\n",
       "               46.40625,  49.21875,  52.03125,  54.84375,  57.65625,  60.46875,\n",
       "               63.28125,  66.09375,  68.90625,  71.71875,  74.53125,  77.34375,\n",
       "               80.15625,  82.96875,  85.78125,  88.59375],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c39b0410-46c6-43c8-a83c-6e935258c5ea' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-c39b0410-46c6-43c8-a83c-6e935258c5ea' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'lat' (lat: 64)>\n",
       "array([  1.40625,   4.21875,   7.03125,   9.84375,  12.65625,  15.46875,\n",
       "        18.28125,  21.09375,  23.90625,  26.71875,  29.53125,  32.34375,\n",
       "        35.15625,  37.96875,  40.78125,  43.59375,  46.40625,  49.21875,\n",
       "        52.03125,  54.84375,  57.65625,  60.46875,  63.28125,  66.09375,\n",
       "        68.90625,  71.71875,  74.53125,  77.34375,  80.15625,  82.96875,\n",
       "        85.78125,  88.59375,  91.40625,  94.21875,  97.03125,  99.84375,\n",
       "       102.65625, 105.46875, 108.28125, 111.09375, 113.90625, 116.71875,\n",
       "       119.53125, 122.34375, 125.15625, 127.96875, 130.78125, 133.59375,\n",
       "       136.40625, 139.21875, 142.03125, 144.84375, 147.65625, 150.46875,\n",
       "       153.28125, 156.09375, 158.90625, 161.71875, 164.53125, 167.34375,\n",
       "       170.15625, 172.96875, 175.78125, 178.59375])\n",
       "Coordinates:\n",
       "  * lat      (lat) float64 -88.59 -85.78 -82.97 -80.16 ... 82.97 85.78 88.59"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lat + 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9f52e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;lon&#x27; (lon: 128)&gt;\n",
       "array([  0.    ,   2.8125,   5.625 ,   8.4375,  11.25  ,  14.0625,  16.875 ,\n",
       "        19.6875,  22.5   ,  25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "        39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,  53.4375,  56.25  ,\n",
       "        59.0625,  61.875 ,  64.6875,  67.5   ,  70.3125,  73.125 ,  75.9375,\n",
       "        78.75  ,  81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,  95.625 ,\n",
       "        98.4375, 101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125,\n",
       "       118.125 , 120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "       137.8125, 140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875,\n",
       "       157.5   , 160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 ,\n",
       "       177.1875, 180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625,\n",
       "       196.875 , 199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  ,\n",
       "       216.5625, 219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "       236.25  , 239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 ,\n",
       "       255.9375, 258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125,\n",
       "       275.625 , 278.4375, 281.25  , 284.0625, 286.875 , 289.6875, 292.5   ,\n",
       "       295.3125, 298.125 , 300.9375, 303.75  , 306.5625, 309.375 , 312.1875,\n",
       "       315.    , 317.8125, 320.625 , 323.4375, 326.25  , 329.0625, 331.875 ,\n",
       "       334.6875, 337.5   , 340.3125, 343.125 , 345.9375, 348.75  , 351.5625,\n",
       "       354.375 , 357.1875])\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'lon'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>lon</span>: 128</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-12263024-621d-4346-89cc-d5d170ea0264' class='xr-array-in' type='checkbox' checked><label for='section-12263024-621d-4346-89cc-d5d170ea0264' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0 2.812 5.625 8.438 11.25 14.06 ... 345.9 348.8 351.6 354.4 357.2</span></div><div class='xr-array-data'><pre>array([  0.    ,   2.8125,   5.625 ,   8.4375,  11.25  ,  14.0625,  16.875 ,\n",
       "        19.6875,  22.5   ,  25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "        39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,  53.4375,  56.25  ,\n",
       "        59.0625,  61.875 ,  64.6875,  67.5   ,  70.3125,  73.125 ,  75.9375,\n",
       "        78.75  ,  81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,  95.625 ,\n",
       "        98.4375, 101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125,\n",
       "       118.125 , 120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "       137.8125, 140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875,\n",
       "       157.5   , 160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 ,\n",
       "       177.1875, 180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625,\n",
       "       196.875 , 199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  ,\n",
       "       216.5625, 219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "       236.25  , 239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 ,\n",
       "       255.9375, 258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125,\n",
       "       275.625 , 278.4375, 281.25  , 284.0625, 286.875 , 289.6875, 292.5   ,\n",
       "       295.3125, 298.125 , 300.9375, 303.75  , 306.5625, 309.375 , 312.1875,\n",
       "       315.    , 317.8125, 320.625 , 323.4375, 326.25  , 329.0625, 331.875 ,\n",
       "       334.6875, 337.5   , 340.3125, 343.125 , 345.9375, 348.75  , 351.5625,\n",
       "       354.375 , 357.1875])</pre></div></div></li><li class='xr-section-item'><input id='section-361f0ac0-a2d6-40a0-bfd5-756c39149adc' class='xr-section-summary-in' type='checkbox'  checked><label for='section-361f0ac0-a2d6-40a0-bfd5-756c39149adc' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 2.812 5.625 ... 354.4 357.2</div><input id='attrs-028b1826-a39e-49bc-8aca-e7cd41c2cd49' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-028b1826-a39e-49bc-8aca-e7cd41c2cd49' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-aef121e3-5c45-448a-b0b0-8fc05fffa475' class='xr-var-data-in' type='checkbox'><label for='data-aef121e3-5c45-448a-b0b0-8fc05fffa475' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0.    ,   2.8125,   5.625 ,   8.4375,  11.25  ,  14.0625,  16.875 ,\n",
       "        19.6875,  22.5   ,  25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "        39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,  53.4375,  56.25  ,\n",
       "        59.0625,  61.875 ,  64.6875,  67.5   ,  70.3125,  73.125 ,  75.9375,\n",
       "        78.75  ,  81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,  95.625 ,\n",
       "        98.4375, 101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125,\n",
       "       118.125 , 120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "       137.8125, 140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875,\n",
       "       157.5   , 160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 ,\n",
       "       177.1875, 180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625,\n",
       "       196.875 , 199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  ,\n",
       "       216.5625, 219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "       236.25  , 239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 ,\n",
       "       255.9375, 258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125,\n",
       "       275.625 , 278.4375, 281.25  , 284.0625, 286.875 , 289.6875, 292.5   ,\n",
       "       295.3125, 298.125 , 300.9375, 303.75  , 306.5625, 309.375 , 312.1875,\n",
       "       315.    , 317.8125, 320.625 , 323.4375, 326.25  , 329.0625, 331.875 ,\n",
       "       334.6875, 337.5   , 340.3125, 343.125 , 345.9375, 348.75  , 351.5625,\n",
       "       354.375 , 357.1875])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-90b8da09-047b-4fce-aca8-7faed2a2f5c9' class='xr-section-summary-in' type='checkbox'  ><label for='section-90b8da09-047b-4fce-aca8-7faed2a2f5c9' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-87ee65c7-f2b9-4c24-936c-5d4f3884e7ee' class='xr-index-data-in' type='checkbox'/><label for='index-87ee65c7-f2b9-4c24-936c-5d4f3884e7ee' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([     0.0,   2.8125,    5.625,   8.4375,    11.25,  14.0625,\n",
       "                16.875,  19.6875,     22.5,  25.3125,\n",
       "              ...\n",
       "               331.875, 334.6875,    337.5, 340.3125,  343.125, 345.9375,\n",
       "                348.75, 351.5625,  354.375, 357.1875],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;, length=128))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-57cf7d00-763b-4314-bfe1-63b25665e94d' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-57cf7d00-763b-4314-bfe1-63b25665e94d' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'lon' (lon: 128)>\n",
       "array([  0.    ,   2.8125,   5.625 ,   8.4375,  11.25  ,  14.0625,  16.875 ,\n",
       "        19.6875,  22.5   ,  25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "        39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,  53.4375,  56.25  ,\n",
       "        59.0625,  61.875 ,  64.6875,  67.5   ,  70.3125,  73.125 ,  75.9375,\n",
       "        78.75  ,  81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,  95.625 ,\n",
       "        98.4375, 101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125,\n",
       "       118.125 , 120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "       137.8125, 140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875,\n",
       "       157.5   , 160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 ,\n",
       "       177.1875, 180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625,\n",
       "       196.875 , 199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  ,\n",
       "       216.5625, 219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "       236.25  , 239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 ,\n",
       "       255.9375, 258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125,\n",
       "       275.625 , 278.4375, 281.25  , 284.0625, 286.875 , 289.6875, 292.5   ,\n",
       "       295.3125, 298.125 , 300.9375, 303.75  , 306.5625, 309.375 , 312.1875,\n",
       "       315.    , 317.8125, 320.625 , 323.4375, 326.25  , 329.0625, 331.875 ,\n",
       "       334.6875, 337.5   , 340.3125, 343.125 , 345.9375, 348.75  , 351.5625,\n",
       "       354.375 , 357.1875])\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ef842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f2ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't create file '/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc.923a8.idx'\n",
      "Traceback (most recent call last):\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 273, in itervalues\n",
      "    yield self.filestream.message_from_file(file, errors=errors)\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 340, in message_from_file\n",
      "    return Message.from_file(file, offset, **kwargs)\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 104, in from_file\n",
      "    raise EOFError(\"End of file: %r\" % file)\n",
      "EOFError: End of file: <_io.BufferedReader name='/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 535, in from_indexpath_or_filestream\n",
      "    self = cls.from_fieldset(filestream, index_keys, computed_keys)\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 378, in from_fieldset\n",
      "    return cls.from_fieldset_and_iteritems(fieldset, iteritems, index_keys, computed_keys)\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 391, in from_fieldset_and_iteritems\n",
      "    for field_id, raw_field in iteritems:\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 291, in __iter__\n",
      "    for message in self.itervalues():\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 277, in itervalues\n",
      "    raise EOFError(\"No valid message found: %r\" % self.filestream.path)\n",
      "EOFError: No valid message found: '/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc'\n",
      "Can't read index file '/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc.923a8.idx'\n",
      "Traceback (most recent call last):\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py\", line 544, in from_indexpath_or_filestream\n",
      "    index_mtime = os.path.getmtime(indexpath)\n",
      "  File \"/nvme/zhangtianning/anaconda3/envs/pytorch/lib/python3.9/genericpath.py\", line 55, in getmtime\n",
      "    return os.stat(filename).st_mtime\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc.923a8.idx'\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "No valid message found: '/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:273\u001b[0m, in \u001b[0;36mFileStreamItems.itervalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilestream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     valid_message_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:340\u001b[0m, in \u001b[0;36mFileStream.message_from_file\u001b[0;34m(self, file, offset, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage_from_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, file, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# type: (T.IO[bytes], T.Optional[OffsetType], T.Any) -> Message\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:104\u001b[0m, in \u001b[0;36mMessage.from_file\u001b[0;34m(cls, file, offset, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m codes_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of file: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m file)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(codes_id\u001b[38;5;241m=\u001b[39mcodes_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mEOFError\u001b[0m: End of file: <_io.BufferedReader name='/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcfgrib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/xarray/backends/api.py:541\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    530\u001b[0m     decode_cf,\n\u001b[1;32m    531\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    538\u001b[0m )\n\u001b[1;32m    540\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 541\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    548\u001b[0m     backend_ds,\n\u001b[1;32m    549\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    558\u001b[0m )\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/xarray_plugin.py:109\u001b[0m, in \u001b[0;36mCfGribBackend.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, lock, indexpath, filter_by_keys, read_keys, encode_cf, squeeze, time_dims, errors, extra_coords)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     filename_or_obj: T\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mstr\u001b[39m, abc\u001b[38;5;241m.\u001b[39mMappingFieldset[T\u001b[38;5;241m.\u001b[39mAny, abc\u001b[38;5;241m.\u001b[39mField]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     extra_coords: T\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m    107\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset:\n\u001b[0;32m--> 109\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mCfGribDataStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_by_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_by_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclose_on_error(store):\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28mvars\u001b[39m, attrs \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mload()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/xarray_plugin.py:40\u001b[0m, in \u001b[0;36mCfGribDataStore.__init__\u001b[0;34m(self, filename, lock, **backend_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     opener \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mopen_fieldset\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds \u001b[38;5;241m=\u001b[39m \u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbackend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/dataset.py:778\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(path, grib_errors, indexpath, filter_by_keys, read_keys, time_dims, extra_coords, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m stream \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mFileStream(path, errors\u001b[38;5;241m=\u001b[39mgrib_errors)\n\u001b[1;32m    777\u001b[0m index_keys \u001b[38;5;241m=\u001b[39m compute_index_keys(time_dims, extra_coords)\n\u001b[0;32m--> 778\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mopen_fileindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_by_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_by_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m open_from_index(index, read_keys, time_dims, extra_coords, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/dataset.py:757\u001b[0m, in \u001b[0;36mopen_fileindex\u001b[0;34m(stream, indexpath, index_keys, filter_by_keys, computed_keys)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_fileindex\u001b[39m(\n\u001b[1;32m    750\u001b[0m     stream: messages\u001b[38;5;241m.\u001b[39mFileStream,\n\u001b[1;32m    751\u001b[0m     indexpath: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mDEFAULT_INDEXPATH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    754\u001b[0m     computed_keys: messages\u001b[38;5;241m.\u001b[39mComputedKeysType \u001b[38;5;241m=\u001b[39m cfmessage\u001b[38;5;241m.\u001b[39mCOMPUTED_KEYS,\n\u001b[1;32m    755\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m messages\u001b[38;5;241m.\u001b[39mFileIndex:\n\u001b[1;32m    756\u001b[0m     index_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_keys) \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(filter_by_keys))\n\u001b[0;32m--> 757\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_indexpath_or_filestream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputed_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputed_keys\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\u001b[38;5;241m.\u001b[39msubindex(filter_by_keys)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:561\u001b[0m, in \u001b[0;36mFileIndex.from_indexpath_or_filestream\u001b[0;34m(cls, filestream, index_keys, indexpath, computed_keys, log)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     log\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt read index file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, indexpath)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_fieldset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilestream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputed_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:378\u001b[0m, in \u001b[0;36mFieldsetIndex.from_fieldset\u001b[0;34m(cls, fieldset, index_keys, computed_keys)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     iteritems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(fieldset)\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_fieldset_and_iteritems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfieldset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteritems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputed_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:391\u001b[0m, in \u001b[0;36mFieldsetIndex.from_fieldset_and_iteritems\u001b[0;34m(cls, fieldset, iteritems, index_keys, computed_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m index_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(index_keys)\n\u001b[1;32m    390\u001b[0m header_values_cache \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# type: T.Dict[T.Tuple[T.Any, type], T.Any]\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field_id, raw_field \u001b[38;5;129;01min\u001b[39;00m iteritems:\n\u001b[1;32m    392\u001b[0m     field \u001b[38;5;241m=\u001b[39m ComputedKeysAdapter(raw_field, computed_keys)\n\u001b[1;32m    393\u001b[0m     header_values \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:291\u001b[0m, in \u001b[0;36mFileStreamItems.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m old_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    290\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitervalues():\n\u001b[1;32m    292\u001b[0m     offset \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mmessage_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;241m==\u001b[39m old_offset:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/cfgrib/messages.py:277\u001b[0m, in \u001b[0;36mFileStreamItems.itervalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_message_found:\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid message found: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilestream\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mEOFError\u001b[0m: No valid message found: '/nvme/zhangtianning/projects/FourCastNet/datasets/weatherbench64x128/constants_2.8125deg.nc'"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(, engine=\"cfgrib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8be79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_from_grid(vname_pair, year):\n",
    "    if os.path.exists(os.path.join(DATAROOT,f\"all_data_{year}.npy\")):\n",
    "        raise\n",
    "    #return np.random.randn(1500,w,h)\n",
    "    vname, vname_short = vname_pair\n",
    "    fname   = f'{CACHEROOT}/{year}/{vname}/{vname:s}-{year:d}.grib'\n",
    "    if len(os.listdir(CACHEROOT))>0:\n",
    "        for tyear in os.listdir(CACHEROOT):\n",
    "            if os.path.exists(os.path.join(DATAROOT,f\"all_data_{tyear}.npy\")):\n",
    "                done_data_path = f\"{CACHEROOT}/{tyear}\"\n",
    "                print(f\"we have detected {tyear} data is finished, remove cache path:\")\n",
    "                print(f\"{done_data_path}\")\n",
    "                os.system(f\"rm -r {done_data_path}\")\n",
    "                #os.system(f\"rm -r {CACHEROOT}/{year}\")\n",
    "                pass\n",
    "    if not os.path.exists(fname):\n",
    "        print(f\"download {fname}\")\n",
    "        os.system(f\"aws s3 --endpoint-url=http://10.140.2.254:80 --profile chenzhuo cp s3://era5/{vname}/{vname}-{year}.grib {fname}\")\n",
    "    ds = xr.open_dataset(fname, engine=\"cfgrib\")\n",
    "    ds_array = ds.data_vars[vname_short]\n",
    "    return ds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11fcfaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1048cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.custom_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd1d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.FEDformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca70c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kargs={'img_size': (7, 7), 'patch_size': 1, 'patch_range': 7, 'in_chans': 73, 'out_chans': 70, 'fno_blocks': 4, 'embed_dim': 512, 'depth': 2, 'debug_mode': 0, 'double_skip': False, 'fno_bias': False, 'fno_softshrink': 0.0, 'history_length': 16, 'reduce_Field_coef': False, 'modes': (17, 33, 6), 'mode_select': 'normal', 'physics_num': 4, 'pred_len': 16, 'n_heads': 8, 'label_len': 8, 'canonical_fft': 1, 'unique_up_sample_channel': 70, 'share_memory': 0, 'dropout_rate': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e613cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourier enhanced block used!\n",
      "for shape:[7 7] and pick modes:(17, 33)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      "create a mode filter shape=torch.Size([7, 7, 9]) with 150 mode activate\n",
      "fourier enhanced block used!\n",
      "for shape:[7 7] and pick modes:(17, 33)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      "create a mode filter shape=torch.Size([7, 7, 13]) with 150 mode activate\n",
      " fourier enhanced cross attention used!\n",
      "for shape:[7 7] and pick modes:(17, 33)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      "for shape:[7 7] and pick modes:(17, 33)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      " modes_q=150,  shape_q=torch.Size([7, 7, 13])\n",
      "modes_kv=150, shape_kv=torch.Size([7, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "model = FEDformer(**kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f09507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.universal_model_util import get_model_para_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18d40e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 74 parameters, totally 17801286 numbers\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "j=0\n",
    "data = []\n",
    "for name,p in model.named_parameters():\n",
    "    data.append([name,np.prod(p.shape),p.detach().numpy().shape])\n",
    "    #print(\"{:40} {:5} {}\".format(name,np.prod(p.shape),p.shape))\n",
    "    i+=np.prod(p.shape)\n",
    "    j+=1\n",
    "print(\"Totally {} parameters, totally {} numbers\".format(j,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9889e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5893d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pd.DataFrame(data,columns=['weight','size','shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "501c7e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>size</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>decoder.projection.bias</td>\n",
       "      <td>70</td>\n",
       "      <td>(70,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>encoder.norm.batchnorm.bias</td>\n",
       "      <td>512</td>\n",
       "      <td>(512,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decoder.layers.0.self_attention.query_projecti...</td>\n",
       "      <td>512</td>\n",
       "      <td>(512,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>decoder.layers.0.self_attention.key_projection...</td>\n",
       "      <td>512</td>\n",
       "      <td>(512,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>decoder.layers.0.self_attention.value_projecti...</td>\n",
       "      <td>512</td>\n",
       "      <td>(512,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>decoder.layers.0.cross_attention.key_projectio...</td>\n",
       "      <td>262144</td>\n",
       "      <td>(512, 512)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>encoder.attn_layers.0.attention.out_projection...</td>\n",
       "      <td>262144</td>\n",
       "      <td>(512, 512)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>decoder.layers.1.cross_attention.query_project...</td>\n",
       "      <td>262144</td>\n",
       "      <td>(512, 512)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>decoder.layers.0.cross_attention.inner_correla...</td>\n",
       "      <td>4915200</td>\n",
       "      <td>(8, 64, 64, 150)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>decoder.layers.1.cross_attention.inner_correla...</td>\n",
       "      <td>4915200</td>\n",
       "      <td>(8, 64, 64, 150)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               weight     size  \\\n",
       "73                            decoder.projection.bias       70   \n",
       "27                        encoder.norm.batchnorm.bias      512   \n",
       "30  decoder.layers.0.self_attention.query_projecti...      512   \n",
       "32  decoder.layers.0.self_attention.key_projection...      512   \n",
       "34  decoder.layers.0.self_attention.value_projecti...      512   \n",
       "..                                                ...      ...   \n",
       "40  decoder.layers.0.cross_attention.key_projectio...   262144   \n",
       "11  encoder.attn_layers.0.attention.out_projection...   262144   \n",
       "59  decoder.layers.1.cross_attention.query_project...   262144   \n",
       "37  decoder.layers.0.cross_attention.inner_correla...  4915200   \n",
       "58  decoder.layers.1.cross_attention.inner_correla...  4915200   \n",
       "\n",
       "               shape  \n",
       "73             (70,)  \n",
       "27            (512,)  \n",
       "30            (512,)  \n",
       "32            (512,)  \n",
       "34            (512,)  \n",
       "..               ...  \n",
       "40        (512, 512)  \n",
       "11        (512, 512)  \n",
       "59        (512, 512)  \n",
       "37  (8, 64, 64, 150)  \n",
       "58  (8, 64, 64, 150)  \n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata.sort_values('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6e3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import getModelSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b83db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51232766, 4098, 195.45313262939453)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getModelSize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "358a109b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 6, 70])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc     = torch.randn(1,32,64,6,70).cuda()\n",
    "x_mark_enc= torch.randn(1,6,4).cuda()\n",
    "x_mark_dec= torch.randn(1,1,4).cuda()\n",
    "model(x_enc,x_mark_enc,x_mark_dec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df7e69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811 ms ± 20.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(enabled=False):\n",
    "        model(x_enc,x_mark_enc,x_mark_dec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26631ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696 ms ± 8.52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        model(x_enc,x_mark_enc,x_mark_dec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6636d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(1,2,3,4,5)\n",
    "k = torch.randn(1,2,3,4,5)\n",
    "v = torch.randn(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24ffb3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(q,k,v,None)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f91bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2D patch model, the img_size will be force set (14, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "model = POverLapTimePosVallinaViT((14,32,64),(3,5,5),in_chans=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42984e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.pretrain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e369b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(config_path=\"checkpoints/WeathBench7066PatchDataset/ViT_in_bulk-POverLapTimePosVallinaViT_Patch_(3, 5, 5)/time_step_2_pretrain-3D70N_every_1_step_random_dataset/12_07_22_50_36-seed_2018/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac20a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use offline data mode <1>: only train use offline data\n",
      "use dataset in datasets/weatherbench_6hour\n",
      "load data from datasets/weatherbench_6hour/test.npy\n",
      "notice we will use around_index(12, 28, 64, 3, 3, 5, 5) to patch data\n"
     ]
    }
   ],
   "source": [
    "time_step = args.time_step if \"fourcast\" in args.mode else 3*24//6 + args.time_step\n",
    "dataset_kargs = copy.deepcopy(args.dataset_kargs)\n",
    "dataset_kargs['time_step'] = time_step\n",
    "if dataset_kargs['time_reverse_flag'] in ['only_forward','random_forward_backward']:\n",
    "    dataset_kargs['time_reverse_flag'] = 'only_forward'\n",
    "dataset_type = eval(args.dataset_type) if isinstance(args.dataset_type,str) else args.dataset_type\n",
    "#print(dataset_kargs)\n",
    "split = args.split if hasattr(args,'split') and args.split else \"test\"\n",
    "test_dataset = dataset_type(split=split, with_idx=True,dataset_tensor=None,record_load_tensor=None,**dataset_kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "305f4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.cross_sample = False\n",
    "idx_a,batch = test_dataset[0]\n",
    "tensor_a, time_stamp_a, pos_a = batch[0]\n",
    "input_a = model.image_to_patches(tensor_a[None],pos_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d140a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tensor_a[None]\n",
    "good_input_shape = model.patch_range\n",
    "now_input_shape  = tuple(x.shape[-3:])\n",
    "\n",
    "around_index = model.around_index_depend_input(now_input_shape)\n",
    "if model.global_position_feature is None:\n",
    "    grid = torch.Tensor(np.stack(np.meshgrid(\n",
    "            np.arange(model.img_size[0]),\n",
    "            np.arange(model.img_size[1]),\n",
    "            np.arange(model.img_size[2]))).transpose(0,2,1,3))\n",
    "    model.global_position_feature = model.get_direction_from_stamp(grid[None]) #(1, 3, Z,W, H)\n",
    "pos_feature  = model.global_position_feature.repeat(x.size(0),1,1,1,1).to(x.device) #(B, 3, Z,W, H)\n",
    "B,P,_,_,_ = x.shape\n",
    "x = torch.cat([x,pos_feature],1) #( B, 77, W, H)\n",
    "# x = x[...,around_index[:,:,:,0],around_index[:,:,:,1],around_index[:,:,:,2]] # (B,P,Z,W-4,H,Patch,Patch)\n",
    "# B,_,Z,W,H,_,_,_ = x.shape\n",
    "# model.input_shape_tmp=(B,Z,W,H,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6097a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 5, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f419a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c8ae98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[10 10 10 10 10]\n",
      "   [10 10 10 10 10]\n",
      "   [10 10 10 10 10]\n",
      "   [10 10 10 10 10]\n",
      "   [10 10 10 10 10]]\n",
      "\n",
      "  [[11 11 11 11 11]\n",
      "   [11 11 11 11 11]\n",
      "   [11 11 11 11 11]\n",
      "   [11 11 11 11 11]\n",
      "   [11 11 11 11 11]]\n",
      "\n",
      "  [[12 12 12 12 12]\n",
      "   [12 12 12 12 12]\n",
      "   [12 12 12 12 12]\n",
      "   [12 12 12 12 12]\n",
      "   [12 12 12 12 12]]]\n",
      "\n",
      "\n",
      " [[[19 19 19 19 19]\n",
      "   [20 20 20 20 20]\n",
      "   [21 21 21 21 21]\n",
      "   [22 22 22 22 22]\n",
      "   [23 23 23 23 23]]\n",
      "\n",
      "  [[19 19 19 19 19]\n",
      "   [20 20 20 20 20]\n",
      "   [21 21 21 21 21]\n",
      "   [22 22 22 22 22]\n",
      "   [23 23 23 23 23]]\n",
      "\n",
      "  [[19 19 19 19 19]\n",
      "   [20 20 20 20 20]\n",
      "   [21 21 21 21 21]\n",
      "   [22 22 22 22 22]\n",
      "   [23 23 23 23 23]]]\n",
      "\n",
      "\n",
      " [[[18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]]\n",
      "\n",
      "  [[18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]]\n",
      "\n",
      "  [[18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]\n",
      "   [18 19 20 21 22]]]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset.cross_sample = True\n",
    "idx_b,batch = test_dataset[0]\n",
    "(tensor_b, time_stamp_b, pos_b) = batch[0]\n",
    "input_b = model.image_to_patches(tensor_b[None],torch.Tensor(pos_b[None]).to(tensor_b.device))\n",
    "print(pos_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26d11170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_tensor= x[...,pos_b[0],pos_b[1],pos_b[2]]\n",
    "torch.dist(selected_tensor,input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa99d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torch.Tensor(np.stack(np.meshgrid(\n",
    "                np.arange(model.img_size[0]),\n",
    "                np.arange(model.img_size[1]),\n",
    "                np.arange(model.img_size[2]))).transpose(0,2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "207911f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image_to_patches() missing 1 required positional argument: 'pos_stamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m c \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpatches_to_image(y)\n",
      "\u001b[0;31mTypeError\u001b[0m: image_to_patches() missing 1 required positional argument: 'pos_stamp'"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,5,14,32,64)\n",
    "y = model.image_to_patches(a)\n",
    "c = model.patches_to_image(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9cd01d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 32, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5a3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,70,3,5,5).cuda()\n",
    "p = torch.randn(1, 3,3,5,5).cuda()\n",
    "t = torch.randn(1,4).cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7a3f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 70, 3, 5, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a,t,p).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f07248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513c0480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 28, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.stack(np.meshgrid(\n",
    "            np.arange(img_size[0]),\n",
    "            np.arange(img_size[1]),\n",
    "        )).transpose(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ecb91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 32, 36])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.stack(np.meshgrid(\n",
    "    np.arange(self.img_size[0]),\n",
    "    np.arange(self.img_size[1]),\n",
    "    np.arange(self.img_size[2]))).transpose(0,2,1,3)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa71757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 70, 14, 32, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a162291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3584"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*16*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96a17ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torach.randn(1,2,4,4)\n",
    "m = torch.randint(2,(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f6e64dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0000, -1.0000,  1.2643,  0.2839],\n",
       "          [-1.0000,  0.0204, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -0.7041],\n",
       "          [ 0.1266, -1.0000, -1.0000, -1.0000]],\n",
       "\n",
       "         [[-1.0000, -1.0000, -2.2420, -0.1599],\n",
       "          [-1.0000,  1.4979, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -0.3242],\n",
       "          [ 0.3754, -1.0000, -1.0000, -1.0000]]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.masked_fill(m,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638e6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x = x.reshape(B,W,H,P,patch_range,patch_range)\n",
    "x = torch.randn(B,W,H,P,patch_range,patch_range)\n",
    "def get_x1(x,counting_matrix):\n",
    "    w_idx   = np.arange(0,L)\n",
    "    wes  = np.stack([w_idx, w_idx+1,w_idx+2, w_idx-1, w_idx-2],1)%L\n",
    "    x_idx   = np.arange(H)\n",
    "    xes = np.stack([x_idx, x_idx+1,x_idx+2, x_idx-1, x_idx-2],1)%H\n",
    "    yes = np.array([[2,  1,  0,  3,  4]])\n",
    "    x = torch.nn.functional.pad(x,(0,0, 0,0, 0,0, 0,0, 2 , 2 )) # only extend W\n",
    "    x     = x[:, wes, :,:,yes,:].sum(1) #(B, W, H, P, PS,PS) --> (W, B, H, P, PS)\n",
    "    x     = x[:, :, xes,:,yes].sum(1)  #(W, B, H, P, PS) --> (H, W, B, P)   \n",
    "    x     = x.permute(2,3,1,0)#(B,P, W,H)   \n",
    "    counting_matrix =counting_matrix.to(x.device)\n",
    "    x     = x/counting_matrix #(B,P, W,H)  / (1,1 , W,H)\n",
    "    return x\n",
    "def get_x2(x,counting_matrix):\n",
    "    w_idx   = np.arange(0,L)\n",
    "    wes  = np.stack([w_idx+2, w_idx+1, w_idx, w_idx-1, w_idx-2],1)%L\n",
    "    x_idx   = np.arange(H)\n",
    "    xes = np.stack([x_idx+2, x_idx+1, x_idx, x_idx-1, x_idx-2],1)%H\n",
    "    yes = np.array([[0 ,1, 2, 3, 4]])\n",
    "    x = torch.nn.functional.pad(x,(0,0, 0,0, 0,0, 0,0, 2 , 2 )) # only extend W\n",
    "    x     = x[:, wes, :,:,yes,:].sum(1) #(B, W, H, P, PS,PS) --> (W, B, H, P, PS)\n",
    "    x     = x[:, :, xes,:,yes].sum(1)  #(W, B, H, P, PS) --> (H, W, B, P)   \n",
    "    x     = x.permute(2,3,1,0)#(B,P, W,H)   \n",
    "    counting_matrix =counting_matrix.to(x.device)\n",
    "    x     = x/counting_matrix #(B,P, W,H)  / (1,1 , W,H)\n",
    "    return x\n",
    "print(torch.dist(get_x1(x,counting_matrix),get_x2(x,counting_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.vit import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.universal_model_util import get_model_para_num\n",
    "from utils.tools import getModelSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d656d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.othermodels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c032af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CK_SWDformer_0505(BaseModel):\n",
    "        def __init__(self,*args,**kargs):\n",
    "            super().__init__()\n",
    "            print(\"this is pre-set model, we disable all config\")\n",
    "            self.backbone = SWD_former(patch_size= [1, 1],\n",
    "                                in_chans= 70,\n",
    "                                out_chans= 70,\n",
    "                                embed_dim= 768,\n",
    "                                window_size= (5,5),\n",
    "                                depths= [4, 4, 4],\n",
    "                                num_heads= [6, 6, 6],\n",
    "                                Weather_T=1,only_swin=True)\n",
    "        def forward(self,x):\n",
    "            return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e510c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CK_SWDformer_0505()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn(1,70,5,5)\n",
    "model(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2376dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=32\n",
    "H=64\n",
    "hd=16\n",
    "D=768\n",
    "B=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74121e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.SWD_former import SWD_former,SWDfromer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4b125",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "model = SWD_former(patch_size= [1, 1],\n",
    "        in_chans= 70,\n",
    "        out_chans= 70,\n",
    "        embed_dim= 1128,\n",
    "        window_size= (32,64),\n",
    "        depths= [4, 4, 4],\n",
    "        num_heads= [6, 6, 6],\n",
    "        Weather_T=1,only_swin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.universal_model_util import get_model_para_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.afnonet import AFNONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cca764",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_para_num(model)[1]/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fde186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cephdataset import WeathBench7066PatchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1,70,32,64)\n",
    "x = model.backbone.to_patch_embedding(img);print(x.shape)\n",
    "b, n, _ = x.shape\n",
    "\n",
    "cls_tokens = repeat(model.backbone.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "x = torch.cat((cls_tokens, x), dim=1);print(x.shape)\n",
    "x += model.backbone.pos_embedding[:, :(n + 1)];print(x.shape)\n",
    "x = model.backbone.dropout(x);print(x.shape)\n",
    "\n",
    "x = model.backbone.transformer(x);print(x.shape)\n",
    "\n",
    "x = x.mean(dim = 1) if model.backbone.pool == 'mean' else x[:, 0];print(x.shape)\n",
    "\n",
    "x = model.backbone.to_latent(x);print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_names = test_dataset.vnames\n",
    "accu_list = torch.stack([p['accu'] for p in fourcastresult.values() if 'accu' in p]).numpy()\n",
    "total_num = len(accu_list)\n",
    "accu_list = accu_list.mean(0)# (fourcast_num,property_num)\n",
    "real_times = [(predict_time+1)*test_dataset.time_intervel*test_dataset.time_unit for predict_time in range(len(accu_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa91ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_tables=[]\n",
    "snap_index = fourcastresult['snap_index']\n",
    "select_snap_start_time_point = snap_index[0]\n",
    "select_snap_show_property_id = snap_index[1]\n",
    "select_snap_property_name    = [property_names[iidd] for iidd in select_snap_show_property_id]\n",
    "for select_time_point in select_snap_start_time_point:\n",
    "    timestamp = test_dataset.datatimelist_pool['test'][select_time_point]\n",
    "    if select_time_point in fourcastresult: # in case do not record\n",
    "        linedata = fourcastresult[select_time_point]['snap_line']\n",
    "        for predict_time_point, tensor, label in linedata:\n",
    "            for name, value in zip(select_snap_property_name,tensor):\n",
    "                predict_timestamp = 0 if predict_time_point==0 else real_times[predict_time_point-1]\n",
    "                snap_tables.append([timestamp, name, predict_timestamp, value.item(), label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80baabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_rmse_map = fourcastresult['global_rmse_map']\n",
    "mean_global_rmse_map = [t/total_num for t in global_rmse_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c1aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b7a7c",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install empatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from empatches import EMPatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = EMPatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_patches, indices = emp.extract_patches(img, patchsize=512, overlap=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6beb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a598a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8dde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    [i,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1667b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b252da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(23,70,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx  = np.array([1,2])\n",
    "proper_idx = np.array([3,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a797a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,0][2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,0][[2,3,4],[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f055b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.std(dim=(1,2,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "torch.gather(t, 1, torch.tensor([[0], [1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea540e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71032b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[*pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65329308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5308dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1500,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e55a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.nbytes//8//1024//1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c243be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61917ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.afnonet import AFNONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.universal_model_util import get_model_para_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e26396",
   "metadata": {
    "code_folding": [
     22
    ]
   },
   "outputs": [],
   "source": [
    "class LargeMLP_3D(nn.Module):\n",
    "    '''\n",
    "    input is (B, P, patch_range_1,patch_range_2,patch_range_3)\n",
    "    output is (B,P)\n",
    "    ''' \n",
    "    def __init__(self,img_size=None,patch_range=5,in_chans=20, out_chans=20,p=0.1,**kargs):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_range = 5\n",
    "        if self.patch_range == 5:\n",
    "            cl = [5*5*5*in_chans,5*5*5*10,5*5*5*20,\n",
    "                  5*5*5*30,5*5*5*30,5*5*5*20,\n",
    "                  5*5*5*10,5*5*5*1,out_chans]\n",
    "            nnlist = []\n",
    "            for i in range(len(cl)-2):\n",
    "                nnlist+=[nn.Linear(cl[i],cl[i+1]),nn.Dropout(p=p),nn.Tanh()]\n",
    "            nnlist+=[nn.Linear(cl[-2],cl[-1])]\n",
    "            self.backbone = nn.Sequential(*nnlist)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.center_index,self.around_index=get_center_around_indexes_3D(self.patch_range,self.img_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        The input either (B,P,patch_range,patch_range) or (B,P,w,h)\n",
    "        The output then is  (B,P) or (B,P,w-patch_range//2,h-patch_range//2)\n",
    "        ''' \n",
    "        assert len(x.shape) == 5 #(B,P,Z,W,H)\n",
    "        input_is_full_image = False\n",
    "        if x.shape[-3:] == self.img_size:\n",
    "            input_is_full_image = True\n",
    "            x = x[..., self.around_index[:, :, : , 0],self.around_index[:, :, : , 1],self.around_index[:, :, : , 2]] \n",
    "            # (B,P,Z-2,W-2,H,Patch,Patch,Patch)\n",
    "            x = x.permute(0, 2, 3, 4, 1, 5, 6, 7)\n",
    "            B, Z, W, H, P, _, _, _ = x.shape\n",
    "            x = x.flatten(0, 3)  # (B* Z-2 * W-2 * H, Property, Patch,Patch,Patch)\n",
    "        assert tuple(x.shape[-3:]) == (self.patch_range,self.patch_range,self.patch_range)\n",
    "        x = self.backbone(x.flatten(-4,-1)) # (B* W-4 * H,P)\n",
    "        if input_is_full_image:\n",
    "            x = x.reshape(B, Z, W, H, P).permute(0, 4, 1, 2,3) #(B, Z-2,W-2,H,P)  -> (B,P, Z-2,W-2,H)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LargeMLP_3D((14,32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96424c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.tools import getModelSize\n",
    "param_sum, buffer_sum, all_size = getModelSize(model)\n",
    "print(f\" Number of Parameters: {param_sum}, Number of Buffers: {buffer_sum}, Size of Model: {all_size:.4f} MB\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074816d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import NaiveConvModel2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad10412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveConvModel2D((32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,20,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import get_center_around_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389817cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape=(32,64)\n",
    "patch_range=5\n",
    "center_index,around_index=get_center_around_indexes(patch_range,img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dad203",
   "metadata": {},
   "outputs": [],
   "source": [
    "around_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20928164",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_range=5\n",
    "delta = [list(range(-(patch_range//2),patch_range//2+1))]*2\n",
    "delta = np.meshgrid(*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92177012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fd2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = [list(range(-(patch_range//2),patch_range//2+1))]*len(center)\n",
    "delta = np.meshgrid(*delta)\n",
    "pos  = [c+dc for c,dc in zip(center,delta)]\n",
    "pos[-1]= pos[-1]%64\n",
    "\n",
    "px = x + dx\n",
    "py = y + dy\n",
    "np.stack([px.flatten(),py.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeda73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate = np.arange(36).reshape(1,1,6,6)\n",
    "print(coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate[:,:,pos].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71673fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coordinate[:,:,x,y][0,0])\n",
    "print(coordinate[:,:,pos[0],pos[1]][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.FEDformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66615d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f42098",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class moving_avg_spacetime(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size)==3\n",
    "        self.kernel_size = np.array(kernel_size)\n",
    "        self.avg         = nn.AvgPool3d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "        self.pad_front   = self.kernel_size - 1-np.floor((self.kernel_size - 1) // 2)\n",
    "        self.pad_end     = np.floor((self.kernel_size - 1) // 2)\n",
    "        self.pad         = np.stack([self.pad_front,self.pad_end],1)[::-1].flatten().astype('int').tolist()\n",
    "        print(self.pad)\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        # the input must be (B,*Space,T,C)， the -1 dim is embed channel, the -2 dim is time channel\n",
    "        shape = x.shape\n",
    "        BSpace_shape = shape[:-2]\n",
    "        C = shape[-1]\n",
    "        permute_order = [0,-1] + list(range(1,len(shape)-1))\n",
    "        x = x.permute(*permute_order)#-->(B, *Space,T, C)-->(B, C, *Space,T)\n",
    "        x = self.avg(F.pad(x,self.pad, mode='replicate'))\n",
    "        permute_order = [0] + list(range(2,len(shape))) + [1]\n",
    "        x = x.permute(*permute_order)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2193e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = moving_avg_spacetime((5,3,2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn(1,32,64,6,7)\n",
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.physics_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.afnonet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245af06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=get_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = AFNONet((32,64),2,265,20,depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = DirectSpace_Feature_Model(args,backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.randn(1,4,5,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285eced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.std_mean(layer(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Second_Derivative_Layer()\n",
    "\n",
    "a=torch.randn(1,1,32,64)\n",
    "\n",
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=2\n",
    "P=4\n",
    "a=torch.randn(B,P,3,32,64).cuda()\n",
    "layer=  First_Derivative_Layer(dim=3).cuda()\n",
    "runtime_weight=layer.runtime_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x = torch.conv3d(a.flatten(0,1).unsqueeze(1),runtime_weight).reshape(*a.shape[:-1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x2 = torch.conv1d(a.flatten(0,-2).unsqueeze(1),runtime_weight[0,0]).reshape(*a.shape[:-1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dist(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.scatter(x,y)\n",
    "#plt.scatter([10],[10],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42446069",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_fourier_drive(x, position,pad):\n",
    "\n",
    "    if len(position)==1:position = position[0]\n",
    "    base_len          = np.array(x.shape[position])\n",
    "    interpolate_shape = base_len + (base_len-1)*pad\n",
    "    interpolate_shape = tuple(interpolate_shape)\n",
    "    if isinstance(position,int) or len(position) == 1\n",
    "        x = x.transpose(-1,position)\n",
    "        out_shape = x.shape[:-1]\n",
    "        x = x.reshape(x.size(0),-1,x.size(-1))\n",
    "        b = torch.nn.functional.interpolate(x,interpolate_shape,mode='linear',align_corners=True)\n",
    "        bf = torch.fft.rfft(b,dim=-1)\n",
    "        kbf= bf*torch.fft.rfftfreq(b.size(-1)).reshape(1,1,-1)\n",
    "        kb = torch.fft.irfft(kbf,dim=-1)\n",
    "        index = torch.arange(0,b.size(-1)+1,base_len-1)\n",
    "        kb = kb[...,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tkinter.messagebox import NO\n",
    "import numpy as np\n",
    "import torch,os,io,socket\n",
    "from torchvision import datasets, transforms\n",
    "hostname = socket.gethostname()\n",
    "from functools import lru_cache\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.timefeatures import time_features\n",
    "import os\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efc1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatimelist  = np.arange(np.datetime64(\"1979-01-01\"), np.datetime64(\"2016-01-01\"), np.timedelta64(6, \"h\"))\n",
    "timestamp = time_features(pd.to_datetime(datatimelist)).transpose(1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d452ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(np.datetime64(\"1980-12-31\")).dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(datatimelist)[0].dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp[:10,[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b05b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JCmodels.fourcastnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AFNONet((32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ac0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,4,5,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c828a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ae080",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### FEDformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55908ea1",
   "metadata": {},
   "source": [
    "#### complex version AdaptiveFourierNeuralOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331c5ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f64f13",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def multiply(input, weights):\n",
    "    return torch.einsum('...bd,bdk->...bk', input, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf839a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "B=1\n",
    "h=32;w=64;C=2\n",
    "num_blocks=1\n",
    "block_size=2\n",
    "\n",
    "w1 = torch.randn(num_blocks, block_size, block_size, dtype=torch.cfloat)\n",
    "b1 = torch.randn(num_blocks, block_size, dtype=torch.cfloat)\n",
    "w2 = torch.randn(num_blocks, block_size, block_size, dtype=torch.cfloat)\n",
    "b2 = torch.randn(num_blocks, block_size, dtype=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa8d54",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def original_realize(x,w1,b1,w2,b2):\n",
    "    x = torch.fft.rfft2(x, dim=(1, 2), norm='ortho');\n",
    "    x = x.reshape(B, x.shape[1], x.shape[2], num_blocks, block_size)\n",
    "    x_real = F.relu(multiply(x.real, w1.real) - multiply(x.imag, w1.imag) + b1.real, inplace=True)\n",
    "    x_imag = F.relu(multiply(x.real, w1.imag) + multiply(x.imag, w1.real) + b1.imag, inplace=True)\n",
    "    x = torch.stack([x_real, x_imag], dim=-1)\n",
    "    x = torch.view_as_complex(x)\n",
    "    return x\n",
    "\n",
    "def complex_version_realize(x,w1,b1,w2,b2):\n",
    "    x = torch.fft.rfft2(x, dim=(1, 2), norm='ortho');\n",
    "    x = x.reshape(B, x.shape[1], x.shape[2], num_blocks, block_size)\n",
    "    x = multiply(x,w1)+b1\n",
    "    x = nonlinear_activate(x)\n",
    "    return x\n",
    "x  = torch.randn(B, h, w, C)\n",
    "y1 = original_realize(x,w1,b1,w2,b2)\n",
    "y2 = complex_version_realize(x,w1,b1,w2,b2)\n",
    "torch.dist(y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f8cb3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from model.afnonet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ccd53",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### AFNONet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d11df",
   "metadata": {
    "code_folding": [
     0,
     1,
     6,
     70,
     103,
     132,
     185,
     192,
     203,
     206,
     213,
     223,
     226,
     242
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PartReLU_Complex(nn.Module):\n",
    "    def forward(self,x):\n",
    "        F.relu(x.real, inplace=True)\n",
    "        F.relu(x.imag, inplace=True)\n",
    "        return x\n",
    "\n",
    "class AdaptiveFourierNeuralOperator(nn.Module):\n",
    "    def __init__(self, dim, img_size, fno_blocks=4,fno_bias=True, fno_softshrink=False,nonlinear_activate=PartReLU_Complex()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = dim\n",
    "        self.img_size   = img_size\n",
    "        self.num_blocks = fno_blocks\n",
    "        self.block_size = self.hidden_size // self.num_blocks\n",
    "        assert self.hidden_size % self.num_blocks == 0\n",
    "\n",
    "        self.scale = 0.02\n",
    "        self.w1 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              self.block_size, dtype=torch.cfloat))\n",
    "        self.b1 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              dtype=torch.cfloat))\n",
    "        self.w2 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              self.block_size, dtype=torch.cfloat))\n",
    "        self.b2 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              dtype=torch.cfloat))\n",
    "        self.relu = nonlinear_activate\n",
    "\n",
    "        if fno_bias:\n",
    "            self.bias = nn.Conv1d(self.hidden_size, self.hidden_size, 1)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.softshrink = fno_softshrink\n",
    "\n",
    "    def multiply(self, input, weights):\n",
    "        return torch.einsum('...bd,bdk->...bk', input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape    \n",
    "        bias = self.bias(x.permute(0, 2, 1)).permute(0, 2, 1) if self.bias else 0\n",
    "        #timer.restart(2)\n",
    "        x = x.reshape(B, *self.img_size, C)\n",
    "        fft_dim = tuple(range(1,len(self.img_size)+1))\n",
    "        print(fft_dim)\n",
    "        #timer.record('reshape1','filter',2)\n",
    "        print(x.shape)\n",
    "        x = torch.fft.rfftn(x, dim=fft_dim, norm='ortho');\n",
    "        #timer.record('rfft2','filter',2)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(*x.shape[:-1], self.num_blocks, self.block_size)\n",
    "        #timer.record('reshape2','filter',2)\n",
    "        x = self.multiply(x,self.w1)+self.b1\n",
    "        x = self.relu(x)\n",
    "        x = self.multiply(x,self.w2)+self.b2\n",
    "        x = F.softshrink(x, lambd=self.softshrink) if self.softshrink else x\n",
    "        #with torch.cuda.amp.autocast(enabled=False):\n",
    "        #x = x.float()   \n",
    "        #x = torch.view_as_complex(x)\n",
    "        #timer.record('reset','filter',2)\n",
    "        x = x.flatten(-2,-1)\n",
    "        #timer.record('reshape3','filter',2)\n",
    "        print(x.shape)\n",
    "        x = torch.fft.irfftn(x, s=self.img_size,dim=fft_dim, norm='ortho')\n",
    "        print(x.shape)\n",
    "        #x = x.half()\n",
    "        #timer.record('irfft2','filter',2)\n",
    "        x = x.reshape(B, N, C)\n",
    "        #timer.record('reshape4','filter',2)\n",
    "        return x + bias\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, mlp_ratio=4., drop=0., drop_path=0., act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm, region_shape=(14,8), fno_blocks=3,double_skip=False, fno_bias=False, fno_softshrink=False):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.filter = AdaptiveFourierNeuralOperator(dim, region_shape,fno_blocks=fno_blocks,fno_bias=fno_bias,fno_softshrink=fno_softshrink)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "        self.double_skip = double_skip\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        #timer.restart(1)\n",
    "        x = self.norm1(x)\n",
    "        #timer.record('norm1','forward_features',1)\n",
    "        x = self.filter(x)\n",
    "        #timer.record('filter','forward_features',1)\n",
    "        if self.double_skip:\n",
    "            x += residual\n",
    "            residual = x;\n",
    "        #timer.record('residual','forward_features',1)\n",
    "        x = self.norm2(x)\n",
    "        #timer.record('norm2','forward_features',1)\n",
    "        x = self.mlp(x)\n",
    "        #timer.record('mlp','forward_features',1)\n",
    "        x = self.drop_path(x)\n",
    "        #timer.record('drop_path','forward_features',1)\n",
    "        x += residual\n",
    "        #timer.record('residual','forward_features',1)\n",
    "        return x\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=None, patch_size=8, in_chans=13, embed_dim=768):\n",
    "        super().__init__()\n",
    "\n",
    "        if img_size is None:raise KeyError('img is None')\n",
    "        patch_size   = [patch_size]*len(img_size) if isinstance(patch_size,int) else patch_size\n",
    "        \n",
    "        num_patches=1\n",
    "        out_size=[]\n",
    "        for i_size,p_size in zip(img_size,patch_size):\n",
    "            if p_size%i_size:\n",
    "                num_patches*=i_size// p_size\n",
    "                out_size.append(i_size// p_size)\n",
    "            else:\n",
    "                raise NotImplementedError(f\"the patch size ({patch_size}) cannot divide the img size {img_size}\")\n",
    "        self.img_size    = tuple(img_size)\n",
    "        self.patch_size  = tuple(patch_size)\n",
    "        self.num_patches = num_patches\n",
    "        self.out_size    = tuple(out_size)\n",
    "        conv_engine = [nn.Conv1d,nn.Conv2d,nn.Conv3d]\n",
    "        self.proj   = conv_engine[len(img_size)-1](in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, = x.shape[:2]\n",
    "        inp_size = x.shape[2:]\n",
    "        assert tuple(inp_size) == self.img_size, f\"Input image size ({inp_size}) doesn't match model set size ({self.img_size}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class AFNONet(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, patch_size=8, in_chans=20, out_chans=20, embed_dim=768, depth=12, mlp_ratio=4.,\n",
    "                 uniform_drop=False, drop_rate=0., drop_path_rate=0., norm_layer=None,\n",
    "                 dropcls=0, checkpoint_activations=False, fno_blocks=3,double_skip=False,\n",
    "                 fno_bias=False, fno_softshrink=False,debug_mode=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert img_size is not None\n",
    "        self.checkpoint_activations=checkpoint_activations\n",
    "        self.embed_dim = embed_dim\n",
    "        norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
    "        self.img_size = img_size\n",
    "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches      = self.patch_embed.num_patches\n",
    "        patch_size       = self.patch_embed.patch_size\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        self.final_shape = self.patch_embed.out_size\n",
    "\n",
    "        if uniform_drop:\n",
    "            dpr = [drop_path_rate for _ in range(depth)]  # stochastic depth decay rule\n",
    "        else:\n",
    "            dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "\n",
    "        self.blocks = nn.ModuleList([Block(dim=embed_dim, mlp_ratio=mlp_ratio, drop=drop_rate,\n",
    "                                           drop_path=dpr[i], \n",
    "                                           norm_layer=norm_layer,\n",
    "                                           region_shape=self.final_shape,\n",
    "                                           double_skip=double_skip,\n",
    "                                           fno_blocks=fno_blocks,\n",
    "                                           fno_bias=fno_bias,\n",
    "                                           fno_softshrink=fno_softshrink) for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Representation layer\n",
    "        # self.num_features = out_chans * img_size[0] * img_size[1]\n",
    "        # self.representation_size = self.num_features * 8\n",
    "        # self.pre_logits = nn.Sequential(OrderedDict([\n",
    "        #     ('fc', nn.Linear(embed_dim, self.representation_size)),\n",
    "        #     ('act', nn.Tanh())\n",
    "        # ]))\n",
    "        conf_list = [{'kernel_size':[],'stride':[],'padding':[]},\n",
    "                     {'kernel_size':[],'stride':[],'padding':[]},\n",
    "                     {'kernel_size':[],'stride':[],'padding':[]}]\n",
    "        conv_set = {8:[[2,2,0],[2,2,0],[2,2,0]],\n",
    "                    4:[[2,2,0],[3,1,1],[2,2,0]],\n",
    "                    2:[[3,1,1],[3,1,1],[2,2,0]],\n",
    "                    1:[[3,1,1],[3,1,1],[3,1,1]],\n",
    "                   }\n",
    "        for patch in patch_size:\n",
    "            for slot in range(len(conf_list)):\n",
    "                conf_list[slot]['kernel_size'].append(conv_set[patch][slot][0])\n",
    "                conf_list[slot]['stride'].append(conv_set[patch][slot][1])\n",
    "                conf_list[slot]['padding'].append(conv_set[patch][slot][2])\n",
    "\n",
    "        transposeconv_engine = [nn.ConvTranspose1d,nn.ConvTranspose2d,nn.ConvTranspose3d][len(img_size)-1]\n",
    "        self.pre_logits = nn.Sequential(OrderedDict([\n",
    "            ('conv1', transposeconv_engine(embed_dim, out_chans*16, **conf_list[0])),\n",
    "            ('act1', nn.Tanh()),\n",
    "            ('conv2', transposeconv_engine(out_chans*16, out_chans*4, **conf_list[1])),\n",
    "            ('act2', nn.Tanh())\n",
    "        ]))\n",
    "\n",
    "        # Generator head\n",
    "        # self.head = nn.Linear(self.representation_size, self.num_features)\n",
    "        self.head = transposeconv_engine(out_chans*4, out_chans, **conf_list[2])\n",
    "\n",
    "        if dropcls > 0:\n",
    "            print('dropout %.2f before classifier' % dropcls)\n",
    "            self.final_dropout = nn.Dropout(p=dropcls)\n",
    "        else:\n",
    "            self.final_dropout = nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        self.apply(self._init_weights)\n",
    "        self.debug_mode=debug_mode\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        x += self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        if not self.checkpoint_activations:\n",
    "            for blk in self.blocks:\n",
    "                x = blk(x)\n",
    "        else:\n",
    "            x = checkpoint_sequential(self.blocks, 4, x)\n",
    "\n",
    "        x = self.norm(x).transpose(1, 2);print(x.shape)\n",
    "        x = torch.reshape(x, [-1, self.embed_dim, *self.final_shape])\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### we assume always feed the tensor (B, p*z, h, w)\n",
    "        B, P ,h, w = x.shape\n",
    "        x = x.reshape(B,-1,*self.img_size)\n",
    "        #timer.restart(level=0)\n",
    "        x = self.forward_features(x)\n",
    "        #timer.record('forward_features',level=0)\n",
    "        x = self.final_dropout(x)\n",
    "        #timer.record('final_dropout',level=0)\n",
    "        x = self.pre_logits(x)\n",
    "        #timer.record('pre_logits',level=0)\n",
    "        x = self.head(x)\n",
    "        #timer.record('head',level=0)\n",
    "        x = x.reshape(B,P,h,w)\n",
    "        #timer.show_stat()\n",
    "        #print(\"============================\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c91758",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = AFNONet(img_size=[10,32,64],patch_size=(1,8,8),depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094685c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(1,20,10,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f0892",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(1,3,4,32,64).flatten(1,2)\n",
    "torch.dist(a.reshape(1,-1,4,32,64).reshape(1,12,32,64),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc73c64",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(1,12,32,64)\n",
    "torch.dist(a.reshape(1,3,4,32,64).reshape(1,-1,32,64),a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e691946",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### EulerEquationModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2f336",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class EulerEquationModel2(nn.Module):\n",
    "    def __init__(self, args, backbone):\n",
    "        super().__init__()\n",
    "        self.Dx= First_Derivative_Layer(position=-1, dim=3, mode=2)\n",
    "        self.Dy= First_Derivative_Layer(position=-2, dim=3, mode=2)\n",
    "        self.Dz= First_Derivative_Layer(position=-3, dim=3, mode=1)\n",
    "        self.thermal_factor  = nn.Parameter(torch.randn(3).reshape(1,3,1,1))\n",
    "        self.alpha = nn.Parameter(torch.randn(1))\n",
    "        #self.p_list         = nn.Parameter(torch.Tensor([10,8.5,5]).reshape(1,3,1,1),requires_grad=False)\n",
    "        self.backbone =  backbone\n",
    "        self.monitor = True\n",
    "    def forward(self, Field):\n",
    "        # u^{t+1} &= u^{t} + F_x - \\nabla (Vu)  + u \\nabla\\cdot V - \\partial_x\\phi\\\\\n",
    "        # v^{t+1} &= v^{t} + F_y - \\nabla (Vv)  + v \\nabla\\cdot V - \\partial_y\\phi\\\\\n",
    "        # T^{t+1} &= T^{t} + Q/C_v + \\frac{RT}{C_pp}\\omega  - \\nabla (VT) +T \\nabla\\cdot V\\\\\n",
    "        # \\phi^{t+1}&=\\phi^{t} + wg  - \\nabla (V\\phi)+ \\phi \\nabla\\cdot V \\\\\n",
    "        # 0&\\approx \\nabla\\cdot V\n",
    "        # input -> Field  = [u ,v, T, p] --> (Batch, 4, z, y ,x)\n",
    "        # need generate unknown data [Fx, Fy , Q, W, o]\n",
    "        b, si_z, i_y, i_x = Field.shape\n",
    "        s=4\n",
    "        i_z= si_z//4\n",
    "        MachineLearningPart = self.backbone(Field).reshape(b, s+1, i_z, i_y, i_x) #(Batch, 5, z, y ,x)\n",
    "        ExternalForce = MachineLearningPart[:,:4] #(Batch, 4, z, y ,x)\n",
    "        o = MachineLearningPart[:,4:5] #(Batch, 1, z, y ,x)\n",
    "        Field = Field.reshape(b, s, i_z, i_y,  i_x) #(Batch, 5, z, y ,x)\n",
    "        u = Field[:,0:1]#(Batch, 1, z, y ,x)\n",
    "        v = Field[:,1:2]#(Batch, 1, z, y ,x)\n",
    "        T = Field[:,2:3]#(Batch, 1, z, y ,x)\n",
    "        p = Field[:,3:4]#(Batch, 1, z, y ,x)\n",
    "        V = torch.cat([u,v,o],1)#(Batch, 3, z, y ,x)\n",
    "        Nabla_cdot_V = (self.Dx(u[:,0]) + self.Dy(v[:,0]) + self.Dz(o[:,0])).unsqueeze(1)#(Batch, 1, z, y ,x)\n",
    "        Nabla_V_Field= Nabla_cdot_V*Field #(Batch, 4, z, y ,x)\n",
    "        Vphysics     = torch.stack([V*u,V*v,V*T,V*p],1)#(Batch,4, 3, z, y ,x)\n",
    "        Vphysics_dx = self.Dx(Vphysics[:,:,0].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        Vphysics_dy = self.Dy(Vphysics[:,:,1].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        Vphysics_dz = self.Dz(Vphysics[:,:,2].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        PhysicsPart = -Vphysics_dx - Vphysics_dy - Vphysics_dz + Nabla_V_Field #(Batch,4,z, y ,x)\n",
    "        InteractionPart= torch.stack([self.Dx(p[:,0]),\n",
    "                                      self.Dy(p[:,0]),\n",
    "                                      self.thermal_factor*T[:,0]*o[:,0]],1)#(Batch,3,z, y ,x)\n",
    "        InteractionPart= F.pad(InteractionPart,(0,0,0,0,0,0,0,1)) #(Batch,4,z, y ,x)\n",
    "        Delta_Fd     = ExternalForce + self.alpha*(PhysicsPart + InteractionPart)\n",
    "        Field        = Field+ Delta_Fd\n",
    "        constrain    = Nabla_V_Field\n",
    "        if not self.monitor:\n",
    "            return Field.flatten(1,2),(constrain**2).mean()\n",
    "        else:\n",
    "            return Field.flatten(1,2),(constrain**2).mean(),{\"ExternalForceFactor\":(ExternalForce**2).mean().item(),\n",
    "                                                             \"PhysicsDrivenFactor\":(PhysicsPart**2).mean().item(),\n",
    "                                                             \"InteractionPart\":(InteractionPart**2).mean().item(),\n",
    "                                                             \"alpha\":self.alpha.item()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b4e50d8356ba75a9636787f9051ee458aaf13e87df491415cc800c7b2b8a21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
