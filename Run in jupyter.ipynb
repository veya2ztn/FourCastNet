{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be5e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad518c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cephdataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab07f72",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from train.pretrain import *\n",
    "from train.pretrain import get_args\n",
    "from mltool.universal_model_util import get_model_para_detail\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d8affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/WeathBench64x128/CombM_UVTPHSC2p2uvth-AFNONet/ts_2_pretrain-physics_small_per_6_step/02_02_14_42_58217-seed_42\"\n",
    "args=get_args(os.path.join(ckpt_path,\"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e70daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.port = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863485e8",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 13:23:22,292 model args: img_size= (64, 128)\n",
      "2023-02-06 13:23:22,293 model args: patch_size= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log at debug\n",
      "wandb id: None\n",
      "wandb is off, the recorder list is  ['tensorboard'], we pass wandb\n",
      "load UVTPHSC2p model from checkpoints/WeathBench64x128/UVTPHSC2p-AFNONet/ts_2_pretrain-physics_small_per_6_step/01_28_17_11_64255-seed_42/backbone.best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 13:23:23,891 use model ==> CombM_UVTPHSC2p2uvth\n",
      "2023-02-06 13:23:23,893 Rank: 0, Local_rank: 0 | Number of Parameters: 155053374, Number of Buffers: 0, Size of Model: 591.4817 MB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load UVTPHSCp2uvth model from \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 13:23:25,698 use lr_scheduler:<timm.scheduler.cosine_lr.CosineLRScheduler object at 0x7fc25fb6af40>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notice we are in property_pick mode, be careful. Current dataset is WeathBench64x128\n"
     ]
    }
   ],
   "source": [
    "args.use_wandb=0\n",
    "args.gpu = args.local_rank = gpu  = local_rank = 0\n",
    "##### parse args: dataset_kargs / model_kargs / train_kargs  ###########\n",
    "args= parse_default_args(args)\n",
    "SAVE_PATH = get_ckpt_path(args)\n",
    "SAVE_PATH = \"debug\"\n",
    "args.SAVE_PATH = str(SAVE_PATH)\n",
    "#args.pretrain_weight = os.path.join(args.SAVE_PATH,'pretrain_latest.pt')\n",
    "########## inital log ###################\n",
    "logsys = create_logsys(args,False)\n",
    "args.distributed = False\n",
    "\n",
    "if args.distributed:\n",
    "    if args.dist_url == \"env://\" and args.rank == -1:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "    if args.multiprocessing_distributed:\n",
    "        # For multiprocessing distributed training, rank needs to be the\n",
    "        # global rank among all the processes\n",
    "        args.rank = args.rank * ngpus_per_node + local_rank\n",
    "    logsys.info(f\"start init_process_group,backend={args.dist_backend}, init_method={args.dist_url},world_size={args.world_size}, rank={args.rank}\")\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,world_size=args.world_size, rank=args.rank)\n",
    "\n",
    "model           = build_model(args)\n",
    "#param_groups    = timm.optim.optim_factory.add_weight_decay(model, args.weight_decay)\n",
    "optimizer,lr_scheduler,criterion = build_optimizer(args,model)\n",
    "loss_scaler     = torch.cuda.amp.GradScaler(enabled=True)\n",
    "logsys.info(f'use lr_scheduler:{lr_scheduler}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c43e73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.mode = 'fourcast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5c2aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.join(ckpt_path,\"backbone.best.pt\")\n",
    "args.pretrain_weight = pretrain_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "287c52be",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 13:45:42,600 loading weight from checkpoints/WeathBench64x128/CombM_UVTPHSC2p2uvth-AFNONet/ts_2_pretrain-physics_small_per_6_step/02_02_14_42_58217-seed_42/backbone.best.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from checkpoints/WeathBench64x128/CombM_UVTPHSC2p2uvth-AFNONet/ts_2_pretrain-physics_small_per_6_step/02_02_14_42_58217-seed_42/backbone.best.pt...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 13:45:43,058 done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model weight success...........\n",
      "loading model success...........\n"
     ]
    }
   ],
   "source": [
    "logsys.info(f\"loading weight from {args.pretrain_weight}\")\n",
    "start_epoch, start_step, min_loss = load_model(model.module if args.distributed else model, optimizer, lr_scheduler, loss_scaler, path=args.pretrain_weight, \n",
    "                    only_model= (args.mode=='fourcast') or (args.mode=='finetune' and not args.continue_train) ,loc = 'cuda:{}'.format(args.gpu))\n",
    "if args.more_epoch_train:\n",
    "    assert args.pretrain_weight\n",
    "    print(f\"detect more epoch training, we will do a copy processing for {args.pretrain_weight}\")\n",
    "    os.system(f'cp {args.pretrain_weight} {args.pretrain_weight}-epoch{start_epoch}')\n",
    "logsys.info(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fb9cc",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f2304ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use dataset in datasets/weatherbench64x128\n"
     ]
    }
   ],
   "source": [
    "args.valid_batch_size = 4\n",
    "args.dataset_kargs['use_offline_data']=0\n",
    "test_dataset,  test_dataloader = get_test_dataset(args,test_dataset_tensor=None,test_record_load=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52085fc0",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load everything, start_validating......\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2188', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2188 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_loader = test_dataloader\n",
    "random_repeat = 0\n",
    "snap_index=None\n",
    "model.eval()\n",
    "logsys.eval()\n",
    "status     = 'test'\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "Fethcher   = Datafetcher\n",
    "prefetcher = Fethcher(data_loader,next(model.parameters()).device)\n",
    "batches = len(data_loader)\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "device = next(model.parameters()).device\n",
    "data_cost = train_cost = rest_cost = 0 \n",
    "now = time.time()\n",
    "model.clim = torch.Tensor(data_loader.dataset.clim_tensor).to(device)\n",
    "fourcastresult={}\n",
    "save_prediction_first_step = None#torch.zeros_like(data_loader.dataset.data)\n",
    "save_prediction_final_step = None#torch.zeros_like(data_loader.dataset.data)\n",
    "# = 100\n",
    "intervel = batches//logsys.log_trace_times + 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    inter_b.lwrite(\"load everything, start_validating......\", end=\"\\r\")\n",
    "    while inter_b.update_step():\n",
    "        #if inter_b.now>10:break\n",
    "        data_cost  += time.time() - now;now = time.time()\n",
    "        step        = inter_b.now\n",
    "        idxes,batch = prefetcher.next()\n",
    "        batch       = make_data_regular(batch,half_model)\n",
    "        break\n",
    "        out         = model(batch[0]) #(B,T,P,W,H) (B,T,4) (B,T,2,W,H)\n",
    "        if torch.isnan(out).any():\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c670e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_loader.dataset\n",
    "time_step_1_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5eebbc74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd801228",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_error_propagration_monitor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b418cdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.use_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac193c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58deec26",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[36.2699, 36.4158, 36.5667,  ..., 35.8370, 35.9752, 36.1191],\n",
      "        [35.2991, 35.5539, 35.8285,  ..., 34.2741, 34.6441, 34.9707],\n",
      "        [31.1176, 32.1553, 33.0155,  ..., 27.9668, 28.8431, 29.9111],\n",
      "        ...,\n",
      "        [-0.4025, -0.3985, -0.3531,  ..., -0.4262, -0.3990, -0.4274],\n",
      "        [-0.3562, -0.3667, -0.3583,  ..., -0.3837, -0.3724, -0.3724],\n",
      "        [-0.4651, -0.4711, -0.4768,  ..., -0.4584, -0.4581, -0.4616]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.4600, -0.4460, -0.4332,  ..., -0.4970, -0.4865, -0.4861],\n",
      "        [-0.6113, -0.6046, -0.5650,  ..., -0.6573, -0.6401, -0.6298],\n",
      "        [-0.6705, -0.6452, -0.6110,  ..., -0.6696, -0.6740, -0.6811],\n",
      "        ...,\n",
      "        [-0.4954, -0.4787, -0.4242,  ..., -0.4608, -0.4616, -0.4801],\n",
      "        [-0.3850, -0.3872, -0.3754,  ..., -0.4157, -0.3994, -0.3904],\n",
      "        [-0.4422, -0.4432, -0.4531,  ..., -0.4639, -0.4601, -0.4527]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m ltmv_pred, target, extra_loss, extra_info_from_model_list, start \u001b[38;5;241m=\u001b[39m once_forward(model,i,start,end,dataset,time_step_1_mode)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(ltmv_pred[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    accu_series=[]\n",
    "    rmse_series=[]\n",
    "    rmse_maps = []\n",
    "    hmse_series=[]\n",
    "    extra_info = {}\n",
    "    time_step_1_mode=False\n",
    "    batch_variance_line_pred = [] \n",
    "    batch_variance_line_true = []\n",
    "    # we will also record the variance for each slot, assume the input is a time series of data\n",
    "    # [ (B, P, W, H) -> (B, P, W, H) -> .... -> (B, P, W, H) ,(B, P, W, H)]\n",
    "    # we would record the variance of each batch on the location (W,H)\n",
    "    error_information = None\n",
    "    clim = model.clim\n",
    "    \n",
    "    start = batch[0:model.history_length] # start must be a list    \n",
    "    \n",
    "    snap_line = []\n",
    "    if (snap_index is not None) and (0 not in [len(t) for t in snap_index]):  \n",
    "        for i,tensor in enumerate(start):\n",
    "            # each tensor is like (B, 70, 32, 64) or (B, P, Z, W, H)\n",
    "            snap_line.append([len(snap_line), get_tensor_value(tensor,snap_index, time=model.history_length),'input'])\n",
    "    \n",
    "    # approx_epsilon_lists = []\n",
    "    # last_pred = last_target = None\n",
    "    i = model.history_length\n",
    "    while i<len(batch):#for i in range(model.history_length,len(batch), model.pred_len):# i now is the target index\n",
    "        \n",
    "        if do_error_propagration_monitor and i < do_error_propagration_monitor:\n",
    "            # in this mode, we will concat all batch to accelarate computing. so far, only support batch=[X_{t},X_{t+1},X_{t+2}]\n",
    "            monitor_batch = torch.stack(batch[:do_error_propagration_monitor],1) #[X_{t},X_{t+1},...,X_{t+2}]-> (B,T,P,W,H)\n",
    "            ltmv_preds, ltmv_trues,error_information = once_forward_error_evaluation(model,monitor_batch)\n",
    "            i = do_error_propagration_monitor-1\n",
    "            start = [ltmv_preds[:,-1]]\n",
    "            time_list  = range(1,do_error_propagration_monitor)\n",
    "            ltmv_trues = ltmv_trues.transpose(0,1) #(B,T,P,W,H) -> (T,B,P,W,H)\n",
    "            ltmv_preds = ltmv_preds.transpose(0,1) #(B,T,P,W,H) -> (T,B,P,W,H)\n",
    "        else:\n",
    "            end = batch[i:i+model.pred_len]\n",
    "            end = end[0] if len(end) == 1 else end\n",
    "            print(start[-1][0].mean(0))\n",
    "            ltmv_pred, target, extra_loss, extra_info_from_model_list, start = once_forward(model,i,start,end,dataset,time_step_1_mode)\n",
    "            print(ltmv_pred[0].mean(0))\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#uvth = model.UVTPHSCp2uvth(torch.cat([UVTPHSC,p],1))\n",
    "#uvtph= torch.cat([uvth[:,:42], p, uvth[:,42:]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68f70256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "==================\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    UVTPHSC = batch[0]\n",
    "    with torch.cuda.amp.autocast(enabled=model.use_amp):\n",
    "        p    = model.UVTPHSC2p(UVTPHSC)\n",
    "        x    = torch.cat([UVTPHSC,p],1)\n",
    "        print(x.isnan().any())\n",
    "        \n",
    "        shape = x.shape\n",
    "        #print(x.shape)\n",
    "        # argue the w resolution.\n",
    "        pad = model.UVTPHSCp2uvth.backbone.get_w_resolution_pad(shape)\n",
    "        if pad is not None:x = F.pad(x.flatten(0,1),(0,0,pad,pad),mode='replicate').reshape(*shape[:-2],-1,shape[-1])\n",
    "        #print(x.shape)\n",
    "        B = x.shape[0]\n",
    "        ot_shape = x.shape[2:]\n",
    "        x = x.reshape(B,-1,*model.UVTPHSCp2uvth.backbone.img_size)# (B, p, z, h, w) or (B, p, h, w)\n",
    "        #timer.restart(level=0)\n",
    "        #print(torch.std_mean(x))\n",
    "        print(x.isnan().any())\n",
    "        \n",
    "        #x = model.UVTPHSCp2uvth.backbone.forward_features(x);#print(torch.std_mean(x))\n",
    "        x = model.UVTPHSCp2uvth.backbone.patch_embed(x)\n",
    "        print(x.isnan().any())\n",
    "        x += model.UVTPHSCp2uvth.backbone.pos_embed\n",
    "        print(x.isnan().any())\n",
    "        x = model.UVTPHSCp2uvth.backbone.pos_drop(x)\n",
    "        print(x.isnan().any())\n",
    "        #print(torch.std_mean(x))\n",
    "        print(\"==================\")\n",
    "        if not model.UVTPHSCp2uvth.backbone.checkpoint_activations:\n",
    "            for num,blk in enumerate(model.UVTPHSCp2uvth.backbone.blocks):\n",
    "                x = blk(x);#print(torch.std_mean(x))\n",
    "                print(x.isnan().any())\n",
    "                if num==2:break\n",
    "        else:\n",
    "            x = checkpoint_sequential(model.UVTPHSCp2uvth.backbone.blocks, 4, x)\n",
    "#         print(\"==================\")\n",
    "#         x = model.UVTPHSCp2uvth.backbone.norm(x).transpose(1, 2);\n",
    "#         print(x.isnan().any())\n",
    "#         x = torch.reshape(x, [-1, model.UVTPHSCp2uvth.backbone.embed_dim, *model.UVTPHSCp2uvth.backbone.final_shape])\n",
    "#         print(x.isnan().any())\n",
    "        #timer.record('forward_features',level=0)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.final_dropout(x)\n",
    "        \n",
    "        \n",
    "#         #timer.record('final_dropout',level=0)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.pre_logits(x);#print(torch.std_mean(x))\n",
    "        \n",
    "#         print(x.isnan().any())\n",
    "#         #timer.record('pre_logits',level=0)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.head(x)  # print(torch.std_mean(x))\n",
    "        \n",
    "#         print(x.isnan().any())\n",
    "#         if model.UVTPHSCp2uvth.backbone.history_length >1:\n",
    "#             x = x.flatten(1,2).transpose(1,-1)\n",
    "#             x = model.UVTPHSCp2uvth.backbone.last_Linear_layer(x)\n",
    "#             x = x.transpose(1,-1)\n",
    "#             ot_shape=ot_shape[1:]\n",
    "#         #timer.record('head',level=0)\n",
    "#         x = x.reshape(B,-1,*ot_shape)\n",
    "#         if pad is not None:\n",
    "#             x = x[...,pad:-pad,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "717f646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tensor = x.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0721c631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveFourierNeuralOperator(\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.UVTPHSCp2uvth.backbone.blocks[3].filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3e04522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41.9455, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.UVTPHSCp2uvth.backbone.blocks[3].norm1.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07d33229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3199,  0.2006, -1.3664,  ..., -1.3705,  0.4756,  1.6072],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.UVTPHSCp2uvth.backbone.blocks[3].norm1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1803b0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-318.6756, device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c9b8ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(enabled=model.use_amp):\n",
    "        x = start_tensor\n",
    "        residual = x;print(x.isnan().any())\n",
    "        #timer.restart(1)\n",
    "        x = model.UVTPHSCp2uvth.backbone.blocks[3].norm1(x);print(x.isnan().any())\n",
    "        #timer.record('norm1','forward_features',1)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.blocks[3].filter(x);print(x.isnan().any())\n",
    "#         #timer.record('filter','forward_features',1)\n",
    "#         if model.UVTPHSCp2uvth.backbone.blocks[3].double_skip:\n",
    "#             x += residual\n",
    "#             residual = x;\n",
    "#         #timer.record('residual','forward_features',1)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.blocks[3].norm2(x);print(x.isnan().any())\n",
    "#         #timer.record('norm2','forward_features',1)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.blocks[3].mlp(x);print(x.isnan().any())\n",
    "#         #timer.record('mlp','forward_features',1)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.blocks[3].drop_path(x);print(x.isnan().any())\n",
    "#         #timer.record('drop_path','forward_features',1)\n",
    "#         x += residual\n",
    "#         #timer.record('residual','forward_features',1)\n",
    "#         #out = model.UVTPHSCp2uvth.backbone.blocks[3](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c997e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(\n",
       "  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (filter): AdaptiveFourierNeuralOperator(\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (drop_path): Identity()\n",
       "  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (mlp): Mlp(\n",
       "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (act): GELU(approximate='none')\n",
       "    (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.UVTPHSCp2uvth.backbone.blocks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06015429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-33.2812, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6923f1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "312ca9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method AFNONet.forward_features of AFNONet(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(86, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (filter): AdaptiveFourierNeuralOperator(\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): AdaptiveAvgPool1d(output_size=1024)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Sequential(\n",
       "    (conv1): ConvTranspose2d(1024, 880, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act1): Tanh()\n",
       "    (conv2): ConvTranspose2d(880, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act2): Tanh()\n",
       "  )\n",
       "  (head): ConvTranspose2d(220, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (final_dropout): Identity()\n",
       ")>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.UVTPHSCp2uvth.backbone.forward_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49d63711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CombM_UVTPHSC2p2uvth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7b24f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d256ff4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#args.dataset_kargs['cross_sample']=args.cross_sample=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f2ebbd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['batch_size']=args.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "145f9a40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['cross_sample']=args.cross_sample=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963beb83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['use_offline_data']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831b3239",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['patch_range']=(3,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959b737c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset, val_dataset, train_dataloader,val_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_and_valid_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtrain_dataset_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtrain_record_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvalid_dataset_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mvalid_record_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m logsys\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse dataset ==> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m logsys\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/train/pretrain.py:2308\u001b[0m, in \u001b[0;36mget_train_and_valid_dataset\u001b[0;34m(args, train_dataset_tensor, train_record_load, valid_dataset_tensor, valid_record_load)\u001b[0m\n\u001b[1;32m   2305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_train_and_valid_dataset\u001b[39m(args,train_dataset_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,train_record_load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,valid_dataset_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,valid_record_load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2306\u001b[0m     dataset_type   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(args\u001b[38;5;241m.\u001b[39mdataset_type) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args\u001b[38;5;241m.\u001b[39mdataset_type,\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdataset_type\n\u001b[0;32m-> 2308\u001b[0m     train_dataset  \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdataset_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2309\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mrecord_load_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_record_load\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_kargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2310\u001b[0m     val_dataset   \u001b[38;5;241m=\u001b[39m dataset_type(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,dataset_tensor\u001b[38;5;241m=\u001b[39mvalid_dataset_tensor,\n\u001b[1;32m   2311\u001b[0m                                   record_load_tensor\u001b[38;5;241m=\u001b[39mvalid_record_load,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs\u001b[38;5;241m.\u001b[39mdataset_kargs)\n\u001b[1;32m   2313\u001b[0m     train_datasampler \u001b[38;5;241m=\u001b[39m DistributedSampler(train_dataset, shuffle\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdo_train_shuffle) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdistributed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/cephdataset.py:1002\u001b[0m, in \u001b[0;36mWeathBench64x128.__init__\u001b[0;34m(self, **kargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkargs):\n\u001b[1;32m   1001\u001b[0m     use_offline_data \u001b[38;5;241m=\u001b[39m kargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_offline_data\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m-> 1002\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m use_offline_data \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkargs)\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_LunaSolarDirectly \u001b[38;5;241m=\u001b[39m  kargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_LunaSolarDirectly\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, train_dataloader,val_dataloader = get_train_and_valid_dataset(args,\n",
    "               train_dataset_tensor=None,train_record_load=None,\n",
    "               valid_dataset_tensor=None,valid_record_load=None)\n",
    "logsys.info(f\"use dataset ==> {train_dataset.__class__.__name__}\")\n",
    "logsys.info(f\"Start training for {args.epochs} epochs\")\n",
    "master_bar = logsys.create_master_bar(args.epochs)\n",
    "accu_list = ['valid_loss']\n",
    "metric_dict = logsys.initial_metric_dict(accu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f524f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['cross_sample']=args.cross_sample=1\n",
    "train_dataset.cross_sample  =1\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d02eb672",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset.cross_sample  =0\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6872d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# val_dataset.cross_sample  =0 \n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8879877",
   "metadata": {
    "code_folding": [
     4,
     7,
     10
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load everything, start_training......\r"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "start_step = 0\n",
    "data_loader = train_dataloader\n",
    "status = 'train'\n",
    "if status == 'train':\n",
    "    model.train()\n",
    "    logsys.train()\n",
    "elif status == 'valid':\n",
    "    model.eval()\n",
    "    logsys.eval()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "accumulation_steps = model.accumulation_steps # should be 16 for finetune. but I think its ok.\n",
    "half_model = next(model.parameters()).dtype == torch.float16\n",
    "\n",
    "data_cost  = []\n",
    "train_cost = []\n",
    "rest_cost  = []\n",
    "now = time.time()\n",
    "\n",
    "Fethcher   = RandomSelectPatchFetcher if( status =='train' and \\\n",
    "                                          data_loader.dataset.use_offline_data and \\\n",
    "                                          data_loader.dataset.split=='train' and \\\n",
    "                                          'Patch' in data_loader.dataset.__class__.__name__) else Datafetcher\n",
    "device     = next(model.parameters()).device\n",
    "prefetcher = Fethcher(data_loader,device)\n",
    "#raise\n",
    "batches    = len(data_loader)\n",
    "\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "\n",
    "if start_step == 0:optimizer.zero_grad()\n",
    "intervel = batches//100 + 1\n",
    "\n",
    "\n",
    "total_diff,total_num  = torch.Tensor([0]).to(device), torch.Tensor([0]).to(device)\n",
    "nan_count = 0\n",
    "Nodeloss1 = Nodeloss2 = Nodeloss12 = -1\n",
    "\n",
    "inter_b.lwrite(f\"load everything, start_{status}ing......\", end=\"\\r\")\n",
    "preds = []\n",
    "reals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31f0155e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset.cross_sample  =0\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e47fe931",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_dataset.cross_sample  = 1\n",
    "val_dataloader  = torch.utils.data.DataLoader(val_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30a04216",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ec29f67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2bee513",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_one_iter(model, batch, criterion, status, gpu, dataset):\n",
    "    iter_info_pool={}\n",
    "    loss = 0\n",
    "    diff = 0\n",
    "    random_run_step = np.random.randint(1,len(batch)) if len(batch)>1 else 0\n",
    "    time_step_1_mode=False\n",
    "    if len(batch) == 1 and isinstance(batch[0],(list,tuple)) and len(batch[0])>1:\n",
    "        batch = batch[0] # (Field, FieldDt)\n",
    "        time_step_1_mode=True\n",
    "    if model.history_length > len(batch):\n",
    "        print(f\"you want to use history={model.history_length}\")\n",
    "        print(f\"but your input batch(timesteps) only has len(batch)={len(batch)}\")\n",
    "        raise\n",
    "    pred_step = 0\n",
    "    start = batch[0:model.history_length] # start must be a list\n",
    "    ltmv_pred_record = []\n",
    "    target_record = []\n",
    "    for i in range(model.history_length,len(batch)):# i now is the target index\n",
    "        ltmv_pred, target, extra_loss, extra_info_from_model_list, start = once_forward(model,i,start,batch[i],dataset,time_step_1_mode)\n",
    "        if extra_loss !=0:\n",
    "            iter_info_pool[f'{status}_extra_loss_gpu{gpu}_timestep{i}'] = extra_loss.item()\n",
    "        for extra_info_from_model in extra_info_from_model_list:\n",
    "            for name, value in extra_info_from_model.items():\n",
    "                iter_info_pool[f'valid_on_{status}_{name}_timestep{i}'] = value\n",
    "        \n",
    "        ltmv_pred = dataset.do_normlize_data([ltmv_pred])[0]\n",
    "\n",
    "        abs_loss = criterion(ltmv_pred,target)\n",
    "        ltmv_pred_record.append(ltmv_pred)\n",
    "        target_record.append(target)\n",
    "        iter_info_pool[f'{status}_abs_loss_gpu{gpu}_timestep{i}'] =  abs_loss.item()\n",
    "        pred_step+=1\n",
    "        loss += abs_loss + extra_loss\n",
    "        diff += abs_loss\n",
    "        if model.random_time_step_train and i >= random_run_step:\n",
    "            break\n",
    "    # loss = loss/(len(batch) - 1)\n",
    "    # diff = diff/(len(batch) - 1)\n",
    "    loss = loss/pred_step\n",
    "    diff = diff/pred_step\n",
    "    return loss, diff, iter_info_pool,torch.cat(ltmv_pred_record),torch.cat(target_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4389189d",
   "metadata": {
    "code_folding": [
     4,
     7,
     10,
     20,
     43,
     82,
     98
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:000 iter:[   36]/[55514] [TimeLeng]:2 GPU:[0] abs_loss:1.18 loss:1.18 cost:[Date]:3.1e-03 [Train]:7.8e+00 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m#print([p.shape for t in batch for p in t])\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m         loss, abs_loss, iter_info_pool,pred,real \u001b[38;5;241m=\u001b[39m\u001b[43mrun_one_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m iter_info_pool\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m     99\u001b[0m iter_info_pool[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_loss_gpu\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]     \u001b[38;5;241m=\u001b[39m  loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn [41], line 19\u001b[0m, in \u001b[0;36mrun_one_iter\u001b[0;34m(model, batch, criterion, status, gpu, dataset)\u001b[0m\n\u001b[1;32m     17\u001b[0m target_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mhistory_length,\u001b[38;5;28mlen\u001b[39m(batch)):\u001b[38;5;66;03m# i now is the target index\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     ltmv_pred, target, extra_loss, extra_info_from_model_list, start \u001b[38;5;241m=\u001b[39m \u001b[43monce_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_step_1_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_loss \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     21\u001b[0m         iter_info_pool[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_extra_loss_gpu\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_timestep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/train/pretrain.py:393\u001b[0m, in \u001b[0;36monce_forward\u001b[0;34m(model, i, start, end, dataset, time_step_1_mode)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m once_forward_patch_N2M(model,i,start,end,dataset,time_step_1_mode)\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43monce_forward_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_step_1_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_time_stamp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39muse_time_stamp:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m once_forward_with_timestamp(model,i,start,end,dataset,time_step_1_mode)\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/train/pretrain.py:279\u001b[0m, in \u001b[0;36monce_forward_patch\u001b[0;34m(model, i, start, end, dataset, time_step_1_mode)\u001b[0m\n\u001b[1;32m    275\u001b[0m     normlized_Field \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(normlized_Field)\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39minput_noise_std\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (time_stamp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) :\n\u001b[0;32m--> 279\u001b[0m     out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormlized_Field\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     out   \u001b[38;5;241m=\u001b[39m model(normlized_Field)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/patch_model.py:970\u001b[0m, in \u001b[0;36mPOverLapTimePosVallinaViT.forward\u001b[0;34m(self, x, time_stamp, pos_stamp)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[1;32m    969\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x,time_stamp)\n\u001b[0;32m--> 970\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatches_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/patch_model.py:679\u001b[0m, in \u001b[0;36mAutoPatchOverLapModel3D.patches_to_image\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    672\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B,X0,X1,X2,P,\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range)\n\u001b[1;32m    673\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(x,(\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,   \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,   \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,   \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    675\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    676\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    677\u001b[0m     )) \u001b[38;5;66;03m#(B, X0, X1, X2, P, p0,p1,p2) --> (B, Y0, Y1, Y2, P, p0,p1,p2)\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    680\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:,      :, yes[\u001b[38;5;241m1\u001b[39m],      :,:, pes[\u001b[38;5;241m1\u001b[39m],:  ]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    681\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:,      :,      :, yes[\u001b[38;5;241m2\u001b[39m],:, pes[\u001b[38;5;241m2\u001b[39m]    ]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "start_step = 0\n",
    "data_loader = train_dataloader\n",
    "status = 'valid'\n",
    "if status == 'train':\n",
    "    model.train()\n",
    "    logsys.train()\n",
    "elif status == 'valid':\n",
    "    model.eval()\n",
    "    logsys.eval()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "accumulation_steps = model.accumulation_steps # should be 16 for finetune. but I think its ok.\n",
    "half_model = next(model.parameters()).dtype == torch.float16\n",
    "\n",
    "data_cost  = []\n",
    "train_cost = []\n",
    "rest_cost  = []\n",
    "now = time.time()\n",
    "\n",
    "Fethcher   = RandomSelectPatchFetcher if( status =='train' and \\\n",
    "                                          data_loader.dataset.use_offline_data and \\\n",
    "                                          data_loader.dataset.split=='train' and \\\n",
    "                                          'Patch' in data_loader.dataset.__class__.__name__) else Datafetcher\n",
    "device     = next(model.parameters()).device\n",
    "prefetcher = Fethcher(data_loader,device)\n",
    "#raise\n",
    "batches    = len(data_loader)\n",
    "\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "\n",
    "if start_step == 0:optimizer.zero_grad()\n",
    "intervel = batches//100 + 1\n",
    "\n",
    "\n",
    "total_diff,total_num  = torch.Tensor([0]).to(device), torch.Tensor([0]).to(device)\n",
    "nan_count = 0\n",
    "Nodeloss1 = Nodeloss2 = Nodeloss12 = -1\n",
    "\n",
    "inter_b.lwrite(f\"load everything, start_{status}ing......\", end=\"\\r\")\n",
    "preds = []\n",
    "reals = []\n",
    "while inter_b.update_step():\n",
    "    #if inter_b.now>10:break\n",
    "    step = inter_b.now\n",
    "    batch = prefetcher.next()\n",
    "    #print(batch[0].shape)\n",
    "    #raise\n",
    "    if step < start_step:continue\n",
    "    #batch = data_loader.dataset.do_normlize_data(batch)\n",
    "\n",
    "    batch = make_data_regular(batch,half_model)\n",
    "    \n",
    "    \n",
    "    #if len(batch)==1:batch = batch[0] # for Field -> Field_Dt dataset\n",
    "    data_cost.append(time.time() - now);now = time.time()\n",
    "    if status == 'train':\n",
    "        if hasattr(model,'set_step'):model.set_step(step=step,epoch=epoch)\n",
    "        if hasattr(model,'module') and hasattr(model.module,'set_step'):model.module.set_step(step=step,epoch=epoch)\n",
    "        if model.train_mode =='pretrain':\n",
    "            time_truncate = max(min(epoch//3,data_loader.dataset.time_step),2)\n",
    "            batch=batch[:model.history_length -1 + time_truncate]\n",
    "\n",
    "        # the normal initial method will cause numerial explore by using timestep > 4 senenrio.\n",
    "        if model.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss, abs_loss, iter_info_pool =run_one_iter(model, batch, criterion, 'train', gpu, data_loader.dataset)\n",
    "        else:\n",
    "            loss, abs_loss, iter_info_pool =run_one_iter(model, batch, criterion, 'train', gpu, data_loader.dataset)\n",
    "        loss, nan_count, skip = nan_diagnose_weight(model,loss,nan_count,logsys)\n",
    "        if skip:continue\n",
    "        loss /= accumulation_steps\n",
    "\n",
    "        if model.use_amp:\n",
    "            loss_scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if model.clip_grad:\n",
    "            if model.use_amp:\n",
    "                assert accumulation_steps == 1\n",
    "                loss_scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), model.clip_grad)\n",
    "\n",
    "        if (step+1) % accumulation_steps == 0:\n",
    "            if model.use_amp:\n",
    "\n",
    "                loss_scaler.step(optimizer)\n",
    "                loss_scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            #print([p.shape for t in batch for p in t])\n",
    "            loss, abs_loss, iter_info_pool,pred,real =run_one_iter(model, batch, criterion, status, gpu, data_loader.dataset)\n",
    "    iter_info_pool={}\n",
    "    iter_info_pool[f'{status}_loss_gpu{gpu}']     =  loss.item()\n",
    "    iter_info_pool[f'{status}_Nodeloss1_gpu{gpu}'] = Nodeloss1\n",
    "    iter_info_pool[f'{status}_Nodeloss12_gpu{gpu}'] = Nodeloss12\n",
    "    iter_info_pool[f'{status}_Nodeloss2_gpu{gpu}'] = Nodeloss2\n",
    "    total_diff  += abs_loss.item()\n",
    "    #total_num   += len(batch) - 1 #batch \n",
    "    total_num   += 1 \n",
    "\n",
    "    train_cost.append(time.time() - now);now = time.time()\n",
    "    time_step_now = len(batch)\n",
    "    outstring=(f\"epoch:{epoch:03d} iter:[{step:5d}]/[{len(data_loader)}] [TimeLeng]:{time_step_now:} GPU:[{gpu}] abs_loss:{abs_loss.item():.2f} loss:{loss.item():.2f} cost:[Date]:{np.mean(data_cost):.1e} [Train]:{np.mean(train_cost):.1e} \")\n",
    "    #print(data_loader.dataset.record_load_tensor.mean().item())\n",
    "    data_cost  = []\n",
    "    train_cost = []\n",
    "    rest_cost = []\n",
    "    inter_b.lwrite(outstring, end=\"\\r\")\n",
    "    preds.append(pred.detach().cpu())\n",
    "    reals.append(real.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b6952",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master_bar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmaster_bar\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m<\u001b[39m start_epoch:\u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m):model\u001b[38;5;241m.\u001b[39mset_epoch(epoch\u001b[38;5;241m=\u001b[39mepoch,epoch_total\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mepochs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master_bar' is not defined"
     ]
    }
   ],
   "source": [
    "# for epoch in mastera_bar:\n",
    "#     if epoch < start_epoch:continue\n",
    "#     if hasattr(model,'set_epoch'):model.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "#     if hasattr(model,'module') and hasattr(model.module,'set_epoch'):model.module.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "#     logsys.record('learning rate',optimizer.param_groups[0]['lr'],epoch, epoch_flag='epoch')\n",
    "#     train_loss = run_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,logsys,'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e3a26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset_tensor=None;\n",
    "train_record_load=None;\n",
    "valid_dataset_tensor=None;\n",
    "valid_record_load=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b458ea",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =======================> start training <==========================\n",
    "print(f\"entering {args.mode} training in {next(model.parameters()).device}\")\n",
    "now_best_path = SAVE_PATH / 'backbone.best.pt'\n",
    "latest_ckpt_p = SAVE_PATH / 'pretrain_latest.pt'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, train_dataloader,val_dataloader = get_train_and_valid_dataset(args,\n",
    "               train_dataset_tensor=train_dataset_tensor,train_record_load=train_record_load,\n",
    "               valid_dataset_tensor=valid_dataset_tensor,valid_record_load=valid_record_load)\n",
    "logsys.info(f\"use dataset ==> {train_dataset.__class__.__name__}\")\n",
    "logsys.info(f\"Start training for {args.epochs} epochs\")\n",
    "metric_list = ['loss']\n",
    "master_bar        = logsys.create_master_bar(args.epochs)\n",
    "master_bar.set_multiply_graph(figsize=(9,3),engine=[['plot','plot']],labels=[metric_list])\n",
    "for epoch in master_bar:\n",
    "    if epoch < start_epoch:continue\n",
    "    if hasattr(model,'set_epoch'):model.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "    if hasattr(model,'module') and hasattr(model.module,'set_epoch'):model.module.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "    logsys.record('learning rate',optimizer.param_groups[0]['lr'],epoch)\n",
    "    train_loss = run_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,logsys,'train')\n",
    "    if (not args.more_epoch_train) and (lr_scheduler is not None):lr_scheduler.step(epoch)\n",
    "    #torch.cuda.empty_cache()\n",
    "    #train_loss = single_step_evaluate(train_dataloader, model, criterion,epoch,logsys,status='train') if 'small' in args.train_set else -1\n",
    "    val_loss   = run_one_epoch(epoch, start_step, model, criterion, val_dataloader, optimizer, loss_scaler,logsys,'valid')\n",
    "\n",
    "    if (not args.distributed) or (args.rank == 0 and local_rank == 0) :\n",
    "        logsys.info(f\"Epoch {epoch} | Train loss: {train_loss:.6f}, Val loss: {val_loss:.6f}\")\n",
    "        logsys.record('train', train_loss, epoch)\n",
    "        logsys.record('valid', val_loss, epoch)\n",
    "        if use_wandb:wandb.log({\"epoch\":epoch,'train':train_loss,'valid':val_loss})\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            if epoch > args.epochs//10:\n",
    "                logsys.info(f\"saving best model ....\")\n",
    "                save_model(model, path=now_best_path, only_model=True)\n",
    "                logsys.info(f\"done;\")\n",
    "            #if last_best_path is not None:os.system(f\"rm {last_best_path}\")\n",
    "            #last_best_path= now_best_path\n",
    "            logsys.info(f\"The best accu is {val_loss}\")\n",
    "        logsys.record('best_loss', min_loss, epoch)\n",
    "        update_experiment_info(experiment_hub_path,epoch,args)\n",
    "        if epoch>args.save_warm_up:\n",
    "            logsys.info(f\"saving latest model ....\")\n",
    "            save_model(model, epoch+1, 0, optimizer, lr_scheduler, loss_scaler, min_loss, latest_ckpt_p)\n",
    "            logsys.info(f\"done ....\")\n",
    "\n",
    "if os.path.exists(now_best_path) and args.do_final_fourcast:\n",
    "    logsys.info(f\"we finish training, then start test on the best checkpoint {now_best_path}\")\n",
    "    start_epoch, start_step, min_loss = load_model(model.module if args.distributed else model, path=now_best_path, only_model=True)\n",
    "    run_fourcast(args, model,logsys)\n",
    "if use_wandb:wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fbe32",
   "metadata": {
    "code_folding": [
     0,
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if local_rank == 0:\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "\n",
    "master_bar        = logsys.create_master_bar(args.epochs)\n",
    "last_best_path = None\n",
    "for epoch in master_bar:\n",
    "    if epoch < start_epoch:continue\n",
    "    train_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,lr_scheduler, min_loss,logsys)\n",
    "    lr_scheduler.step(epoch)\n",
    "    #torch.cuda.empty_cache()\n",
    "    train_loss = single_step_evaluate(train_dataloader, model, criterion,epoch,logsys)\n",
    "    #train_loss = -1\n",
    "    val_loss   = single_step_evaluate(val_dataloader, model, criterion,epoch,logsys)\n",
    "\n",
    "    if rank == 0 and local_rank == 0:\n",
    "        print(f\"Epoch {epoch} | Train loss: {train_loss:.6f}, Val loss: {val_loss:.6f}\")\n",
    "        logsys.record('train', train_loss, epoch)\n",
    "        logsys.record('valid', val_loss, epoch)\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print(f\"saving best model ....\")\n",
    "            now_best_path = SAVE_PATH / f'backbone.best.pt'\n",
    "            if epoch>args.save_warm_up:save_model(model, path=now_best_path, only_model=True)\n",
    "            #if last_best_path is not None:os.system(f\"rm {last_best_path}\")\n",
    "            #last_best_path= now_best_path\n",
    "            print(f\"done; the best accu is {val_loss}\")\n",
    "        logsys.record('best_loss', min_loss, epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c43ef",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    ngpus = ngpus_per_node = torch.cuda.device_count()\n",
    "    args.world_size = -1\n",
    "    args.dist_file  = None\n",
    "    args.rank       = 0\n",
    "    args.dist_backend = \"nccl\"\n",
    "    args.multiprocessing_distributed = ngpus>1\n",
    "    if not hasattr(args,'train_set'):args.train_set='large'\n",
    "    ip = os.environ.get(\"MASTER_ADDR\", \"127.0.0.1\")\n",
    "    port = os.environ.get(\"MASTER_PORT\", \"54247\")\n",
    "    hosts = int(os.environ.get(\"WORLD_SIZE\", \"1\"))  # number of nodes\n",
    "    rank = int(os.environ.get(\"RANK\", \"0\"))  # node id\n",
    "    gpus = torch.cuda.device_count()  # gpus per node\n",
    "    args.dist_url = f\"tcp://{ip}:{port}\"\n",
    "    if args.world_size == -1 and \"SLURM_NPROCS\" in os.environ:\n",
    "        args.world_size = int(os.environ[\"SLURM_NPROCS\"])\n",
    "        args.rank       = int(os.environ[\"SLURM_PROCID\"])\n",
    "        jobid           = os.environ[\"SLURM_JOBID\"]\n",
    "\n",
    "        hostfile        = \"dist_url.\" + jobid  + \".txt\"\n",
    "        if args.dist_file is not None:\n",
    "            args.dist_url = \"file://{}.{}\".format(os.path.realpath(args.dist_file), jobid)\n",
    "        elif args.rank == 0:\n",
    "            import socket\n",
    "            ip = socket.gethostbyname(socket.gethostname())\n",
    "            port = find_free_port()\n",
    "            args.dist_url = \"tcp://{}:{}\".format(ip, port)\n",
    "            #with open(hostfile, \"w\") as f:f.write(args.dist_url)\n",
    "        else:\n",
    "            import os\n",
    "            import time\n",
    "            while not os.path.exists(hostfile):\n",
    "                time.sleep(1)\n",
    "            with open(hostfile, \"r\") as f:\n",
    "                args.dist_url = f.read()\n",
    "        print(\"dist-url:{} at PROCID {} / {}\".format(args.dist_url, args.rank, args.world_size))\n",
    "    else:\n",
    "        args.world_size = 1\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "    train_dataset_tensor=valid_dataset_tensor=None\n",
    "\n",
    "    print(\"======== loading data ==========\")\n",
    "    if 'small' in args.train_set:\n",
    "        if not args.fourcast:\n",
    "            train_dataset_tensor = load_small_dataset_in_memory('train').share_memory_()\n",
    "            valid_dataset_tensor = load_small_dataset_in_memory('valid').share_memory_()\n",
    "        else:\n",
    "            train_dataset_tensor = load_small_dataset_in_memory('test').share_memory_()\n",
    "            valid_dataset_tensor = None\n",
    "    else:\n",
    "        if args.fourcast:\n",
    "            train_dataset_tensor = load_test_dataset_in_memory(years=[2018],root=\"/nvme/zhangtianning/datasets/ERA5\").share_memory_()\n",
    "            valid_dataset_tensor = None\n",
    "    print(\"=======done==========\")\n",
    "    print(train_dataset_tensor.shape)\n",
    "    if args.multiprocessing_distributed:\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        torch.multiprocessing.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args,train_dataset_tensor,valid_dataset_tensor))\n",
    "    else:\n",
    "        main_worker(0, ngpus_per_node, args,train_dataset_tensor,valid_dataset_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b4e50d8356ba75a9636787f9051ee458aaf13e87df491415cc800c7b2b8a21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
