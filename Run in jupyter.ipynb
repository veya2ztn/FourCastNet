{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad518c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cephdataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab07f72",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from train.pretrain import *\n",
    "from train.pretrain import get_args\n",
    "from mltool.universal_model_util import get_model_para_detail\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d8affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/WeathBench7066PatchDataset/POverLapTimePosFEDformer.normal_select.M7-7-8_P7L3/his_28_ts_35_pretrain-2D70N_per_1_step/12_22_20_45_48-seed_2013\"\n",
    "args=get_args(os.path.join(ckpt_path,\"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863485e8",
   "metadata": {
    "code_folding": [
     7,
     12
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device: 'checkpoints/WeathBench7066PatchDataset/POverLapTimePosFEDformer.normal_select.M7-7-8_P7L3/his_28_ts_35_pretrain-2D70N_per_1_step/12_26_15_58_43-seed_2013'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m##### parse args: dataset_kargs / model_kargs / train_kargs  ###########\u001b[39;00m\n\u001b[1;32m      4\u001b[0m args\u001b[38;5;241m=\u001b[39m parse_default_args(args)\n\u001b[0;32m----> 5\u001b[0m SAVE_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mget_ckpt_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m SAVE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m args\u001b[38;5;241m.\u001b[39mSAVE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(SAVE_PATH)\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/train/pretrain.py:1506\u001b[0m, in \u001b[0;36mget_ckpt_path\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1505\u001b[0m     SAVE_PATH \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatasetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTIME_NOW\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1506\u001b[0m     \u001b[43mSAVE_PATH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SAVE_PATH\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: 'checkpoints/WeathBench7066PatchDataset/POverLapTimePosFEDformer.normal_select.M7-7-8_P7L3/his_28_ts_35_pretrain-2D70N_per_1_step/12_26_15_58_43-seed_2013'"
     ]
    }
   ],
   "source": [
    "args.use_wandb=0\n",
    "args.gpu = args.local_rank = gpu  = local_rank = 0\n",
    "##### parse args: dataset_kargs / model_kargs / train_kargs  ###########\n",
    "args= parse_default_args(args)\n",
    "SAVE_PATH = get_ckpt_path(args)\n",
    "SAVE_PATH = \"debug\"\n",
    "args.SAVE_PATH = str(SAVE_PATH)\n",
    "#args.pretrain_weight = os.path.join(args.SAVE_PATH,'pretrain_latest.pt')\n",
    "########## inital log ###################\n",
    "logsys = create_logsys(args,False)\n",
    "\n",
    "\n",
    "if args.distributed:\n",
    "    if args.dist_url == \"env://\" and args.rank == -1:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "    if args.multiprocessing_distributed:\n",
    "        # For multiprocessing distributed training, rank needs to be the\n",
    "        # global rank among all the processes\n",
    "        args.rank = args.rank * ngpus_per_node + local_rank\n",
    "    logsys.info(f\"start init_process_group,backend={args.dist_backend}, init_method={args.dist_url},world_size={args.world_size}, rank={args.rank}\")\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,world_size=args.world_size, rank=args.rank)\n",
    "\n",
    "model           = build_model(args)\n",
    "#param_groups    = timm.optim.optim_factory.add_weight_decay(model, args.weight_decay)\n",
    "optimizer,lr_scheduler,criterion = build_optimizer(args,model)\n",
    "loss_scaler     = torch.cuda.amp.GradScaler(enabled=True)\n",
    "logsys.info(f'use lr_scheduler:{lr_scheduler}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c2aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.join(ckpt_path,\"pretrain_latest.pt\")\n",
    "args.pretrain_weight = pretrain_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287c52be",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 14:21:47,102 loading weight from checkpoints/WeathBench7066PatchDataset/POverLapTimePosFEDformer.normal_select.M7-7-8_P7L3/his_28_ts_35_pretrain-2D70N_per_1_step/12_22_20_45_48-seed_2013/pretrain_latest.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from checkpoints/WeathBench7066PatchDataset/POverLapTimePosFEDformer.normal_select.M7-7-8_P7L3/his_28_ts_35_pretrain-2D70N_per_1_step/12_22_20_45_48-seed_2013/pretrain_latest.pt...........\n",
      "loading model weight success...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 14:21:48,625 done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading optimizer weight success...........\n",
      "loading lr_scheduler weight success...........\n",
      "loading loss_scaler weight success...........\n",
      "loading model success...........\n"
     ]
    }
   ],
   "source": [
    "logsys.info(f\"loading weight from {args.pretrain_weight}\")\n",
    "start_epoch, start_step, min_loss = load_model(model.module if args.distributed else model, optimizer, lr_scheduler, loss_scaler, path=args.pretrain_weight, \n",
    "                    only_model= (args.mode=='fourcast') or (args.mode=='finetune' and not args.continue_train) ,loc = 'cuda:{}'.format(args.gpu))\n",
    "if args.more_epoch_train:\n",
    "    assert args.pretrain_weight\n",
    "    print(f\"detect more epoch training, we will do a copy processing for {args.pretrain_weight}\")\n",
    "    os.system(f'cp {args.pretrain_weight} {args.pretrain_weight}-epoch{start_epoch}')\n",
    "logsys.info(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d256ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.dataset_kargs['cross_sample']=args.cross_sample=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b06f15",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7f2ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_kargs['batch_size']=args.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "145f9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_kargs['cross_sample']=args.cross_sample=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "963beb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_kargs['use_offline_data']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "831b3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_kargs['patch_range']=(3,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3932927e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959b737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use offline data mode <2>: train/valid/test use offline data\n",
      "use dataset in datasets/weatherbench_6hour\n",
      "load data from datasets/weatherbench_6hour/train_2D70N.npy\n",
      "notice we will use around_index(26, 64, 2, 7, 7) to patch data\n",
      "use offline data mode <2>: train/valid/test use offline data\n",
      "use dataset in datasets/weatherbench_6hour\n",
      "load data from datasets/weatherbench_6hour/valid_2D70N.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 14:22:27,327 use dataset ==> WeathBench7066PatchDataset\n",
      "2022-12-26 14:22:27,328 Start training for 500 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notice we will use around_index(26, 64, 2, 7, 7) to patch data\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, train_dataloader,val_dataloader = get_train_and_valid_dataset(args,\n",
    "               train_dataset_tensor=None,train_record_load=None,\n",
    "               valid_dataset_tensor=None,valid_record_load=None)\n",
    "logsys.info(f\"use dataset ==> {train_dataset.__class__.__name__}\")\n",
    "logsys.info(f\"Start training for {args.epochs} epochs\")\n",
    "master_bar = logsys.create_master_bar(args.epochs)\n",
    "accu_list = ['valid_loss']\n",
    "metric_dict = logsys.initial_metric_dict(accu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be74f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f524f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_kargs['cross_sample']=args.cross_sample=1\n",
    "train_dataset.cross_sample  =1\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d02eb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.cross_sample  =0\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6872d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset.cross_sample  =0 \n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8879877",
   "metadata": {
    "code_folding": [
     4,
     7,
     10
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m start_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[43mval_dataloader\u001b[49m\n\u001b[1;32m      4\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "start_step = 0\n",
    "data_loader = val_dataloader\n",
    "status = 'valid'\n",
    "if status == 'train':\n",
    "    model.train()\n",
    "    logsys.train()\n",
    "elif status == 'valid':\n",
    "    model.eval()\n",
    "    logsys.eval()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "accumulation_steps = model.accumulation_steps # should be 16 for finetune. but I think its ok.\n",
    "half_model = next(model.parameters()).dtype == torch.float16\n",
    "\n",
    "data_cost  = []\n",
    "train_cost = []\n",
    "rest_cost  = []\n",
    "now = time.time()\n",
    "\n",
    "Fethcher   = RandomSelectPatchFetcher if( status =='train' and \\\n",
    "                                          data_loader.dataset.use_offline_data and \\\n",
    "                                          data_loader.dataset.split=='train' and \\\n",
    "                                          'Patch' in data_loader.dataset.__class__.__name__) else Datafetcher\n",
    "device     = next(model.parameters()).device\n",
    "prefetcher = Fethcher(data_loader,device)\n",
    "#raise\n",
    "batches    = len(data_loader)\n",
    "\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "\n",
    "if start_step == 0:optimizer.zero_grad()\n",
    "intervel = batches//100 + 1\n",
    "\n",
    "\n",
    "total_diff,total_num  = torch.Tensor([0]).to(device), torch.Tensor([0]).to(device)\n",
    "nan_count = 0\n",
    "Nodeloss1 = Nodeloss2 = Nodeloss12 = -1\n",
    "\n",
    "inter_b.lwrite(f\"load everything, start_{status}ing......\", end=\"\\r\")\n",
    "preds = []\n",
    "reals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31f0155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.cross_sample  =0\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e47fe931",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.cross_sample  = 1\n",
    "val_dataloader  = torch.utils.data.DataLoader(val_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30a04216",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ec29f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2bee513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_iter(model, batch, criterion, status, gpu, dataset):\n",
    "    iter_info_pool={}\n",
    "    loss = 0\n",
    "    diff = 0\n",
    "    random_run_step = np.random.randint(1,len(batch)) if len(batch)>1 else 0\n",
    "    time_step_1_mode=False\n",
    "    if len(batch) == 1 and isinstance(batch[0],(list,tuple)) and len(batch[0])>1:\n",
    "        batch = batch[0] # (Field, FieldDt)\n",
    "        time_step_1_mode=True\n",
    "    if model.history_length > len(batch):\n",
    "        print(f\"you want to use history={model.history_length}\")\n",
    "        print(f\"but your input batch(timesteps) only has len(batch)={len(batch)}\")\n",
    "        raise\n",
    "    pred_step = 0\n",
    "    start = batch[0:model.history_length] # start must be a list\n",
    "    ltmv_pred_record = []\n",
    "    target_record = []\n",
    "    for i in range(model.history_length,len(batch)):# i now is the target index\n",
    "        ltmv_pred, target, extra_loss, extra_info_from_model_list, start = once_forward(model,i,start,batch[i],dataset,time_step_1_mode)\n",
    "        if extra_loss !=0:\n",
    "            iter_info_pool[f'{status}_extra_loss_gpu{gpu}_timestep{i}'] = extra_loss.item()\n",
    "        for extra_info_from_model in extra_info_from_model_list:\n",
    "            for name, value in extra_info_from_model.items():\n",
    "                iter_info_pool[f'valid_on_{status}_{name}_timestep{i}'] = value\n",
    "        \n",
    "        ltmv_pred = dataset.do_normlize_data([ltmv_pred])[0]\n",
    "\n",
    "        abs_loss = criterion(ltmv_pred,target)\n",
    "        ltmv_pred_record.append(ltmv_pred)\n",
    "        target_record.append(target)\n",
    "        iter_info_pool[f'{status}_abs_loss_gpu{gpu}_timestep{i}'] =  abs_loss.item()\n",
    "        pred_step+=1\n",
    "        loss += abs_loss + extra_loss\n",
    "        diff += abs_loss\n",
    "        if model.random_time_step_train and i >= random_run_step:\n",
    "            break\n",
    "    # loss = loss/(len(batch) - 1)\n",
    "    # diff = diff/(len(batch) - 1)\n",
    "    loss = loss/pred_step\n",
    "    diff = diff/pred_step\n",
    "    return loss, diff, iter_info_pool,torch.cat(ltmv_pred_record),torch.cat(target_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4389189d",
   "metadata": {
    "code_folding": [
     4,
     7,
     10,
     20,
     43,
     82,
     98
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:000 iter:[   36]/[55514] [TimeLeng]:2 GPU:[0] abs_loss:1.18 loss:1.18 cost:[Date]:3.1e-03 [Train]:7.8e+00 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m#print([p.shape for t in batch for p in t])\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m         loss, abs_loss, iter_info_pool,pred,real \u001b[38;5;241m=\u001b[39m\u001b[43mrun_one_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m iter_info_pool\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m     99\u001b[0m iter_info_pool[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_loss_gpu\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]     \u001b[38;5;241m=\u001b[39m  loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn [41], line 19\u001b[0m, in \u001b[0;36mrun_one_iter\u001b[0;34m(model, batch, criterion, status, gpu, dataset)\u001b[0m\n\u001b[1;32m     17\u001b[0m target_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mhistory_length,\u001b[38;5;28mlen\u001b[39m(batch)):\u001b[38;5;66;03m# i now is the target index\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     ltmv_pred, target, extra_loss, extra_info_from_model_list, start \u001b[38;5;241m=\u001b[39m \u001b[43monce_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_step_1_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_loss \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     21\u001b[0m         iter_info_pool[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_extra_loss_gpu\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_timestep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/train/pretrain.py:393\u001b[0m, in \u001b[0;36monce_forward\u001b[0;34m(model, i, start, end, dataset, time_step_1_mode)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m once_forward_patch_N2M(model,i,start,end,dataset,time_step_1_mode)\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43monce_forward_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_step_1_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_time_stamp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39muse_time_stamp:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m once_forward_with_timestamp(model,i,start,end,dataset,time_step_1_mode)\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/train/pretrain.py:279\u001b[0m, in \u001b[0;36monce_forward_patch\u001b[0;34m(model, i, start, end, dataset, time_step_1_mode)\u001b[0m\n\u001b[1;32m    275\u001b[0m     normlized_Field \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(normlized_Field)\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39minput_noise_std\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (time_stamp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) :\n\u001b[0;32m--> 279\u001b[0m     out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormlized_Field\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     out   \u001b[38;5;241m=\u001b[39m model(normlized_Field)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/patch_model.py:970\u001b[0m, in \u001b[0;36mPOverLapTimePosVallinaViT.forward\u001b[0;34m(self, x, time_stamp, pos_stamp)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[1;32m    969\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x,time_stamp)\n\u001b[0;32m--> 970\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatches_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/patch_model.py:679\u001b[0m, in \u001b[0;36mAutoPatchOverLapModel3D.patches_to_image\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    672\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B,X0,X1,X2,P,\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range)\n\u001b[1;32m    673\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(x,(\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,   \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,   \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,   \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    675\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    676\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    677\u001b[0m     )) \u001b[38;5;66;03m#(B, X0, X1, X2, P, p0,p1,p2) --> (B, Y0, Y1, Y2, P, p0,p1,p2)\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    680\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:,      :, yes[\u001b[38;5;241m1\u001b[39m],      :,:, pes[\u001b[38;5;241m1\u001b[39m],:  ]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    681\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:,      :,      :, yes[\u001b[38;5;241m2\u001b[39m],:, pes[\u001b[38;5;241m2\u001b[39m]    ]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "start_step = 0\n",
    "data_loader = train_dataloader\n",
    "status = 'valid'\n",
    "if status == 'train':\n",
    "    model.train()\n",
    "    logsys.train()\n",
    "elif status == 'valid':\n",
    "    model.eval()\n",
    "    logsys.eval()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "accumulation_steps = model.accumulation_steps # should be 16 for finetune. but I think its ok.\n",
    "half_model = next(model.parameters()).dtype == torch.float16\n",
    "\n",
    "data_cost  = []\n",
    "train_cost = []\n",
    "rest_cost  = []\n",
    "now = time.time()\n",
    "\n",
    "Fethcher   = RandomSelectPatchFetcher if( status =='train' and \\\n",
    "                                          data_loader.dataset.use_offline_data and \\\n",
    "                                          data_loader.dataset.split=='train' and \\\n",
    "                                          'Patch' in data_loader.dataset.__class__.__name__) else Datafetcher\n",
    "device     = next(model.parameters()).device\n",
    "prefetcher = Fethcher(data_loader,device)\n",
    "#raise\n",
    "batches    = len(data_loader)\n",
    "\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "\n",
    "if start_step == 0:optimizer.zero_grad()\n",
    "intervel = batches//100 + 1\n",
    "\n",
    "\n",
    "total_diff,total_num  = torch.Tensor([0]).to(device), torch.Tensor([0]).to(device)\n",
    "nan_count = 0\n",
    "Nodeloss1 = Nodeloss2 = Nodeloss12 = -1\n",
    "\n",
    "inter_b.lwrite(f\"load everything, start_{status}ing......\", end=\"\\r\")\n",
    "preds = []\n",
    "reals = []\n",
    "while inter_b.update_step():\n",
    "    #if inter_b.now>10:break\n",
    "    step = inter_b.now\n",
    "    batch = prefetcher.next()\n",
    "    #print(batch[0].shape)\n",
    "    #raise\n",
    "    if step < start_step:continue\n",
    "    #batch = data_loader.dataset.do_normlize_data(batch)\n",
    "\n",
    "    batch = make_data_regular(batch,half_model)\n",
    "    \n",
    "    \n",
    "    #if len(batch)==1:batch = batch[0] # for Field -> Field_Dt dataset\n",
    "    data_cost.append(time.time() - now);now = time.time()\n",
    "    if status == 'train':\n",
    "        if hasattr(model,'set_step'):model.set_step(step=step,epoch=epoch)\n",
    "        if hasattr(model,'module') and hasattr(model.module,'set_step'):model.module.set_step(step=step,epoch=epoch)\n",
    "        if model.train_mode =='pretrain':\n",
    "            time_truncate = max(min(epoch//3,data_loader.dataset.time_step),2)\n",
    "            batch=batch[:model.history_length -1 + time_truncate]\n",
    "\n",
    "        # the normal initial method will cause numerial explore by using timestep > 4 senenrio.\n",
    "        if model.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss, abs_loss, iter_info_pool =run_one_iter(model, batch, criterion, 'train', gpu, data_loader.dataset)\n",
    "        else:\n",
    "            loss, abs_loss, iter_info_pool =run_one_iter(model, batch, criterion, 'train', gpu, data_loader.dataset)\n",
    "        loss, nan_count, skip = nan_diagnose_weight(model,loss,nan_count,logsys)\n",
    "        if skip:continue\n",
    "        loss /= accumulation_steps\n",
    "\n",
    "        if model.use_amp:\n",
    "            loss_scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if model.clip_grad:\n",
    "            if model.use_amp:\n",
    "                assert accumulation_steps == 1\n",
    "                loss_scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), model.clip_grad)\n",
    "\n",
    "        if (step+1) % accumulation_steps == 0:\n",
    "            if model.use_amp:\n",
    "\n",
    "                loss_scaler.step(optimizer)\n",
    "                loss_scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            #print([p.shape for t in batch for p in t])\n",
    "            loss, abs_loss, iter_info_pool,pred,real =run_one_iter(model, batch, criterion, status, gpu, data_loader.dataset)\n",
    "    iter_info_pool={}\n",
    "    iter_info_pool[f'{status}_loss_gpu{gpu}']     =  loss.item()\n",
    "    iter_info_pool[f'{status}_Nodeloss1_gpu{gpu}'] = Nodeloss1\n",
    "    iter_info_pool[f'{status}_Nodeloss12_gpu{gpu}'] = Nodeloss12\n",
    "    iter_info_pool[f'{status}_Nodeloss2_gpu{gpu}'] = Nodeloss2\n",
    "    total_diff  += abs_loss.item()\n",
    "    #total_num   += len(batch) - 1 #batch \n",
    "    total_num   += 1 \n",
    "\n",
    "    train_cost.append(time.time() - now);now = time.time()\n",
    "    time_step_now = len(batch)\n",
    "    outstring=(f\"epoch:{epoch:03d} iter:[{step:5d}]/[{len(data_loader)}] [TimeLeng]:{time_step_now:} GPU:[{gpu}] abs_loss:{abs_loss.item():.2f} loss:{loss.item():.2f} cost:[Date]:{np.mean(data_cost):.1e} [Train]:{np.mean(train_cost):.1e} \")\n",
    "    #print(data_loader.dataset.record_load_tensor.mean().item())\n",
    "    data_cost  = []\n",
    "    train_cost = []\n",
    "    rest_cost = []\n",
    "    inter_b.lwrite(outstring, end=\"\\r\")\n",
    "    preds.append(pred.detach().cpu())\n",
    "    reals.append(real.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b6952",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master_bar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmaster_bar\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m<\u001b[39m start_epoch:\u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m):model\u001b[38;5;241m.\u001b[39mset_epoch(epoch\u001b[38;5;241m=\u001b[39mepoch,epoch_total\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mepochs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master_bar' is not defined"
     ]
    }
   ],
   "source": [
    "# for epoch in mastera_bar:\n",
    "#     if epoch < start_epoch:continue\n",
    "#     if hasattr(model,'set_epoch'):model.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "#     if hasattr(model,'module') and hasattr(model.module,'set_epoch'):model.module.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "#     logsys.record('learning rate',optimizer.param_groups[0]['lr'],epoch, epoch_flag='epoch')\n",
    "#     train_loss = run_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,logsys,'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_tensor=None;\n",
    "train_record_load=None;\n",
    "valid_dataset_tensor=None;\n",
    "valid_record_load=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b458ea",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =======================> start training <==========================\n",
    "print(f\"entering {args.mode} training in {next(model.parameters()).device}\")\n",
    "now_best_path = SAVE_PATH / 'backbone.best.pt'\n",
    "latest_ckpt_p = SAVE_PATH / 'pretrain_latest.pt'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, train_dataloader,val_dataloader = get_train_and_valid_dataset(args,\n",
    "               train_dataset_tensor=train_dataset_tensor,train_record_load=train_record_load,\n",
    "               valid_dataset_tensor=valid_dataset_tensor,valid_record_load=valid_record_load)\n",
    "logsys.info(f\"use dataset ==> {train_dataset.__class__.__name__}\")\n",
    "logsys.info(f\"Start training for {args.epochs} epochs\")\n",
    "metric_list = ['loss']\n",
    "master_bar        = logsys.create_master_bar(args.epochs)\n",
    "master_bar.set_multiply_graph(figsize=(9,3),engine=[['plot','plot']],labels=[metric_list])\n",
    "for epoch in master_bar:\n",
    "    if epoch < start_epoch:continue\n",
    "    if hasattr(model,'set_epoch'):model.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "    if hasattr(model,'module') and hasattr(model.module,'set_epoch'):model.module.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "    logsys.record('learning rate',optimizer.param_groups[0]['lr'],epoch)\n",
    "    train_loss = run_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,logsys,'train')\n",
    "    if (not args.more_epoch_train) and (lr_scheduler is not None):lr_scheduler.step(epoch)\n",
    "    #torch.cuda.empty_cache()\n",
    "    #train_loss = single_step_evaluate(train_dataloader, model, criterion,epoch,logsys,status='train') if 'small' in args.train_set else -1\n",
    "    val_loss   = run_one_epoch(epoch, start_step, model, criterion, val_dataloader, optimizer, loss_scaler,logsys,'valid')\n",
    "\n",
    "    if (not args.distributed) or (args.rank == 0 and local_rank == 0) :\n",
    "        logsys.info(f\"Epoch {epoch} | Train loss: {train_loss:.6f}, Val loss: {val_loss:.6f}\")\n",
    "        logsys.record('train', train_loss, epoch)\n",
    "        logsys.record('valid', val_loss, epoch)\n",
    "        if use_wandb:wandb.log({\"epoch\":epoch,'train':train_loss,'valid':val_loss})\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            if epoch > args.epochs//10:\n",
    "                logsys.info(f\"saving best model ....\")\n",
    "                save_model(model, path=now_best_path, only_model=True)\n",
    "                logsys.info(f\"done;\")\n",
    "            #if last_best_path is not None:os.system(f\"rm {last_best_path}\")\n",
    "            #last_best_path= now_best_path\n",
    "            logsys.info(f\"The best accu is {val_loss}\")\n",
    "        logsys.record('best_loss', min_loss, epoch)\n",
    "        update_experiment_info(experiment_hub_path,epoch,args)\n",
    "        if epoch>args.save_warm_up:\n",
    "            logsys.info(f\"saving latest model ....\")\n",
    "            save_model(model, epoch+1, 0, optimizer, lr_scheduler, loss_scaler, min_loss, latest_ckpt_p)\n",
    "            logsys.info(f\"done ....\")\n",
    "\n",
    "if os.path.exists(now_best_path) and args.do_final_fourcast:\n",
    "    logsys.info(f\"we finish training, then start test on the best checkpoint {now_best_path}\")\n",
    "    start_epoch, start_step, min_loss = load_model(model.module if args.distributed else model, path=now_best_path, only_model=True)\n",
    "    run_fourcast(args, model,logsys)\n",
    "if use_wandb:wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fbe32",
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "if local_rank == 0:\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "\n",
    "master_bar        = logsys.create_master_bar(args.epochs)\n",
    "last_best_path = None\n",
    "for epoch in master_bar:\n",
    "    if epoch < start_epoch:continue\n",
    "    train_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,lr_scheduler, min_loss,logsys)\n",
    "    lr_scheduler.step(epoch)\n",
    "    #torch.cuda.empty_cache()\n",
    "    train_loss = single_step_evaluate(train_dataloader, model, criterion,epoch,logsys)\n",
    "    #train_loss = -1\n",
    "    val_loss   = single_step_evaluate(val_dataloader, model, criterion,epoch,logsys)\n",
    "\n",
    "    if rank == 0 and local_rank == 0:\n",
    "        print(f\"Epoch {epoch} | Train loss: {train_loss:.6f}, Val loss: {val_loss:.6f}\")\n",
    "        logsys.record('train', train_loss, epoch)\n",
    "        logsys.record('valid', val_loss, epoch)\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print(f\"saving best model ....\")\n",
    "            now_best_path = SAVE_PATH / f'backbone.best.pt'\n",
    "            if epoch>args.save_warm_up:save_model(model, path=now_best_path, only_model=True)\n",
    "            #if last_best_path is not None:os.system(f\"rm {last_best_path}\")\n",
    "            #last_best_path= now_best_path\n",
    "            print(f\"done; the best accu is {val_loss}\")\n",
    "        logsys.record('best_loss', min_loss, epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c43ef",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    ngpus = ngpus_per_node = torch.cuda.device_count()\n",
    "    args.world_size = -1\n",
    "    args.dist_file  = None\n",
    "    args.rank       = 0\n",
    "    args.dist_backend = \"nccl\"\n",
    "    args.multiprocessing_distributed = ngpus>1\n",
    "    if not hasattr(args,'train_set'):args.train_set='large'\n",
    "    ip = os.environ.get(\"MASTER_ADDR\", \"127.0.0.1\")\n",
    "    port = os.environ.get(\"MASTER_PORT\", \"54247\")\n",
    "    hosts = int(os.environ.get(\"WORLD_SIZE\", \"1\"))  # number of nodes\n",
    "    rank = int(os.environ.get(\"RANK\", \"0\"))  # node id\n",
    "    gpus = torch.cuda.device_count()  # gpus per node\n",
    "    args.dist_url = f\"tcp://{ip}:{port}\"\n",
    "    if args.world_size == -1 and \"SLURM_NPROCS\" in os.environ:\n",
    "        args.world_size = int(os.environ[\"SLURM_NPROCS\"])\n",
    "        args.rank       = int(os.environ[\"SLURM_PROCID\"])\n",
    "        jobid           = os.environ[\"SLURM_JOBID\"]\n",
    "\n",
    "        hostfile        = \"dist_url.\" + jobid  + \".txt\"\n",
    "        if args.dist_file is not None:\n",
    "            args.dist_url = \"file://{}.{}\".format(os.path.realpath(args.dist_file), jobid)\n",
    "        elif args.rank == 0:\n",
    "            import socket\n",
    "            ip = socket.gethostbyname(socket.gethostname())\n",
    "            port = find_free_port()\n",
    "            args.dist_url = \"tcp://{}:{}\".format(ip, port)\n",
    "            #with open(hostfile, \"w\") as f:f.write(args.dist_url)\n",
    "        else:\n",
    "            import os\n",
    "            import time\n",
    "            while not os.path.exists(hostfile):\n",
    "                time.sleep(1)\n",
    "            with open(hostfile, \"r\") as f:\n",
    "                args.dist_url = f.read()\n",
    "        print(\"dist-url:{} at PROCID {} / {}\".format(args.dist_url, args.rank, args.world_size))\n",
    "    else:\n",
    "        args.world_size = 1\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "    train_dataset_tensor=valid_dataset_tensor=None\n",
    "\n",
    "    print(\"======== loading data ==========\")\n",
    "    if 'small' in args.train_set:\n",
    "        if not args.fourcast:\n",
    "            train_dataset_tensor = load_small_dataset_in_memory('train').share_memory_()\n",
    "            valid_dataset_tensor = load_small_dataset_in_memory('valid').share_memory_()\n",
    "        else:\n",
    "            train_dataset_tensor = load_small_dataset_in_memory('test').share_memory_()\n",
    "            valid_dataset_tensor = None\n",
    "    else:\n",
    "        if args.fourcast:\n",
    "            train_dataset_tensor = load_test_dataset_in_memory(years=[2018],root=\"/nvme/zhangtianning/datasets/ERA5\").share_memory_()\n",
    "            valid_dataset_tensor = None\n",
    "    print(\"=======done==========\")\n",
    "    print(train_dataset_tensor.shape)\n",
    "    if args.multiprocessing_distributed:\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        torch.multiprocessing.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args,train_dataset_tensor,valid_dataset_tensor))\n",
    "    else:\n",
    "        main_worker(0, ngpus_per_node, args,train_dataset_tensor,valid_dataset_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518d2dba",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80e6092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use offline data mode <2>: train/valid/test use offline data\n",
      "use dataset in datasets/weatherbench_6hour\n",
      "load data from datasets/weatherbench_6hour/test_2D70N.npy\n",
      "notice we will use around_index(26, 64, 2, 7, 7) to patch data\n"
     ]
    }
   ],
   "source": [
    "test_dataset,  test_dataloader = get_test_dataset(args,test_dataset_tensor=None,test_record_load=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ab01651",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = test_dataloader\n",
    "random_repeat = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b61c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load everything, start_validating......\r"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "logsys.eval()\n",
    "status     = 'test'\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "Fethcher   = Datafetcher\n",
    "prefetcher = Fethcher(data_loader,next(model.parameters()).device)\n",
    "batches = len(data_loader)\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "device = next(model.parameters()).device\n",
    "data_cost = train_cost = rest_cost = 0\n",
    "now = time.time()\n",
    "model.clim = torch.Tensor(data_loader.dataset.clim_tensor).to(device)\n",
    "fourcastresult={}\n",
    "save_prediction_first_step = None#torch.zeros_like(data_loader.dataset.data)\n",
    "save_prediction_final_step = None#torch.zeros_like(data_loader.dataset.data)\n",
    "# = 100\n",
    "intervel = batches//logsys.log_trace_times + 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    inter_b.lwrite(\"load everything, start_validating......\", end=\"\\r\")\n",
    "    while inter_b.update_step():\n",
    "        #if inter_b.now>10:break\n",
    "        data_cost += time.time() - now;now = time.time()\n",
    "        step        = inter_b.now\n",
    "        idxes,batch = prefetcher.next()\n",
    "        batch       = make_data_regular(batch,half_model)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc2c7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=test_dataloader.dataset\n",
    "time_step_1_mode=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d2e03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e17d437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "085a77c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = batch[0:model.history_length] # start must be a list\n",
    "for i in range(model.history_length,len(batch), model.pred_len):# i now is the target index\n",
    "    end = batch[i:i+model.pred_len]\n",
    "    end = end[0] if len(end) == 1 else end\n",
    "    #ltmv_pred, target, extra_loss, extra_info_from_model_list, start = once_forward(model,i,start,end,dataset,time_step_1_mode)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c57b5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor, start_time_stamp, start_pos = [torch.stack([s[i] for s in start],1) for i in range(len(start[-1]))] \n",
    "target,   end_time_stamp,   end_pos =  [torch.stack([s[i] for s in   end],1) for i in range(len(  end[-1]))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7889c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 28, 70, 32, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb2aecda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 28, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_stamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b234c33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 39.19 GiB (GPU 0; 79.35 GiB total capacity; 69.59 GiB already allocated; 2.16 GiB free; 75.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_time_stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_time_stamp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#(B,T,P,W,H) (B,T,4) (B,T,2,W,H)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [44], line 68\u001b[0m, in \u001b[0;36mPOverLapTimePosFEDformer.forward\u001b[0;34m(self, x, pos_stamp, start_time_stamp, end_time_stamp)\u001b[0m\n\u001b[1;32m     66\u001b[0m x,start_time_stamp,end_time_stamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_to_patches(x,pos_stamp,start_time_stamp,end_time_stamp)\n\u001b[1;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m rearrange(x,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb t c w h -> b w h t c\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_time_stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time_stamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m x \u001b[38;5;241m=\u001b[39m rearrange(x,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb w h t c -> b t c w h\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/FEDformer.py:1053\u001b[0m, in \u001b[0;36mFEDformer.forward\u001b[0;34m(self, x_enc, x_mark_enc, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[1;32m   1050\u001b[0m enc_out        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_embedding(x_enc, x_mark_enc)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m#timer.record('enc_embedding',level=0)\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m enc_out, attns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_self_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m#timer.record('encoder',level=0)\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# dec\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m dec_out                   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_embedding(seasonal_init, x_mark_dec)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/FEDformer.py:897\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attn_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_layers:\n\u001b[0;32m--> 897\u001b[0m         x, attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m         attns\u001b[38;5;241m.\u001b[39mappend(attn)\n\u001b[1;32m    899\u001b[0m \u001b[38;5;66;03m#timer.record(f'layers_encoder','encoder',1)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/FEDformer.py:867\u001b[0m, in \u001b[0;36mEncoderLayerN.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;66;03m# x     [Batch,  *space_dims, in_channels] -> [Batch, z, h ,w, T1, in_channels]\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     x, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     x       \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m    869\u001b[0m     x, _    \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecomp(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects_local/FourCastNet/model/FEDformer.py:782\u001b[0m, in \u001b[0;36mAutoCorrelationLayerN.forward\u001b[0;34m(self, queries, keys, values, attn_mask)\u001b[0m\n\u001b[1;32m    778\u001b[0m tensor_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(queries\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    780\u001b[0m Space_last_order\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,tensor_rank\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \n\u001b[0;32m--> 782\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mBS_dims_L, H, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_keys)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m*\u001b[39mSpace_last_order)  \u001b[38;5;66;03m#[Batch, head_num, in_channels, *space_dims]\u001b[39;00m\n\u001b[1;32m    783\u001b[0m keys    \u001b[38;5;241m=\u001b[39m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_projection(keys)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mBS_dims_S, H, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_keys)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m*\u001b[39mSpace_last_order)  \u001b[38;5;66;03m#[Batch, head_num, in_channels, *space_dims]\u001b[39;00m\n\u001b[1;32m    784\u001b[0m values  \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_projection(values)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mBS_dims_S, H, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_values)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m*\u001b[39mSpace_last_order)\u001b[38;5;66;03m#[Batch, head_num, in_channels, *space_dims]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 39.19 GiB (GPU 0; 79.35 GiB total capacity; 69.59 GiB already allocated; 2.16 GiB free; 75.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "out   = model(tensor, start_pos,start_time_stamp,end_time_stamp) #(B,T,P,W,H) (B,T,4) (B,T,2,W,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f7492c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd4abed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 3, 28, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_stamp.unsqueeze(1).unsqueeze(1).repeat(1,3,3,1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50d9905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2D patch model, the img_size will be force set (32,64)\n",
      "fourier enhanced block used!\n",
      "for shape:[7 7] and pick modes:(7, 7)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      "create a mode filter shape=torch.Size([7, 7, 15]) with 200 mode activate\n",
      "fourier enhanced block used!\n",
      "for shape:[7 7] and pick modes:(7, 7)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      "create a mode filter shape=torch.Size([7, 7, 6]) with 150 mode activate\n",
      " fourier enhanced cross attention used!\n",
      "for shape:[7 7] and pick modes:(7, 7)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      "for shape:[7 7] and pick modes:(7, 7)>=25.0, we pick 25.0 modes, the baseline modes is 25.0\n",
      " modes_q=150,  shape_q=torch.Size([7, 7, 6])\n",
      "modes_kv=200, shape_kv=torch.Size([7, 7, 15])\n"
     ]
    }
   ],
   "source": [
    "model = POverLapTimePosFEDformer(**args.model_kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a6d15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_loss = 0\n",
    "extra_info_from_model_list = []\n",
    "if isinstance(out,(list,tuple)):\n",
    "    extra_loss                 = out[1]\n",
    "    extra_info_from_model_list = out[2:]\n",
    "    out = out[0]\n",
    "\n",
    "ltmv_pred = dataset.inv_normlize_data([out])[0] #(B,T,P,W,H)\n",
    "\n",
    "start = start[len(end):] + [[tensor, time_stamp, pos] for tensor,(_,time_stamp,pos) in zip(ltmv_pred.permute(1,0,2,3,4), end)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b4e50d8356ba75a9636787f9051ee458aaf13e87df491415cc800c7b2b8a21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
