{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25688fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from cephdataset import *\n",
    "\n",
    "from mltool.universal_model_util import get_model_para_detail\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d422fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.othermodels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a2d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.pretrain import *\n",
    "from train.pretrain import get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd6cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet_138/ts_3_pretrain-2D706N_per_6_step/03_15_14_37_50207-seed_42/\"\n",
    "args=get_args(os.path.join(ckpt_path,\"config.json\"))\n",
    "args= parse_default_args(args)\n",
    "\n",
    "args.use_wandb=0\n",
    "args.gpu = args.local_rank = gpu  = local_rank = 0\n",
    "##### parse args: dataset_kargs / model_kargs / train_kargs  ###########\n",
    "args= parse_default_args(args)\n",
    "SAVE_PATH = get_ckpt_path(args)\n",
    "SAVE_PATH = \"debug\"\n",
    "args.SAVE_PATH = str(SAVE_PATH)\n",
    "#args.pretrain_weight = os.path.join(args.SAVE_PATH,'pretrain_latest.pt')\n",
    "########## inital log ###################\n",
    "logsys = create_logsys(args,False)\n",
    "args.distributed = False\n",
    "\n",
    "if args.distributed:\n",
    "    if args.dist_url == \"env://\" and args.rank == -1:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "    if args.multiprocessing_distributed:\n",
    "        # For multiprocessing distributed training, rank needs to be the\n",
    "        # global rank among all the processes\n",
    "        args.rank = args.rank * ngpus_per_node + local_rank\n",
    "    logsys.info(f\"start init_process_group,backend={args.dist_backend}, init_method={args.dist_url},world_size={args.world_size}, rank={args.rank}\")\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,world_size=args.world_size, rank=args.rank)\n",
    "\n",
    "model           = build_model(args)\n",
    "#param_groups    = timm.optim.optim_factory.add_weight_decay(model, args.weight_decay)\n",
    "optimizer,lr_scheduler,criterion = build_optimizer(args,model)\n",
    "loss_scaler     = torch.cuda.amp.GradScaler(enabled=True)\n",
    "logsys.info(f'use lr_scheduler:{lr_scheduler}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ded1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:41:54,006 model args: img_size= (64, 128)\n",
      "2023-03-21 11:41:54,008 model args: patch_size= (2, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log at debug\n",
      "wandb id: None\n",
      "wandb is off, the recorder list is  ['tensorboard'], we pass wandb\n",
      "this is pre-set model, we disable all config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:41:57,733 use model ==> SWIN_Feature\n",
      "2023-03-21 11:41:57,735 Rank: 0, Local_rank: 0 | Number of Parameters: 200882304, Number of Buffers: 0, Size of Model: 766.3052 MB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/pruned_first64_channel_out/backbone.best.pt...........\n",
      "loading model weight success...........\n",
      "loading model success...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:42:00,812 use lr_scheduler:None\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet_138/ts_3_pretrain-2D706N_per_6_step/03_15_14_37_50207-seed_42/\"\n",
    "args=get_args(os.path.join(ckpt_path,\"config.json\"))\n",
    "\n",
    "args.model_type = 'CK_LgNet'\n",
    "args.output_channel=69\n",
    "args.use_pos_embed=1\n",
    "args.subweight = \"\"\n",
    "args.mode = \"fourcast\"\n",
    "args.pretrain_weight=\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/pruned_first64_channel_out/backbone.best.pt\"\n",
    "args= parse_default_args(args)\n",
    "args.use_wandb=0\n",
    "args.gpu = args.local_rank = gpu  = local_rank = 0\n",
    "##### parse args: dataset_kargs / model_kargs / train_kargs  ###########\n",
    "args= parse_default_args(args)\n",
    "SAVE_PATH = get_ckpt_path(args)\n",
    "SAVE_PATH = \"debug\"\n",
    "args.SAVE_PATH = str(SAVE_PATH)\n",
    "#args.pretrain_weight = os.path.join(args.SAVE_PATH,'pretrain_latest.pt')\n",
    "########## inital log ###################\n",
    "logsys = create_logsys(args,False)\n",
    "args.distributed = False\n",
    "\n",
    "if args.distributed:\n",
    "    if args.dist_url == \"env://\" and args.rank == -1:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "    if args.multiprocessing_distributed:\n",
    "        # For multiprocessing distributed training, rank needs to be the\n",
    "        # global rank among all the processes\n",
    "        args.rank = args.rank * ngpus_per_node + local_rank\n",
    "    logsys.info(f\"start init_process_group,backend={args.dist_backend}, init_method={args.dist_url},world_size={args.world_size}, rank={args.rank}\")\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,world_size=args.world_size, rank=args.rank)\n",
    "\n",
    "model           = build_model(args)\n",
    "#param_groups    = timm.optim.optim_factory.add_weight_decay(model, args.weight_decay)\n",
    "optimizer,lr_scheduler,criterion = build_optimizer(args,model)\n",
    "loss_scaler     = torch.cuda.amp.GradScaler(enabled=True)\n",
    "logsys.info(f'use lr_scheduler:{lr_scheduler}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079aea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,71,64,128).cuda()\n",
    "model = model.cuda()\n",
    "model2= model2.cuda()\n",
    "with torch.no_grad():\n",
    "    print(torch.dist(model(a),model2(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2303f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(new_state_dict,\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet_69/ts_3_pretrain-2D706N_per_6_step/pruned_first64_channel_out/backbone.best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4281f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.utils.utils import window_partition, window_reverse, ScaleOffset, attn_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6578554b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use dataset in datasets/weatherbench32x64/\n"
     ]
    }
   ],
   "source": [
    "test_dataset,  test_dataloader = get_test_dataset(args,test_dataset_tensor=None,test_record_load=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "089b2078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(395.5527)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_fourcast_metric_table(ckpt_path,logsys,test_dataset,collect_names=['500hPa_geopotential','850hPa_temperature'],return_value = ['Z500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c74659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.mode = 'fourcast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c2aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrain_path = os.path.join(ckpt_path,\"backbone.best.pt\")\n",
    "pretrain_path = os.path.join(ckpt_path,\"pretrain_latest.pt\")\n",
    "#pretrain_path = os.path.join(\"checkpoints/WeathBench32x64/CK_LgNet/ts_3_finetune-2D706N_per_6_step/grow_up_inner_1536_model/grow_up.weight.pt\")\n",
    "args.pretrain_weight = pretrain_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "287c52be",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 18:38:00,753 loading weight from checkpoints/WeathBench32x64/CK_LgNet/ts_3_finetune-2D706N_per_6_step/03_10_18_59_45137-seed_73001/pretrain_latest.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from checkpoints/WeathBench32x64/CK_LgNet/ts_3_finetune-2D706N_per_6_step/03_10_18_59_45137-seed_73001/pretrain_latest.pt...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 18:38:01,754 done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model weight success...........\n",
      "loading model success...........\n"
     ]
    }
   ],
   "source": [
    "logsys.info(f\"loading weight from {args.pretrain_weight}\")\n",
    "start_epoch, start_step, min_loss = load_model(model.module if args.distributed else model, optimizer, lr_scheduler, loss_scaler, path=args.pretrain_weight, \n",
    "                    only_model= (args.mode=='fourcast') or (args.mode=='finetune' and not args.continue_train) ,loc = 'cuda:{}'.format(args.gpu))\n",
    "if args.more_epoch_train:\n",
    "    assert args.pretrain_weight\n",
    "    print(f\"detect more epoch training, we will do a copy processing for {args.pretrain_weight}\")\n",
    "    os.system(f'cp {args.pretrain_weight} {args.pretrain_weight}-epoch{start_epoch}')\n",
    "logsys.info(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cdcaeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.LGNet import LGnet_grow_up_full_recursively,SD_attn_grow_up_inner_recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3d434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.universal_model_util import get_model_para_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f961f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "growing SD_attn of [64, 128] from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of [64, 128] from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of [64, 128] from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of [64, 128] from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n",
      "growing SD_attn of (4, 8) from (1152-1152-1152) to (1152-2304-1152)\n"
     ]
    }
   ],
   "source": [
    "SD_attn_grow_up_inner_recursively(model,1152*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a76d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/attn_grow_up/backbone.best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b613322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      growing PatchEmbed from (1152,) to (2304,)\n",
      "                            growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of [64, 128] from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of [64, 128] from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of [64, 128] from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of [64, 128] from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "                      growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "                      growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "             growing LayerNorm from (1152,) to (2304,)\n",
      "       growing SD_attn of (4, 8) from (1152-1152-1152) to (2304-2304-2304)\n",
      "              growing LayerNorm from (1152,) to (2304,)\n",
      "       growing Mlp from (1152-4608-1152) to (2304-9216-2304)\n",
      "   growing final Linear from (1152,69) to (2304,69)\n"
     ]
    }
   ],
   "source": [
    "LGnet_grow_up_full_recursively(model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9acfac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "pos_embed = state_dict['backbone.backbone.net.pos_embed'] \n",
    "state_dict['backbone.backbone.net.pos_embed'] = torch.cat([pos_embed,pos_embed],-1)\n",
    "\n",
    "torch.save(state_dict,\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/full_grow_up/backbone.best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9933ba2c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model_kargs['out_chans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d54661",
   "metadata": {
    "code_folding": [
     22
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:42:08,553 model args: img_size= (64, 128)\n",
      "2023-03-21 11:42:08,553 model args: patch_size= (2, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log at debug\n",
      "wandb id: None\n",
      "wandb is off, the recorder list is  ['tensorboard'], we pass wandb\n",
      "this is pre-set model, we disable all config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:42:13,302 use model ==> SWIN_Feature\n",
      "2023-03-21 11:42:13,306 Rank: 0, Local_rank: 0 | Number of Parameters: 264624768, Number of Buffers: 0, Size of Model: 1009.4634 MB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/attn_grow_up/backbone.best.pt...........\n",
      "loading model weight success...........\n",
      "loading model success...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:42:14,405 use lr_scheduler:None\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet_138/ts_3_pretrain-2D706N_per_6_step/03_15_14_37_50207-seed_42/\"\n",
    "args=get_args(os.path.join(ckpt_path,\"config.json\"))\n",
    "\n",
    "args.model_type = 'HalfGrowUp_CK_LgNet'\n",
    "args.output_channel=69\n",
    "args.use_pos_embed=1\n",
    "args.subweight = \"\"\n",
    "args.mode = \"fourcast\"\n",
    "args.pretrain_weight=\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/attn_grow_up/backbone.best.pt\"\n",
    "args= parse_default_args(args)\n",
    "args.use_wandb=0\n",
    "args.gpu = args.local_rank = gpu  = local_rank = 0\n",
    "##### parse args: dataset_kargs / model_kargs / train_kargs  ###########\n",
    "args= parse_default_args(args)\n",
    "SAVE_PATH = get_ckpt_path(args)\n",
    "SAVE_PATH = \"debug\"\n",
    "args.SAVE_PATH = str(SAVE_PATH)\n",
    "#args.pretrain_weight = os.path.join(args.SAVE_PATH,'pretrain_latest.pt')\n",
    "########## inital log ###################\n",
    "logsys = create_logsys(args,False)\n",
    "args.distributed = False\n",
    "\n",
    "if args.distributed:\n",
    "    if args.dist_url == \"env://\" and args.rank == -1:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "    if args.multiprocessing_distributed:\n",
    "        # For multiprocessing distributed training, rank needs to be the\n",
    "        # global rank among all the processes\n",
    "        args.rank = args.rank * ngpus_per_node + local_rank\n",
    "    logsys.info(f\"start init_process_group,backend={args.dist_backend}, init_method={args.dist_url},world_size={args.world_size}, rank={args.rank}\")\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,world_size=args.world_size, rank=args.rank)\n",
    "\n",
    "model3           = build_model(args)\n",
    "#param_groups    = timm.optim.optim_factory.add_weight_decay(model, args.weight_decay)\n",
    "optimizer,lr_scheduler,criterion = build_optimizer(args,model)\n",
    "loss_scaler     = torch.cuda.amp.GradScaler(enabled=True)\n",
    "logsys.info(f'use lr_scheduler:{lr_scheduler}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8cb092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = HalfGrowUp_CK_LgNet(**args.model_kargs)\n",
    "# start_epoch, start_step, min_loss = load_model(model3, optimizer, lr_scheduler, loss_scaler, \n",
    "# path=\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/attn_grow_up/backbone.best.pt\",\n",
    "# only_model= True ,loc = 'cuda:{}'.format(args.gpu))\n",
    "# #model3.load_state_dict(torch.load(\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet_69/ts_3_pretrain-2D706N_per_6_step/attn_grow_up/backbone.best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f8ab294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1152, out_features=138, bias=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone.backbone.net.final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1039f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0069, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,71,64,128).cuda()\n",
    "cons  = a[:,:2]\n",
    "model = model.cuda()\n",
    "model3= model3.cuda()\n",
    "with torch.no_grad():\n",
    "    print(torch.dist(model(torch.cat([model(a),cons],1)),model3(torch.cat([model3(a),cons],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6daba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_kargs['embed_dim'] *=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ceb6d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is pre-set model, we disable all config\n",
      "loading model from checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/full_grow_up/backbone.best.pt...........\n",
      "loading model weight success...........\n",
      "loading model success...........\n"
     ]
    }
   ],
   "source": [
    "from model.othermodels import FullGrowUp_CK_LgNet\n",
    "model3 = FullGrowUp_CK_LgNet(**args.model_kargs)\n",
    "start_epoch, start_step, min_loss = load_model(model3, optimizer, lr_scheduler, loss_scaler, \n",
    "path=\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet/ts_3_pretrain-2D706N_per_6_step/full_grow_up/backbone.best.pt\",\n",
    "only_model= True ,loc = 'cuda:{}'.format(args.gpu))\n",
    "#model3.load_state_dict(torch.load(\"checkpoints/WeathBench64x128CK/SWIN_Feature-CK_LgNet_69/ts_3_pretrain-2D706N_per_6_step/attn_grow_up/backbone.best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4792cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is pre-set model, we disable all config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args.model_kargs['embed_dim'] *=2\n",
    "# model3 = FullGrowUp_CK_LgNet(**args.model_kargs)\n",
    "# model3.load_state_dict(torch.load(\"checkpoints/WeathBench32x64/CK_LgNet/ts_3_finetune-2D706N_per_6_step/grow_up_full_1536_model/grow_up.weight.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d15a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.cuda()\n",
    "model3 = model3.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0136af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0010, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 71, 64, 128).cuda()\n",
    "with torch.no_grad():\n",
    "    print(torch.dist(model1(a),model3(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea8dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.utils.Attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c335c450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1,68,32,64).cuda()\n",
    "layer = model2.backbone.net.layers[0]\n",
    "block = layer.blocks[0]\n",
    "x = a.clone()\n",
    "with torch.no_grad():\n",
    "    #for blk in layer.blocks[:1]:x = blk(x)\n",
    "    #x1 = compute(block.attn,(block.norm(x)))\n",
    "    original_output = model2(x)\n",
    "\n",
    "layer = model3.backbone.net.layers[0]\n",
    "block = layer.blocks[0]\n",
    "x = a.clone()\n",
    "with torch.no_grad():\n",
    "    #for blk in layer.blocks[:1]:x = blk(x)\n",
    "    #x2 = compute(block.attn,(block.norm(x)))\n",
    "    grow_up_output = model3(x)\n",
    "\n",
    "torch.abs(original_output - grow_up_output).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9795400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5100, device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(original_output,grow_up_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fb9cc",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e44fb49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fourcast'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f2304ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use dataset in datasets/weatherbench32x64\n"
     ]
    }
   ],
   "source": [
    "args.valid_batch_size = 4\n",
    "args.dataset_kargs['use_offline_data']=0\n",
    "args.dataset_kargs['time_step']  = args.time_step = 22\n",
    "test_dataset,  test_dataloader = get_test_dataset(args,test_dataset_tensor=None,test_record_load=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f8f2d437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4608//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b1db61ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324301"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96e7ca3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327168"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "71*1152*2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5bc331e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use dataset in datasets/weatherbench32x64/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 14:09:24,886 use dataset ==> WeathBench32x64\n",
      "2023-03-16 14:09:24,886 Start training for 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use dataset in datasets/weatherbench32x64/\n"
     ]
    }
   ],
   "source": [
    "args.debug  = 0 \n",
    "train_dataset, val_dataset, train_dataloader,val_dataloader = get_train_and_valid_dataset(args,\n",
    "               train_dataset_tensor=None,train_record_load=None,\n",
    "               valid_dataset_tensor=None,valid_record_load=None)\n",
    "logsys.info(f\"use dataset ==> {train_dataset.__class__.__name__}\")\n",
    "logsys.info(f\"Start training for {args.epochs} epochs\")\n",
    "master_bar = logsys.create_master_bar(args.epochs)\n",
    "accu_list = ['valid_loss']\n",
    "metric_dict = logsys.initial_metric_dict(accu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e0e78",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### speed test check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b38a2f20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52085fc0",
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 ms ± 829 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch = [torch.randn(4,70,32,64).cuda().half(),\n",
    "         torch.randn(4,70,32,64).cuda().half(),\n",
    "         torch.randn(4,70,32,64).cuda().half()]\n",
    "model.activate_stamps     = [[1, 2], [2]]\n",
    "model.activate_error_coef = [[0, 1, 1, 1.5, 'quantity'],\n",
    "                             [0, 2, 2, 1.5, 'quantity'],\n",
    "                             [1, 2, 2, 3.0, 'quantity']]\n",
    "model.consistancy_alpha   = None\n",
    "model.train()\n",
    "logsys.train()\n",
    "with torch.cuda.amp.autocast(enabled=model.use_amp):\n",
    "    loss, abs_loss, iter_info_pool,ltmv_pred,target  =run_one_iter(model, batch, criterion, 'train', gpu, train_dataset)\n",
    "loss_scaler.scale(loss).backward()   \n",
    "loss_scaler.step(optimizer)\n",
    "loss_scaler.update()   \n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4c4346a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 ms ± 683 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch = [torch.randn(4,70,32,64).cuda().half(),\n",
    "         torch.randn(4,70,32,64).cuda().half(),\n",
    "         torch.randn(4,70,32,64).cuda().half()]\n",
    "model.activate_stamps     = None\n",
    "model.activate_error_coef = None\n",
    "model.consistancy_alpha   = [1,0,0]\n",
    "model.train()\n",
    "logsys.train()\n",
    "with torch.cuda.amp.autocast(enabled=model.use_amp):\n",
    "    loss, abs_loss, iter_info_pool,ltmv_pred,target  =run_one_iter(model, batch, criterion, 'train', gpu, train_dataset)\n",
    "loss_scaler.scale(loss).backward()   \n",
    "loss_scaler.step(optimizer)\n",
    "loss_scaler.update()   \n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1a9c8",
   "metadata": {},
   "source": [
    "##### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "10115b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load everything, start_validating......\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2158', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2158 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_loader = test_dataloader\n",
    "random_repeat = 0\n",
    "snap_index=None\n",
    "do_error_propagration_monitor=False\n",
    "\n",
    "model.eval()\n",
    "logsys.eval()\n",
    "status     = 'test'\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "Fethcher   = Datafetcher\n",
    "prefetcher = Fethcher(data_loader,next(model.parameters()).device)\n",
    "batches = len(data_loader)\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "device = next(model.parameters()).device\n",
    "data_cost = train_cost = rest_cost = 0\n",
    "now = time.time()\n",
    "model.clim = torch.Tensor(data_loader.dataset.clim_tensor).to(device)\n",
    "fourcastresult={}\n",
    "save_prediction_first_step = None#torch.zeros_like(data_loader.dataset.data)\n",
    "save_prediction_final_step = None#torch.zeros_like(data_loader.dataset.data)\n",
    "# = 100\n",
    "intervel = batches//logsys.log_trace_times + 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    inter_b.lwrite(\"load everything, start_validating......\", end=\"\\r\")\n",
    "    while inter_b.update_step():\n",
    "        #if inter_b.now>10:break\n",
    "        data_cost += time.time() - now;now = time.time()\n",
    "        step        = inter_b.now\n",
    "        idxes,batch = prefetcher.next()\n",
    "        batch       = make_data_regular(batch,half_model)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a4b90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b510210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_1_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2eb5ad77",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "start = batch[0:model.history_length] # start must be a list    \n",
    "myaccu= []\n",
    "i = 1\n",
    "with torch.no_grad():\n",
    "    end = batch[i:i+model.pred_len]\n",
    "    end = end[0] if len(end) == 1 else end\n",
    "    ltmv_pred, target, extra_loss, extra_info_from_model_list, start = once_forward(model,i,start,end,dataset,time_step_1_mode)\n",
    "    #ltmv_pred, target = recovery_tensor(dataset,start,end,ltmv_pred,target,index=idxes+i) # the index is the timestamp position in dataset\n",
    "    #ltmv_trues = dataset.inv_normlize_data([target])[0]#.detach().cpu() ### use CUDA computing\n",
    "    #ltmv_preds = ltmv_pred#.detach().cpu()\n",
    "    #time_list  = range(i,i+model.pred_len)\n",
    "    #i+=model.pred_len         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ed9f20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.time_intervel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3f5248c9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ltmv_pred, target = recovery_tensor(dataset,start,end,ltmv_pred,target,index=idxes+i*dataset.time_intervel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca2f30",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# real_mean,real_std = dataset.get_space_time_mean_std(1)\n",
    "real_mean,real_std = torch.from_numpy(real_mean),torch.from_numpy(real_std)\n",
    "origin = target[0]* real_std.to(x.device) + real_mean.to(x.device)\n",
    "origin = origin.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b487ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dist(batch[1][:,:68],target.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b645875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a725f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.162045039606877e-09\n",
      "9.43763593773303e-06\n",
      "0.010113620624025203\n"
     ]
    }
   ],
   "source": [
    "nowidx      = idxes+i*dataset.time_intervel\n",
    "tidx        = 3\n",
    "idx         = nowidx[tidx]\n",
    "odata       = dataset.load_otensor(idx)[dataset.channel_choice]\n",
    "mean,std    = dataset.get_space_time_mean_std(idx)\n",
    "real_target = (odata-mean)/std\n",
    "dataset_out = dataset[tidx][1][i][:68]\n",
    "print(np.linalg.norm(real_target-dataset_out))\n",
    "real_mean,real_std = torch.from_numpy(mean),torch.from_numpy(std)\n",
    "target_tensor = target[tidx] #batch[1][tidx,:68]#target[tidx]\n",
    "print(np.linalg.norm(target_tensor.cpu().numpy()-dataset_out))\n",
    "origin = target_tensor* real_std.to(target_tensor.device) + real_mean.to(target_tensor.device)\n",
    "origin = origin.cpu().numpy()\n",
    "print(np.linalg.norm(odata-origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7c19dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1,std1    = dataset.get_space_time_mean_std(1)\n",
    "mean2,std2    = dataset.get_space_time_mean_std(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3d8638c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8622a682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([8761, 8762, 8763, 8764, 8760, 8766, 8772, 8778, 0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96, 102, 8767, 8773, 8779, 1, 7, 13, 19, 25, 31, 37, 43, 49, 55, 61, 67, 73, 79, 85, 91, 97, 103, 108, 8765, 8768, 8774, 8780, 2, 8, 14, 20, 26, 32, 38, 44, 50, 56, 62, 68, 74, 80, 86, 92, 98, 104, 8769, 8775, 8781, 3, 9, 15, 21, 27, 33, 39, 45, 51, 57, 63, 69, 75, 81, 87, 93, 99, 105, 8770, 40, 28])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loaded_flag.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2272d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 32, 64)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_space_time_mean_std(62)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e827a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1108d64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3864647190>]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(dataset.get_space_time_mean_std(62)[0][:20,16,32],'r')\n",
    "plt.plot(dataset.get_space_time_mean_std(64)[0][:20,16,32],'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "dde6d1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3778640586220363"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(std1[0] - std2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba070548",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery = real_target.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd1f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f2657bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 68, 32, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3b206c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 68, 32, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltmv_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39817a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltmv_pred -  target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d61482f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0089, device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ltmv_pred -  target)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58deec26",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (4217269823.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast(enabled=model.use_amp):\n",
    "    fourcastresult,extra_info = run_one_fourcast_iter(model, batch, idxes, fourcastresult,data_loader.dataset,\n",
    "                             save_prediction_first_step=save_prediction_first_step,\n",
    "                             save_prediction_final_step=save_prediction_final_step,\n",
    "                             snap_index=the_snap_index_in_iter,do_error_propagration_monitor=do_error_propagration_monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a71fcc46",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "==================\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    UVTPHSC = batch[0]\n",
    "    with torch.cuda.amp.autocast(enabled=model.use_amp):\n",
    "        p    = model.UVTPHSC2p(UVTPHSC)\n",
    "        x    = torch.cat([UVTPHSC,p],1)\n",
    "        print(x.isnan().any())\n",
    "        \n",
    "        shape = x.shape\n",
    "        #print(x.shape)\n",
    "        # argue the w resolution.\n",
    "        pad = model.UVTPHSCp2uvth.backbone.get_w_resolution_pad(shape)\n",
    "        if pad is not None:x = F.pad(x.flatten(0,1),(0,0,pad,pad),mode='replicate').reshape(*shape[:-2],-1,shape[-1])\n",
    "        #print(x.shape)\n",
    "        B = x.shape[0]\n",
    "        ot_shape = x.shape[2:]\n",
    "        x = x.reshape(B,-1,*model.UVTPHSCp2uvth.backbone.img_size)# (B, p, z, h, w) or (B, p, h, w)\n",
    "        #timer.restart(level=0)\n",
    "        #print(torch.std_mean(x))\n",
    "        print(x.isnan().any())\n",
    "        \n",
    "        #x = model.UVTPHSCp2uvth.backbone.forward_features(x);#print(torch.std_mean(x))\n",
    "        x = model.UVTPHSCp2uvth.backbone.patch_embed(x)\n",
    "        print(x.isnan().any())\n",
    "        x += model.UVTPHSCp2uvth.backbone.pos_embed\n",
    "        print(x.isnan().any())\n",
    "        x = model.UVTPHSCp2uvth.backbone.pos_drop(x)\n",
    "        print(x.isnan().any())\n",
    "        #print(torch.std_mean(x))\n",
    "        print(\"==================\")\n",
    "        if not model.UVTPHSCp2uvth.backbone.checkpoint_activations:\n",
    "            for num,blk in enumerate(model.UVTPHSCp2uvth.backbone.blocks):\n",
    "                x = blk(x);#print(torch.std_mean(x))\n",
    "                print(x.isnan().any())\n",
    "                if num==2:break\n",
    "        else:\n",
    "            x = checkpoint_sequential(model.UVTPHSCp2uvth.backbone.blocks, 4, x)\n",
    "#         print(\"==================\")\n",
    "#         x = model.UVTPHSCp2uvth.backbone.norm(x).transpose(1, 2);\n",
    "#         print(x.isnan().any())\n",
    "#         x = torch.reshape(x, [-1, model.UVTPHSCp2uvth.backbone.embed_dim, *model.UVTPHSCp2uvth.backbone.final_shape])\n",
    "#         print(x.isnan().any())\n",
    "        #timer.record('forward_features',level=0)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.final_dropout(x)\n",
    "        \n",
    "        \n",
    "#         #timer.record('final_dropout',level=0)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.pre_logits(x);#print(torch.std_mean(x))\n",
    "        \n",
    "#         print(x.isnan().any())\n",
    "#         #timer.record('pre_logits',level=0)\n",
    "#         x = model.UVTPHSCp2uvth.backbone.head(x)  # print(torch.std_mean(x))\n",
    "        \n",
    "#         print(x.isnan().any())\n",
    "#         if model.UVTPHSCp2uvth.backbone.history_length >1:\n",
    "#             x = x.flatten(1,2).transpose(1,-1)\n",
    "#             x = model.UVTPHSCp2uvth.backbone.last_Linear_layer(x)\n",
    "#             x = x.transpose(1,-1)\n",
    "#             ot_shape=ot_shape[1:]\n",
    "#         #timer.record('head',level=0)\n",
    "#         x = x.reshape(B,-1,*ot_shape)\n",
    "#         if pad is not None:\n",
    "#             x = x[...,pad:-pad,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7b24f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d256ff4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#args.dataset_kargs['cross_sample']=args.cross_sample=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f2ebbd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['batch_size']=args.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "145f9a40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['cross_sample']=args.cross_sample=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963beb83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['use_offline_data']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831b3239",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['patch_range']=(3,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9282be42",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.debug  = 1\n",
    "args.dataset_kargs['batch_size'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "959b737c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use offline data mode <2>: train/valid/test use offline data\n",
      "use dataset in datasets/weatherbench_6hour\n",
      "load data from datasets/weatherbench_6hour/test_2D70N.npy\n",
      "use offline data mode <2>: train/valid/test use offline data\n",
      "use dataset in datasets/weatherbench_6hour\n",
      "load data from datasets/weatherbench_6hour/test_2D70N.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 20:28:56,408 use dataset ==> WeathBench7066\n",
      "2023-02-13 20:28:56,409 Start training for 100 epochs\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, train_dataloader,val_dataloader = get_train_and_valid_dataset(args,\n",
    "               train_dataset_tensor=None,train_record_load=None,\n",
    "               valid_dataset_tensor=None,valid_record_load=None)\n",
    "logsys.info(f\"use dataset ==> {train_dataset.__class__.__name__}\")\n",
    "logsys.info(f\"Start training for {args.epochs} epochs\")\n",
    "master_bar = logsys.create_master_bar(args.epochs)\n",
    "accu_list = ['valid_loss']\n",
    "metric_dict = logsys.initial_metric_dict(accu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6f524f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.dataset_kargs['cross_sample']=args.cross_sample=1\n",
    "train_dataset.cross_sample  =1\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d02eb672",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset.cross_sample  =0\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6872d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# val_dataset.cross_sample  =0 \n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8879877",
   "metadata": {
    "code_folding": [
     4,
     7,
     10
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load everything, start_training......\r"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "start_step = 0\n",
    "data_loader = train_dataloader\n",
    "status = 'train'\n",
    "if status == 'train':\n",
    "    model.train()\n",
    "    logsys.train()\n",
    "elif status == 'valid':\n",
    "    model.eval()\n",
    "    logsys.eval()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "accumulation_steps = model.accumulation_steps # should be 16 for finetune. but I think its ok.\n",
    "half_model = next(model.parameters()).dtype == torch.float16\n",
    "\n",
    "data_cost  = []\n",
    "train_cost = []\n",
    "rest_cost  = []\n",
    "now = time.time()\n",
    "\n",
    "Fethcher   = RandomSelectPatchFetcher if( status =='train' and \\\n",
    "                                          data_loader.dataset.use_offline_data and \\\n",
    "                                          data_loader.dataset.split=='train' and \\\n",
    "                                          'Patch' in data_loader.dataset.__class__.__name__) else Datafetcher\n",
    "device     = next(model.parameters()).device\n",
    "prefetcher = Fethcher(data_loader,device)\n",
    "#raise\n",
    "batches    = len(data_loader)\n",
    "\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "\n",
    "if start_step == 0:optimizer.zero_grad()\n",
    "intervel = batches//100 + 1\n",
    "\n",
    "\n",
    "total_diff,total_num  = torch.Tensor([0]).to(device), torch.Tensor([0]).to(device)\n",
    "nan_count = 0\n",
    "Nodeloss1 = Nodeloss2 = Nodeloss12 = -1\n",
    "\n",
    "inter_b.lwrite(f\"load everything, start_{status}ing......\", end=\"\\r\")\n",
    "preds = []\n",
    "reals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31f0155e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset.cross_sample  =0\n",
    "train_dataloader  = torch.utils.data.DataLoader(train_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e47fe931",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_dataset.cross_sample  = 1\n",
    "val_dataloader  = torch.utils.data.DataLoader(val_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30a04216",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ec29f67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4389189d",
   "metadata": {
    "code_folding": [
     4,
     7,
     10,
     20
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load everything, start_validing......\r"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "start_step = 0\n",
    "data_loader = train_dataloader\n",
    "status = 'valid'\n",
    "if status == 'train':\n",
    "    model.train()\n",
    "    logsys.train()\n",
    "elif status == 'valid':\n",
    "    model.eval()\n",
    "    logsys.eval()\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "accumulation_steps = model.accumulation_steps # should be 16 for finetune. but I think its ok.\n",
    "half_model = next(model.parameters()).dtype == torch.float16\n",
    "\n",
    "data_cost  = []\n",
    "train_cost = []\n",
    "rest_cost  = []\n",
    "now = time.time()\n",
    "\n",
    "Fethcher   = RandomSelectPatchFetcher if( status =='train' and \\\n",
    "                                          data_loader.dataset.use_offline_data and \\\n",
    "                                          data_loader.dataset.split=='train' and \\\n",
    "                                          'Patch' in data_loader.dataset.__class__.__name__) else Datafetcher\n",
    "device     = next(model.parameters()).device\n",
    "prefetcher = Fethcher(data_loader,device)\n",
    "#raise\n",
    "batches    = len(data_loader)\n",
    "\n",
    "inter_b    = logsys.create_progress_bar(batches,unit=' img',unit_scale=data_loader.batch_size)\n",
    "gpu        = dist.get_rank() if hasattr(model,'module') else 0\n",
    "\n",
    "if start_step == 0:optimizer.zero_grad()\n",
    "intervel = batches//100 + 1\n",
    "\n",
    "\n",
    "total_diff,total_num  = torch.Tensor([0]).to(device), torch.Tensor([0]).to(device)\n",
    "nan_count = 0\n",
    "Nodeloss1 = Nodeloss2 = Nodeloss12 = -1\n",
    "\n",
    "inter_b.lwrite(f\"load everything, start_{status}ing......\", end=\"\\r\")\n",
    "preds = []\n",
    "reals = []\n",
    "while inter_b.update_step():\n",
    "    #if inter_b.now>10:break\n",
    "    step = inter_b.now\n",
    "    batch = prefetcher.next()\n",
    "    #print(batch[0].shape)\n",
    "    #raise\n",
    "    if step < start_step:continue\n",
    "    #batch = data_loader.dataset.do_normlize_data(batch)\n",
    "\n",
    "    batch = make_data_regular(batch,half_model)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25dd4f83",
   "metadata": {
    "code_folding": [
     44,
     51,
     55,
     66,
     90,
     98,
     110,
     140,
     142,
     148,
     154,
     160,
     166,
     179,
     191
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_one_iter_highlevel_fast(model, batch, criterion, status, gpu, dataset):\n",
    "    assert model.history_length == 1\n",
    "    assert model.pred_len == 1\n",
    "    assert len(batch)>1\n",
    "    assert len(batch) <= len(model.activate_stamps) + 1\n",
    "    iter_info_pool={}\n",
    "    \n",
    "    if model.history_length > len(batch):\n",
    "        print(f\"you want to use history={model.history_length}\")\n",
    "        print(f\"but your input batch(timesteps) only has len(batch)={len(batch)}\")\n",
    "        raise\n",
    "    now_level_batch = torch.stack(batch,1) #[(B,P,W,H),(B,P,W,H),...,(B,P,W,H)] -> (B,L,P,W,H)\n",
    "    # input is a tenosor (B,L,P,W,H)\n",
    "    # The generated intermediate is recorded as \n",
    "    # X0 x1 y2 z3\n",
    "    # X1 x2 y3 z4\n",
    "    # X2 x3 y4\n",
    "    # X3 x4\n",
    "    B,L = now_level_batch.shape[:2]\n",
    "    tshp= now_level_batch.shape[2:]\n",
    "    all_level_batch = [now_level_batch]\n",
    "    all_level_record= [list(range(L))] #[0,1,2,3]]\n",
    "    ####################################################\n",
    "    # we will do once forward at begin to gain \n",
    "    # X0 X1 X2 X3\n",
    "    # |  |  |  |\n",
    "    # x1 x2 x3 x4\n",
    "    # |  |  |\n",
    "    # y2 y3 y4\n",
    "    # |  |\n",
    "    # z3 z4\n",
    "    ### the problem is we may cut some path by feeding an extra option.\n",
    "    ### for example, we may achieve a computing graph as\n",
    "    # X0 X1 X2 X3\n",
    "    # |  |  |  \n",
    "    # x1 x2 x3 \n",
    "    # |   \n",
    "    # y2 \n",
    "    # |  \n",
    "    # z3 \n",
    "    # so we need a flag \n",
    "    ####################################################\n",
    "    train_channel_from_this_stamp,train_channel_from_next_stamp,pred_channel_for_next_stamp = feature_pick_check(model)\n",
    "\n",
    "    for i in range(len(model.activate_stamps)): # generate L , L-1, L-2\n",
    "        # the least coding here\n",
    "        # now_level_batch = model(now_level_batch[:,:(L-i)].flatten(0,1)).reshape(B,(L-i),*tshp)  \n",
    "        # all_level_batch.append(now_level_batch)\n",
    "        activate_stamp      = model.activate_stamps[i]\n",
    "        last_activate_stamp = all_level_record[-1]\n",
    "        picked_stamp = []\n",
    "        for t in activate_stamp:\n",
    "            picked_stamp.append(last_activate_stamp.index(t-1)) # if t-1 not in last_activate_stamp, raise Error\n",
    "        start = [now_level_batch[:,picked_stamp].flatten(0,1)]\n",
    "\n",
    "        if pred_channel_for_next_stamp or train_channel_from_next_stamp:\n",
    "            if pred_channel_for_next_stamp  : assert t<=L # save key when prediction need last stamp information\n",
    "            if train_channel_from_next_stamp: assert t< L           \n",
    "            target_stamp = []\n",
    "            for t in activate_stamp:\n",
    "                target_stamp.append(last_activate_stamp.index(t) if t   in last_activate_stamp  else last_activate_stamp.index(t-1))\n",
    "                # if the target stamp not appear in this batch, use current stamp fill, but we need prohibit this prediction \n",
    "                # to do next forward prediction. Thus we limit in t < L \n",
    "            # notice when activate pred_channel_for_next_stamp, the unpredicted part should be filled by the part from next stamp \n",
    "            # but the loss should be calculate only on the predicted part.\n",
    "            end = now_level_batch[:,target_stamp].flatten(0,1)\n",
    "        else:\n",
    "            end = None\n",
    "        _, _, _, _, start    = once_forward_normal(model,i,start,end,dataset,False)\n",
    "        now_level_batch      = start[-1].reshape(B,len(picked_stamp),*tshp)  \n",
    "        #now_level_batch     = model(now_level_batch[:,picked_stamp].flatten(0,1)).reshape(B,len(picked_stamp),*tshp)  \n",
    "        all_level_batch.append(now_level_batch)\n",
    "        #all_level_record.append([last_activate_stamp[t]+1 for t in picked_stamp])\n",
    "        all_level_record.append(activate_stamp)\n",
    "\n",
    "    ####################################################\n",
    "    ################ calculate error ###################\n",
    "    iter_info_pool={}\n",
    "    loss = 0\n",
    "    diff = 0\n",
    "    loss_count = diff_count = len(model.activate_error_coef)\n",
    "    for (level_1, level_2, stamp, coef,_type) in model.activate_error_coef:\n",
    "        tensor1 = all_level_batch[level_1][:,all_level_record[level_1].index(stamp)]\n",
    "        tensor2 = all_level_batch[level_2][:,all_level_record[level_2].index(stamp)]\n",
    "        if 'quantity' in _type:\n",
    "            if _type == 'quantity':\n",
    "                error   = criterion(tensor1,tensor2)\n",
    "            elif _type == 'quantity_log':\n",
    "                error   = ((tensor1-tensor2)**2+1).log().mean()\n",
    "            else:raise NotImplementedError\n",
    "        elif 'alpha' in _type:\n",
    "            last_tensor1 = all_level_batch[level_1-1][:,all_level_record[level_1-1].index(stamp-1)]\n",
    "            last_tensor2 = all_level_batch[level_2-1][:,all_level_record[level_2-1].index(stamp-1)]\n",
    "            if _type == 'alpha':\n",
    "                error   = torch.mean(  ((tensor1-tensor2)**2) / ((last_tensor1-last_tensor2)**2+1e-4)  )\n",
    "            elif _type == 'alpha_log':\n",
    "                error   = torch.mean(  ((tensor1-tensor2)**2+1).log() - ((last_tensor1-last_tensor2)**2+1).log() )\n",
    "            else:raise NotImplementedError\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        iter_info_pool[f\"{status}_error_{level_1}_{level_2}_{stamp}\"] = error.item()\n",
    "        loss   += coef*error\n",
    "        if level_1 ==0 and (level_2 == stamp):# to be same as normal train \n",
    "            diff += coef*error\n",
    "    loss = loss/loss_count\n",
    "    diff = diff/loss_count\n",
    "    return loss, diff, iter_info_pool, None, all_level_batch\n",
    "\n",
    "def run_one_iter_normal(model, batch, criterion, status, gpu, dataset):\n",
    "    iter_info_pool={}\n",
    "    loss = 0\n",
    "    diff = 0\n",
    "    random_run_step = np.random.randint(1,len(batch)) if len(batch)>1 else 0\n",
    "    time_step_1_mode=False\n",
    "    if len(batch) == 1 and isinstance(batch[0],(list,tuple)) and len(batch[0])>1:\n",
    "        batch = batch[0] # (Field, FieldDt)\n",
    "        time_step_1_mode=True\n",
    "    if model.history_length > len(batch):\n",
    "        print(f\"you want to use history={model.history_length}\")\n",
    "        print(f\"but your input batch(timesteps) only has len(batch)={len(batch)}\")\n",
    "        raise\n",
    "    pred_step = 0\n",
    "    start = batch[0:model.history_length] # start must be a list\n",
    "    full_fourcast_error_list = []\n",
    "    hidden_fourcast_list = [] \n",
    "    # length depend on pred_len time_step=2 --> 1+1\n",
    "    #                time_step=3 --> 1+2+2\n",
    "    #                time_step=4 --> 1+2+3\n",
    "    # use_consistancy_alpha to control activate amplitude\n",
    "    \n",
    "    save_list = []\n",
    "    for i in range(model.history_length,len(batch), model.pred_len):# i now is the target index\n",
    "        end = batch[i:i+model.pred_len]\n",
    "        end = end[0] if len(end) == 1 else end\n",
    "\n",
    "        ltmv_pred, target, extra_loss, extra_info_from_model_list, start = once_forward(model,i,start,end,dataset,time_step_1_mode)\n",
    "        \n",
    "            \n",
    "        if extra_loss !=0:\n",
    "            iter_info_pool[f'{status}_extra_loss_gpu{gpu}_timestep{i}'] = extra_loss.item()\n",
    "        for extra_info_from_model in extra_info_from_model_list:\n",
    "            for name, value in extra_info_from_model.items():\n",
    "                iter_info_pool[f'{status}_on_{status}_{name}_timestep{i}'] = value\n",
    "        \n",
    "        ltmv_pred = dataset.do_normlize_data([ltmv_pred])[0]\n",
    "\n",
    "        if 'Delta' in dataset.__class__.__name__:\n",
    "            loss  += criterion(ltmv_pred,target)+ extra_loss\n",
    "            with torch.no_grad():\n",
    "                normlized_field_predict = dataset.combine_base_delta(start[-1][0], start[-1][1]) \n",
    "                normlized_field_real    = dataset.combine_base_delta(      end[0],       end[1])  \n",
    "                abs_loss = criterion(normlized_field_predict,normlized_field_real)            \n",
    "        elif 'deseasonal' in dataset.__class__.__name__:\n",
    "            loss  += criterion(ltmv_pred,target)+ extra_loss\n",
    "            with torch.no_grad():\n",
    "                normlized_field_predict = dataset.addseasonal(start[-1][0], start[-1][1])\n",
    "                normlized_field_real    = dataset.addseasonal(end[0], end[1])\n",
    "                abs_loss = criterion(normlized_field_predict,normlized_field_real)\n",
    "        elif '68pixelnorm' in dataset.__class__.__name__:\n",
    "            loss  += criterion(ltmv_pred,target)+ extra_loss\n",
    "            with torch.no_grad():\n",
    "                normlized_field_predict = dataset.recovery(start[-1])\n",
    "                normlized_field_real    = dataset.recovery(end)\n",
    "                abs_loss = criterion(normlized_field_predict,normlized_field_real)\n",
    "        else:\n",
    "            normlized_field_predict = ltmv_pred\n",
    "            normlized_field_real = target\n",
    "            abs_loss = criterion[pred_step](ltmv_pred,target) if isinstance(criterion,(dict,list)) else criterion(ltmv_pred,target)\n",
    "            loss += abs_loss + extra_loss\n",
    "        \n",
    "        diff += abs_loss\n",
    "        print(abs_loss)\n",
    "        pred_step+=1\n",
    "        \n",
    "        if hasattr(model,\"consistancy_alpha\") and model.consistancy_alpha and loss < model.consistancy_activate_wall: \n",
    "            hidden_fourcast_list,full_fourcast_error_list,extra_loss2 = full_fourcast_forward(model,criterion,full_fourcast_error_list,ltmv_pred,target,hidden_fourcast_list)\n",
    "            save_list.append([ltmv_pred] + hidden_fourcast_list)\n",
    "            if hasattr(model,\"vertical_constrain\") and model.vertical_constrain and len(hidden_fourcast_list)>=2:\n",
    "                all_hidden_fourcast_list = [ltmv_pred]+hidden_fourcast_list\n",
    "                first_level_error_tensor = all_hidden_fourcast_list[-1] - all_hidden_fourcast_list[-2] #epsilon_2^I\n",
    "                for il in range(len(all_hidden_fourcast_list)-2):\n",
    "                    hidden_error_tensor = all_hidden_fourcast_list[-2] - all_hidden_fourcast_list[il]\n",
    "                    verticalQ = torch.mean((hidden_error_tensor*first_level_error_tensor)**2) # <epsilon_2^I|epsilon_2^II-epsilon_2^I>\n",
    "                    iter_info_pool[f'{status}_vertical_error_{i}_{il}_gpu{gpu}'] =  verticalQ.item()\n",
    "                    extra_loss2+= model.vertical_constrain*verticalQ # we only\n",
    "            if not model.consistancy_eval:loss+= extra_loss2\n",
    "            \n",
    "                \n",
    "        iter_info_pool[f'{status}_abs_loss_gpu{gpu}_timestep{i}'] =  abs_loss.item()\n",
    "        if status != \"train\":\n",
    "            iter_info_pool[f'{status}_accu_gpu{gpu}_timestep{i}']     =  compute_accu(normlized_field_predict,normlized_field_real).mean().item()\n",
    "            iter_info_pool[f'{status}_rmse_gpu{gpu}_timestep{i}']     =  compute_rmse(normlized_field_predict,normlized_field_real).mean().item()\n",
    "        if model.random_time_step_train and i >= random_run_step:\n",
    "            break\n",
    "    if hasattr(model,\"consistancy_alpha\") and model.consistancy_alpha and loss < model.consistancy_activate_wall:\n",
    "        ltmv_pred, target, extra_loss, extra_info_from_model_list, start = once_forward(model,i,start,None,dataset,time_step_1_mode) \n",
    "        ltmv_pred = dataset.do_normlize_data([ltmv_pred])[0]\n",
    "        hidden_fourcast_list,full_fourcast_error_list,extra_loss2 = full_fourcast_forward(model,criterion,full_fourcast_error_list,ltmv_pred,None,hidden_fourcast_list)\n",
    "        if not model.consistancy_eval:loss+= extra_loss2\n",
    "        for iii, val in enumerate(full_fourcast_error_list):\n",
    "            if val >0: iter_info_pool[f'{status}_full_fourcast_error_{iii}_gpu{gpu}'] =  val\n",
    "        save_list.append([ltmv_pred] + hidden_fourcast_list)\n",
    "    # loss = loss/(len(batch) - 1)\n",
    "    # diff = diff/(len(batch) - 1)\n",
    "    loss = loss/pred_step\n",
    "    diff = diff/pred_step\n",
    "    return loss, diff, iter_info_pool, ltmv_pred,save_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "914df35c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.activate_stamps, model.activate_error_coef =([[1,2,3],[2,3],[3]], [[0,1,1, 2.5, \"quantity\"], \n",
    "                           [0,2,2, 2.5, \"quantity\"],\n",
    "                           [1,2,2, 2.5, \"quantity\"],\n",
    "                           [1,3,3, 2.5, \"quantity\"],\n",
    "                           [2,3,3, 2.5, \"quantity\"]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78bd3d04",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9006b1b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(enabled=False):\n",
    "        loss1, diff1, iter_info_pool1, ltmv_pred1, save_list1 = run_one_iter_highlevel_fast(model, batch, criterion, status, gpu, train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f572c65",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$(X_{t}),(X_{t+1}),(X_{t+2})$\n",
    "\n",
    "$f(X_{t}),f(X_{t+1}),f(X_{t+2})$\n",
    "\n",
    "$f(f(X_{t})),f(f(X_{t+1}))$\n",
    "\n",
    "$f(f(f(X_{t})))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83363008",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0086, device='cuda:0')\n",
      "tensor(1.8527, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.consistancy_eval  = 0\n",
    "model.consistancy_alpha = [1,1,1]\n",
    "model.vertical_constrain= 0\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(enabled=False):\n",
    "        loss2, diff2, iter_info_pool2, ltmv_pred2, save_list2 = run_one_iter_normal(model, batch, criterion, status, gpu, train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01d828cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.9307, device='cuda:0'), tensor(1.9307, device='cuda:0'))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff1,diff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d31202cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.2378, device='cuda:0'), tensor(4.2378, device='cuda:0'))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1,loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7476367",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(len(t)) for t in save_list2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec99bf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "None --> None | $f(X_{t}), X_{t+1}$\n",
    "\n",
    "f(f(X_{t})) --> $f(f(X_{t})),f(X_{t+1}),X_{t+2}$\n",
    "   \n",
    "f(f(f(X_{t}))) --> $f(f(f(X_{t}))),f(f(X_{t+1})),f(X_{t+2})| X_{t+3}=None$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc3e86",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> 傅里叶变换罪大恶极， 12层的傅里叶变换直接带来精度误差的放大积累"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fdf16d97",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def process(model,x):\n",
    "#     shape = x.shape\n",
    "#     #print(x.shape)\n",
    "#     # argue the w resolution.\n",
    "#     pad = model.get_w_resolution_pad(shape)\n",
    "#     if pad is not None:\n",
    "#         x = F.pad(x.flatten(0,1),(0,0,pad,pad),mode='replicate').reshape(*shape[:-2],-1,shape[-1])\n",
    "#     #print(x.shape)\n",
    "#     B = x.shape[0]\n",
    "#     ot_shape = x.shape[2:]\n",
    "#     x = x.reshape(B,-1,*model.img_size)# (B, p, z, h, w) or (B, p, h, w)\n",
    "#     #timer.restart(level=0)\n",
    "#     #print(torch.std_mean(x))\n",
    "# ####    x = model.forward_features(x);#print(torch.std_mean(x))\n",
    "#     B = x.shape[0]\n",
    "#     x = model.patch_embed(x)\n",
    "#     x += model.pos_embed\n",
    "#     x = model.pos_drop(x)\n",
    "#     #print(torch.std_mean(x))\n",
    "#     for i,blk in enumerate(model.blocks):\n",
    "#         #x = blk(x);#print(torch.std_mean(x))\n",
    "#         x = blk.norm1(x)\n",
    "        \n",
    "#         #timer.record('norm1','forward_features',1)\n",
    "#         x = blk.filter(x)\n",
    "#         if i==0:break\n",
    "#         #timer.record('filter','forward_features',1)\n",
    "#         if blk.double_skip:\n",
    "#             x += residual\n",
    "#             residual = x;\n",
    "            \n",
    "#         #timer.record('residual','forward_features',1)\n",
    "#         x = blk.norm2(x)\n",
    "#         #timer.record('norm2','forward_features',1)\n",
    "#         x = blk.mlp(x)\n",
    "#         #timer.record('mlp','forward_features',1)\n",
    "#         x = blk.drop_path(x)\n",
    "#         #timer.record('drop_path','forward_features',1)\n",
    "        \n",
    "#         x += residual\n",
    "        \n",
    "# #    x = model.norm(x).transpose(1, 2);\n",
    "# #    x = torch.reshape(x, [-1, model.embed_dim, *model.final_shape])\n",
    "# #     #timer.record('forward_features',level=0)\n",
    "# #     x = model.final_dropout(x)\n",
    "# #     #timer.record('final_dropout',level=0)\n",
    "# #     x = model.pre_logits(x);#print(torch.std_mean(x))\n",
    "# #     #timer.record('pre_logits',level=0)\n",
    "# #     x = model.head(x)  # print(torch.std_mean(x))\n",
    "# #     if model.history_length >1:\n",
    "# #         x = x.flatten(1,2).transpose(1,-1)\n",
    "# #         x = model.last_Linear_layer(x)\n",
    "# #         x = x.transpose(1,-1)\n",
    "# #         ot_shape=ot_shape[1:]\n",
    "# #     #timer.record('head',level=0)\n",
    "# #     x = x.reshape(B,-1,*ot_shape)\n",
    "# #     if pad is not None:\n",
    "# #         x = x[...,pad:-pad,:]\n",
    "\n",
    "#     return x    \n",
    "\n",
    "# now_level_batch = torch.stack(batch,1)\n",
    "# with torch.no_grad():\n",
    "#     should1 = process(model,now_level_batch[:,0])\n",
    "#     should2 = process(model,now_level_batch[0])[0]\n",
    "#     print(torch.dist(should1, should2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c710c06e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.0003, device='cuda:0')\n",
      "tensor(0.0002, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.0004, device='cuda:0')\n",
      "tensor(0.0003, device='cuda:0')\n",
      "tensor(0.0002, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.dist(save_list2[0][0],save_list1[1][:,0]))\n",
    "print(torch.dist(save_list2[0][1],save_list1[0][:,1]))\n",
    "print(torch.dist(save_list2[1][0],save_list1[2][:,0]))\n",
    "print(torch.dist(save_list2[1][1],save_list1[1][:,1]))\n",
    "print(torch.dist(save_list2[1][2],save_list1[0][:,2]))\n",
    "print(torch.dist(save_list2[2][0],save_list1[3][:,0]))\n",
    "print(torch.dist(save_list2[2][1],save_list1[2][:,1]))\n",
    "print(torch.dist(save_list2[2][2],save_list1[1][:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b6952",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master_bar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmaster_bar\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m<\u001b[39m start_epoch:\u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m):model\u001b[38;5;241m.\u001b[39mset_epoch(epoch\u001b[38;5;241m=\u001b[39mepoch,epoch_total\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mepochs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master_bar' is not defined"
     ]
    }
   ],
   "source": [
    "# for epoch in mastera_bar:\n",
    "#     if epoch < start_epoch:continue\n",
    "#     if hasattr(model,'set_epoch'):model.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "#     if hasattr(model,'module') and hasattr(model.module,'set_epoch'):model.module.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "#     logsys.record('learning rate',optimizer.param_groups[0]['lr'],epoch, epoch_flag='epoch')\n",
    "#     train_loss = run_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,logsys,'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e3a26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset_tensor=None;\n",
    "train_record_load=None;\n",
    "valid_dataset_tensor=None;\n",
    "valid_record_load=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b458ea",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =======================> start training <==========================\n",
    "print(f\"entering {args.mode} training in {next(model.parameters()).device}\")\n",
    "now_best_path = SAVE_PATH / 'backbone.best.pt'\n",
    "latest_ckpt_p = SAVE_PATH / 'pretrain_latest.pt'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, train_dataloader,val_dataloader = get_train_and_valid_dataset(args,\n",
    "               train_dataset_tensor=train_dataset_tensor,train_record_load=train_record_load,\n",
    "               valid_dataset_tensor=valid_dataset_tensor,valid_record_load=valid_record_load)\n",
    "logsys.info(f\"use dataset ==> {train_dataset.__class__.__name__}\")\n",
    "logsys.info(f\"Start training for {args.epochs} epochs\")\n",
    "metric_list = ['loss']\n",
    "master_bar        = logsys.create_master_bar(args.epochs)\n",
    "master_bar.set_multiply_graph(figsize=(9,3),engine=[['plot','plot']],labels=[metric_list])\n",
    "for epoch in master_bar:\n",
    "    if epoch < start_epoch:continue\n",
    "    if hasattr(model,'set_epoch'):model.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "    if hasattr(model,'module') and hasattr(model.module,'set_epoch'):model.module.set_epoch(epoch=epoch,epoch_total=args.epochs)\n",
    "    logsys.record('learning rate',optimizer.param_groups[0]['lr'],epoch)\n",
    "    train_loss = run_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,logsys,'train')\n",
    "    if (not args.more_epoch_train) and (lr_scheduler is not None):lr_scheduler.step(epoch)\n",
    "    #torch.cuda.empty_cache()\n",
    "    #train_loss = single_step_evaluate(train_dataloader, model, criterion,epoch,logsys,status='train') if 'small' in args.train_set else -1\n",
    "    val_loss   = run_one_epoch(epoch, start_step, model, criterion, val_dataloader, optimizer, loss_scaler,logsys,'valid')\n",
    "\n",
    "    if (not args.distributed) or (args.rank == 0 and local_rank == 0) :\n",
    "        logsys.info(f\"Epoch {epoch} | Train loss: {train_loss:.6f}, Val loss: {val_loss:.6f}\")\n",
    "        logsys.record('train', train_loss, epoch)\n",
    "        logsys.record('valid', val_loss, epoch)\n",
    "        if use_wandb:wandb.log({\"epoch\":epoch,'train':train_loss,'valid':val_loss})\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            if epoch > args.epochs//10:\n",
    "                logsys.info(f\"saving best model ....\")\n",
    "                save_model(model, path=now_best_path, only_model=True)\n",
    "                logsys.info(f\"done;\")\n",
    "            #if last_best_path is not None:os.system(f\"rm {last_best_path}\")\n",
    "            #last_best_path= now_best_path\n",
    "            logsys.info(f\"The best accu is {val_loss}\")\n",
    "        logsys.record('best_loss', min_loss, epoch)\n",
    "        update_experiment_info(experiment_hub_path,epoch,args)\n",
    "        if epoch>args.save_warm_up:\n",
    "            logsys.info(f\"saving latest model ....\")\n",
    "            save_model(model, epoch+1, 0, optimizer, lr_scheduler, loss_scaler, min_loss, latest_ckpt_p)\n",
    "            logsys.info(f\"done ....\")\n",
    "\n",
    "if os.path.exists(now_best_path) and args.do_final_fourcast:\n",
    "    logsys.info(f\"we finish training, then start test on the best checkpoint {now_best_path}\")\n",
    "    start_epoch, start_step, min_loss = load_model(model.module if args.distributed else model, path=now_best_path, only_model=True)\n",
    "    run_fourcast(args, model,logsys)\n",
    "if use_wandb:wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fbe32",
   "metadata": {
    "code_folding": [
     0,
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if local_rank == 0:\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "\n",
    "master_bar        = logsys.create_master_bar(args.epochs)\n",
    "last_best_path = None\n",
    "for epoch in master_bar:\n",
    "    if epoch < start_epoch:continue\n",
    "    train_one_epoch(epoch, start_step, model, criterion, train_dataloader, optimizer, loss_scaler,lr_scheduler, min_loss,logsys)\n",
    "    lr_scheduler.step(epoch)\n",
    "    #torch.cuda.empty_cache()\n",
    "    train_loss = single_step_evaluate(train_dataloader, model, criterion,epoch,logsys)\n",
    "    #train_loss = -1\n",
    "    val_loss   = single_step_evaluate(val_dataloader, model, criterion,epoch,logsys)\n",
    "\n",
    "    if rank == 0 and local_rank == 0:\n",
    "        print(f\"Epoch {epoch} | Train loss: {train_loss:.6f}, Val loss: {val_loss:.6f}\")\n",
    "        logsys.record('train', train_loss, epoch)\n",
    "        logsys.record('valid', val_loss, epoch)\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print(f\"saving best model ....\")\n",
    "            now_best_path = SAVE_PATH / f'backbone.best.pt'\n",
    "            if epoch>args.save_warm_up:save_model(model, path=now_best_path, only_model=True)\n",
    "            #if last_best_path is not None:os.system(f\"rm {last_best_path}\")\n",
    "            #last_best_path= now_best_path\n",
    "            print(f\"done; the best accu is {val_loss}\")\n",
    "        logsys.record('best_loss', min_loss, epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c43ef",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    ngpus = ngpus_per_node = torch.cuda.device_count()\n",
    "    args.world_size = -1\n",
    "    args.dist_file  = None\n",
    "    args.rank       = 0\n",
    "    args.dist_backend = \"nccl\"\n",
    "    args.multiprocessing_distributed = ngpus>1\n",
    "    if not hasattr(args,'train_set'):args.train_set='large'\n",
    "    ip = os.environ.get(\"MASTER_ADDR\", \"127.0.0.1\")\n",
    "    port = os.environ.get(\"MASTER_PORT\", \"54247\")\n",
    "    hosts = int(os.environ.get(\"WORLD_SIZE\", \"1\"))  # number of nodes\n",
    "    rank = int(os.environ.get(\"RANK\", \"0\"))  # node id\n",
    "    gpus = torch.cuda.device_count()  # gpus per node\n",
    "    args.dist_url = f\"tcp://{ip}:{port}\"\n",
    "    if args.world_size == -1 and \"SLURM_NPROCS\" in os.environ:\n",
    "        args.world_size = int(os.environ[\"SLURM_NPROCS\"])\n",
    "        args.rank       = int(os.environ[\"SLURM_PROCID\"])\n",
    "        jobid           = os.environ[\"SLURM_JOBID\"]\n",
    "\n",
    "        hostfile        = \"dist_url.\" + jobid  + \".txt\"\n",
    "        if args.dist_file is not None:\n",
    "            args.dist_url = \"file://{}.{}\".format(os.path.realpath(args.dist_file), jobid)\n",
    "        elif args.rank == 0:\n",
    "            import socket\n",
    "            ip = socket.gethostbyname(socket.gethostname())\n",
    "            port = find_free_port()\n",
    "            args.dist_url = \"tcp://{}:{}\".format(ip, port)\n",
    "            #with open(hostfile, \"w\") as f:f.write(args.dist_url)\n",
    "        else:\n",
    "            import os\n",
    "            import time\n",
    "            while not os.path.exists(hostfile):\n",
    "                time.sleep(1)\n",
    "            with open(hostfile, \"r\") as f:\n",
    "                args.dist_url = f.read()\n",
    "        print(\"dist-url:{} at PROCID {} / {}\".format(args.dist_url, args.rank, args.world_size))\n",
    "    else:\n",
    "        args.world_size = 1\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "    train_dataset_tensor=valid_dataset_tensor=None\n",
    "\n",
    "    print(\"======== loading data ==========\")\n",
    "    if 'small' in args.train_set:\n",
    "        if not args.fourcast:\n",
    "            train_dataset_tensor = load_small_dataset_in_memory('train').share_memory_()\n",
    "            valid_dataset_tensor = load_small_dataset_in_memory('valid').share_memory_()\n",
    "        else:\n",
    "            train_dataset_tensor = load_small_dataset_in_memory('test').share_memory_()\n",
    "            valid_dataset_tensor = None\n",
    "    else:\n",
    "        if args.fourcast:\n",
    "            train_dataset_tensor = load_test_dataset_in_memory(years=[2018],root=\"/nvme/zhangtianning/datasets/ERA5\").share_memory_()\n",
    "            valid_dataset_tensor = None\n",
    "    print(\"=======done==========\")\n",
    "    print(train_dataset_tensor.shape)\n",
    "    if args.multiprocessing_distributed:\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        torch.multiprocessing.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args,train_dataset_tensor,valid_dataset_tensor))\n",
    "    else:\n",
    "        main_worker(0, ngpus_per_node, args,train_dataset_tensor,valid_dataset_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b4e50d8356ba75a9636787f9051ee458aaf13e87df491415cc800c7b2b8a21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
