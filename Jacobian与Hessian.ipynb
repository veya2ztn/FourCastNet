{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca86263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b603a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import functorch\n",
    "from functorch import jacrev\n",
    "from functorch import make_functional, vmap, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be03745b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super().__init__()\n",
    "        self.backbone = torch.nn.Linear(in_chan, out_chan,bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9202bc26",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from functorch import make_functional, vmap, grad\n",
    "model= MyModel(3, 4)\n",
    "x    = torch.randn(7, 3)\n",
    "func_model, params = make_functional(model)\n",
    "w    = params[0]\n",
    "batch_J= vmap(jacrev(func_model, argnums=1), (None, 0))(params, x)\n",
    "batch_H= jacrev(vmap(jacrev(func_model, argnums=1), (None, 0)), argnums=0)(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a593fc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_J.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5611e08",
   "metadata": {},
   "source": [
    "这里设定\n",
    "$$\n",
    "Y=(W^TX)^2 则 Y_{j}=(\\sum W_{jk}X_k)^2\n",
    "$$\n",
    "\n",
    "那么 \n",
    "$$\n",
    "\\frac{dY_{j}}{dX_{\\alpha}}=2 (\\sum W_{jk}X_k) (\\sum W_{jk}\\delta_{\\alpha k})=2 (\\sum W_{jk}X_k) W_{j\\alpha}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a744a",
   "metadata": {},
   "source": [
    "首先来看 Jacobian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07e2772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "y1 = torch.einsum('ij,bj->bi',w,x)\n",
    "yx = 2*torch.einsum('bi,ik->bik',y1,w)\n",
    "print(torch.allclose(yx,batch_J))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819284f",
   "metadata": {},
   "source": [
    "再来看 Hessian\n",
    "\n",
    "那么 \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d^2Y_{j}}{dW_{\\beta\\gamma}dX_{\\alpha}}\n",
    "&=\\frac{d}{dW_{\\beta\\gamma}}\\frac{dY_{j}}{dX_{\\alpha}}=2 \\frac{d}{dW_{\\beta\\gamma}}(\\sum_k W_{jk}X_k) W_{j\\alpha}\\\\\n",
    "&=2 (\\sum_k \\delta_{jk}^{\\beta\\gamma} X_k)  W_{j\\alpha} + 2 (\\sum_k W_{jk}X_k)\\delta_{j\\alpha}^{\\beta\\gamma}\\\\\n",
    "&=2 (\\delta_{j}^{\\beta} X_{\\gamma})W_{j\\alpha} +2 (\\sum_k W_{jk}X_k)\\delta_{j}^{\\beta}\\delta_{\\alpha}^{\\gamma}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f794b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "dta1 = torch.eye(w.shape[0],w.shape[0])\n",
    "dta2 = torch.eye(w.shape[1],x.shape[1])\n",
    "\n",
    "h=2*torch.einsum('bj,Bg,ja   ->Bjabg',dta1,x,w) \\\n",
    " +2*torch.einsum('jk,Bk,bj,ga->Bjabg',w,x,dta1,dta2)\n",
    "print(torch.allclose(h,batch_H[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aee316",
   "metadata": {},
   "source": [
    "#### 我们也可以直接来计算正则项的导数\n",
    "$$\n",
    "P^{\\gamma}=< y^\\gamma,t^\\gamma >+\\lambda_1 (\\sum_\\alpha J_\\alpha^{\\gamma}-1)^2+\\lambda_2 [\\sum_\\alpha (J_\\alpha^{\\gamma})^2-1]^2\n",
    "$$\n",
    "\n",
    "如果我们的函数是 $Y = (WX)**2$ 即 $y_j = (\\sum_k W_{jk}X_k)^2$ 那么\n",
    "\n",
    "$$\n",
    "J_\\alpha^\\gamma = \\frac{dY_{\\gamma}}{dX_{\\alpha}}=2 (\\sum_k W_{\\gamma k}X_k) (\\sum_k W_{\\gamma k}\\delta_{\\alpha k})=2 (\\sum_k W_{\\gamma k}X_k) W_{\\gamma\\alpha}\n",
    "$$\n",
    "\n",
    "那么我们可以显式的得到 \n",
    "$$\n",
    "\\sum_\\alpha J_\\alpha^{\\gamma} = \\sum_\\alpha 2 (\\sum_k W_{\\gamma k}X_k) W_{j\\alpha} = 2 (\\sum_k W_{\\gamma k}X_k) \\sum_\\alpha W_{\\gamma\\alpha}\n",
    "$$\n",
    "\n",
    "我们的 L1 约束是对每一个上标 $(\\sum_\\alpha J_\\alpha^{\\gamma}-1)^2$ 都极小, 在这个 toy 模型里面, $\\gamma$ 只是 $W$ 的某一行, 所以我们现在去掉上标 $W_{\\gamma k}\\rightarrow w_k$, 得到\n",
    "$$\n",
    "P(w) = <w|x><w|\\mathbf{1}>\n",
    "$$\n",
    "再给定 |x> 的情况下, 我们要观察 $P(w) =1$ 这个解是否存在, 以及他是否是 $(P(w)-1)^2$ 的极小值解.\n",
    "\n",
    "注意 |x> 是一个 batch tensor, 意思是我们会要求所有的 x 都要满足 $P(w;x) =1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff7eea",
   "metadata": {},
   "source": [
    "我们不妨假设 $\\sum_\\alpha w_{\\alpha} = 1/\\Lambda$ 为一个常数. 那么就得到方程组(n个未知数,一个方程,必有解, 如果有B个 Batch 那么总的方程数是B, 所以最后存在解的条件就是参数量要大于数据量)\n",
    "$$\n",
    "w_1+w_2+\\dots+w_n = 1/\\Lambda\\\\\n",
    "w_1x_1+w_2x_2+\\dots+w_nx_n = \\Lambda\n",
    "$$\n",
    "有柯西不等式和基本不等式\n",
    "$$\n",
    "\\Lambda = \\sum_i (w_ix_i) \\leq \\sqrt{\\sum_i w_i^2 \\sum_i x_i^2} \\leq \\sqrt{(\\sum_i w_i)^2 \\sum_i x_i^2} = |\\frac{1}{\\Lambda}| \\sqrt{ \\sum_i x_i^2}\n",
    "$$\n",
    "也就是\n",
    "$$\n",
    "\\Lambda^2 \\leq \\sqrt{ \\sum_i x_i^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cae4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ad282637",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "B=20\n",
    "I=10\n",
    "O=30\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super().__init__()\n",
    "        self.backbone = torch.nn.Linear(in_chan, out_chan,bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)**2\n",
    "model= MyModel(I, O)\n",
    "x    = torch.randn(B, I)\n",
    "cotangents = torch.ones(B,I)\n",
    "func_model, params = make_functional(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0401a239",
   "metadata": {},
   "source": [
    "##### 验证 estimate 的效果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857749e",
   "metadata": {},
   "source": [
    "- $||A||_F^2=Tr(AA^T) = \\frac{1}{m}\\sum_i^m v_i AA^T v_i^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7bfc1e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4923.3936)\n",
      "tensor(4981.4468)\n"
     ]
    }
   ],
   "source": [
    "O = 100\n",
    "I = 50 \n",
    "sample_times = 100\n",
    "A = torch.randn(O,I)\n",
    "v = torch.randint(2,(100, O))*2-1\n",
    "v = v.float()\n",
    "ground_truth = (A**2).sum()\n",
    "estima_value = torch.einsum('bi,ij,lj,bl->b',v,A,A,v).mean()\n",
    "print(ground_truth)\n",
    "print(estima_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578af569",
   "metadata": {},
   "source": [
    "- $Var(\\sum_i^m v_i A v_i^T) = 2(||A||_F^2 - \\sum_{i}^n A_{ii})$\n",
    "\n",
    "sample_times 没必要太大就有比较好的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "91ced50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(289.8571)\n",
      "tensor(277.1272)\n"
     ]
    }
   ],
   "source": [
    "O = 10\n",
    "sample_times = 10\n",
    "A = torch.randn(O,O) \n",
    "A = A+A.transpose(1,0)\n",
    "v = torch.randint(2,(sample_times, O))*2-1\n",
    "v = v.float()\n",
    "ground_truth = 2*((A**2).sum() - (A**2).trace())\n",
    "estima_value = torch.einsum('bi,il,bl->b',v,A,v).var()\n",
    "print(ground_truth)\n",
    "print(estima_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119b7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "259c0b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('bi,ij,lj,bl->b',v,A,A,v).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6154a",
   "metadata": {},
   "source": [
    "压力测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.afnonet import AFNONet\n",
    "# model = AFNONet((32,64),2,1,1).cuda()\n",
    "# func_model, params = make_functional(model)\n",
    "# x = torch.randn(4,1,32,64).cuda()\n",
    "# cotangents=torch.ones_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eaa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_memlab import MemReporter\n",
    "# reporter = MemReporter()\n",
    "# reporter.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8f5c15",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import functorch\n",
    "from functorch import jacrev,jacfwd\n",
    "from functorch import make_functional, vmap, grad\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "018ebb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.afnonet import AFNONet\n",
    "# model = AFNONet((32,64),2,110,110).cuda()\n",
    "# func_model, params = make_functional(model)\n",
    "# x = torch.randn(4,110,32,64).cuda()\n",
    "# y = torch.randn(4,110,32,64).cuda()\n",
    "# optimzer= torch.optim.Adam(model.parameters())\n",
    "# shape = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7550a7c",
   "metadata": {
    "code_folding": [
     1,
     17,
     23,
     28,
     30
    ]
   },
   "outputs": [],
   "source": [
    "class Nodal_GradientModifier:\n",
    "    def __init__(self,lambda1=1,lambda2=1,sample_times=10):\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.sample_times = sample_times\n",
    "        self.cotangents_sum_along_x_dimension = None\n",
    "    def Normlization_Term_1(self,params,x):\n",
    "        if self.cotangents_sum_along_x_dimension is None or self.cotangents_sum_along_x_dimension.shape!=x.shape:\n",
    "            self.cotangents_sum_along_x_dimension = torch.ones_like(x)\n",
    "        return ((functorch.jvp(lambda x:self.func_model(params,x), (x,), (self.cotangents_sum_along_x_dimension,))[1]-1)**2).mean()\n",
    "    def TrvJOJv_and_ETrAAT(self,params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        dims = list(range(1,len(vJ.shape)))\n",
    "        vJO  = vJ.sum(dims,keepdims=True)-vJ # <vJ|1-I|\n",
    "        vJOJv= (vJ*vJO).sum(dims)#should sum over all dimension except batch\n",
    "        return vJOJv, functorch.jvp(lambda x:self.func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "    def get_TrvJOJv(self,params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "        vJOJv= (vJ*vJO).sum(-1)#should sum over all dimension except batch\n",
    "        return vJOJv\n",
    "    def get_ETrAAT(self,params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "        return functorch.jvp(lambda x:self.func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "    def get_ETrAAT_times(self,params,x,cotangents_variables):\n",
    "        return vmap(get_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "    def get_TrvJOJv_times(self,params,x,cotangents_variables):\n",
    "        return vmap(self.get_TrvJOJv, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "    def Normlization_Term_2(self,params,x,cotangents_variables):\n",
    "        TrvJOJvs,ETrAATs =  vmap(self.TrvJOJv_and_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables)\n",
    "        return ETrAATs.mean() - torch.var(TrvJOJvs,0).mean()\n",
    "    def Normlization_Term_2_Full(self,params,x,cotangents_variables):\n",
    "        return (((vmap(jacrev(self.func_model, argnums=1), (None, 0))(params, x)**2).sum(-1)-1)**2).mean()   \n",
    "    \n",
    "    def backward(self,model, x, y , return_Normlization_Term_1=False, return_Normlization_Term_2=False):\n",
    "        \n",
    "        self.func_model, params =  make_functional(model)\n",
    "        shape = y.shape\n",
    "        cotangents_variables = torch.randint(2,(self.sample_times,*shape)).cuda()*2-1\n",
    "        with torch.no_grad():\n",
    "            if self.lambda1 != 0:\n",
    "                Derivation_Term_1 = jacrev(self.Normlization_Term_1, argnums=0)(params, x)\n",
    "            if self.lambda2 != 0:\n",
    "                Derivation_Term_2 = jacrev(self.Normlization_Term_2, argnums=0)(params, x,cotangents_variables)\n",
    "        for i, param in enumerate(model.parameters()):\n",
    "            delta_p = 0\n",
    "            if self.lambda1 != 0:delta_p += self.lambda1*Derivation_Term_1[i]\n",
    "            if self.lambda2 != 0:delta_p += self.lambda2*Derivation_Term_2[i]\n",
    "            if param.grad is not None:\n",
    "                param.grad.data += delta_p\n",
    "            else:\n",
    "                param.grad = delta_p\n",
    "        with torch.no_grad():\n",
    "            if return_Normlization_Term_1: \n",
    "                return self.Normlization_Term_1(params, x)\n",
    "            if return_Normlization_Term_2:\n",
    "                return self.Normlization_Term_2(params, x,cotangents_variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c6164",
   "metadata": {},
   "source": [
    "$\\sum_\\beta\\sum_{\\alpha\\neq\\beta} J_\\alpha^{\\gamma}J_\\beta^{\\gamma} \\rightarrow 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e5f0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=1\n",
    "I=10\n",
    "O=30\n",
    "model= MyModel(I, O).cuda()\n",
    "x    = torch.randn(B, I).cuda()\n",
    "y    = torch.randn(B, O).cuda()\n",
    "shape = y.shape\n",
    "sample_times=1000\n",
    "func_model, params =  make_functional(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33ea5df7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def CorrelationTerm(params,x,cotangents_variable):\n",
    "    '''\n",
    "    \\sum_\\beta\\sum_{\\alpha\\neq\\beta} J_\\alpha^{\\gamma}J_\\beta^{\\gamma}\n",
    "    '''\n",
    "    J = vmap(jacrev(func_model, argnums=1), (None, 0))(params, x) #(B, O, I)\n",
    "    B, O, I =J.shape\n",
    "    K = torch.ones(I,I) - torch.eye(I,I)\n",
    "    K = K.to(J.device)\n",
    "    # L^\\gamma = \\sum_\\beta\\sum_{\\alpha\\neq\\beta} J_\\alpha^{\\gamma}J_\\beta^{\\gamma}\n",
    "    C = torch.einsum('bij,jk,bik->bi',J,K,J) #(B,O)  L^\\gamma\n",
    "    C = (C**2).sum(-1) #(B) \\sum_\\gamma (L^\\gamma)^2\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "390698c3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def TrvJOJv_and_ETrAAT(params,x,cotangents_variable):\n",
    "    _, vJ_fn = functorch.vjp(lambda x:func_model(params,x), x)\n",
    "    vJ   = vJ_fn(cotangents_variable)[0]\n",
    "    dims = list(range(1,len(vJ.shape)))\n",
    "    vJO  = vJ.sum(dims,keepdims=True)-vJ # <vJ|1-I|\n",
    "    vJOJv= (vJ*vJO).sum(dims)#should sum over all dimension except batch\n",
    "    return vJOJv, functorch.jvp(lambda x:func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb1e8d3c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def Normlization_Term_2(params,x,cotangents_variables):\n",
    "    TrvJOJvs,ETrAATs =  vmap(TrvJOJv_and_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables)\n",
    "    return ETrAATs.mean() - torch.var(TrvJOJvs,0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32e390ff",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.7047, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ground_truth = CorrelationTerm(params,x,None)[0]\n",
    "    print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c4124a3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-70.0145, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    TrvJOJvs,ETrAATs = vmap(TrvJOJv_and_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables)\n",
    "    print(ETrAATs.mean() - torch.var(TrvJOJvs,0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64ebee1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrvJOJvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfb3806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETrAATs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61d86050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2106140851974487\n",
      "-280.4579162597656\n"
     ]
    }
   ],
   "source": [
    "B=1\n",
    "I=10\n",
    "O=30\n",
    "model= MyModel(I, O).cuda()\n",
    "x    = torch.randn(B, I).cuda()\n",
    "y    = torch.randn(B, O).cuda()\n",
    "shape = y.shape\n",
    "sample_times=1000\n",
    "\n",
    "grad_modifier.func_model, params =  make_functional(model)\n",
    "with torch.no_grad():\n",
    "    ground_truth = grad_modifier.Normlization_Term_2_Full(params,x,None)\n",
    "with torch.no_grad():\n",
    "    cotangents_variables = torch.randint(2,(sample_times,*shape)).cuda()*2-1\n",
    "    esimat_value = grad_modifier.Normlization_Term_2(params,x,cotangents_variables)\n",
    "print(ground_truth.item())\n",
    "print(esimat_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785994b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8256dda2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# the position of gradient modifier(before `loss.backward` or after `loss.backward`) does not effect the result\n",
    "##############################################################################################################\n",
    "B=20\n",
    "I=10\n",
    "O=30\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super().__init__()\n",
    "        self.backbone = torch.nn.Linear(in_chan, out_chan,bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)**2\n",
    "model= MyModel(I, O).cuda()\n",
    "x    = torch.randn(B, I).cuda()\n",
    "y    = torch.randn(B, O).cuda()\n",
    "func_model, params = make_functional(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(),1)\n",
    "\n",
    "model.load_state_dict(torch.load('debug/model.weight.pt'))\n",
    "x = torch.load('debug/input.pt')\n",
    "y = torch.load('debug/ouput.pt')\n",
    "\n",
    "#optimizer = SGD_Nodel(model.parameters(),1)\n",
    "#optimzer= torch.optim.Adam(model.parameters())\n",
    "\n",
    "accues= []\n",
    "grad_modifier = Nodal_GradientModifier()\n",
    "weight_beg = model.backbone.weight.cpu().detach().numpy()\n",
    "# for _ in tqdm(range(1000)):\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = F.mse_loss(model(x),y)\n",
    "loss.backward()\n",
    "grad_modifier.backward(model,x,y)\n",
    "gradient = model.backbone.weight.grad.cpu().detach().numpy()\n",
    "\n",
    "optimizer.step()\n",
    "#     accues.append(accu.item())\n",
    "weight_end = model.backbone.weight.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4bf461a",
   "metadata": {
    "code_folding": [
     8,
     9
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011625289916992188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b07174deb94b0990d0035efd6b91f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f6deac310>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the goal about achieve zero loss is depended on the Batch size and the number of data\n",
    "##############################################################################################################\n",
    "%matplotlib inline\n",
    "from mltool.visualization import *\n",
    "from tqdm.notebook import tqdm\n",
    "B=20\n",
    "I=100\n",
    "O=300\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super().__init__()\n",
    "        self.backbone = torch.nn.Linear(in_chan, out_chan,bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)**2\n",
    "model= MyModel(I, O).cuda()\n",
    "x    = torch.randn(B, I).cuda()\n",
    "y    = torch.randn(B, O).cuda()\n",
    "func_model, params = make_functional(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(),1)\n",
    "\n",
    "#optimizer = SGD_Nodel(model.parameters(),1)\n",
    "#optimzer= torch.optim.Adam(model.parameters())\n",
    "\n",
    "accues= []\n",
    "grad_modifier = Nodal_GradientModifier(1,0)\n",
    "#weight_beg = model.backbone.weight.cpu().detach().numpy()\n",
    "for _ in tqdm(range(100)):\n",
    "    optimizer.zero_grad()\n",
    "    # loss = F.mse_loss(model(x),y)\n",
    "    # loss.backward()\n",
    "    #gradient = model.backbone.weight.grad.cpu().detach().numpy()\n",
    "    accu=grad_modifier.backward(model,x,y,return_Normlization_Term_1=True)\n",
    "    optimizer.step()\n",
    "    accues.append(accu.item())\n",
    "#weight_end = model.backbone.weight.cpu().detach().numpy()\n",
    "\n",
    "plt.plot(accues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dabb4ae",
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011411190032958984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa0c3679564457293ec417e3fdd8633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f1b2bf340>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the goal about achieve zero loss is depended on the Batch size and the number of data\n",
    "##############################################################################################################\n",
    "%matplotlib inline\n",
    "from mltool.visualization import *\n",
    "from tqdm.notebook import tqdm\n",
    "B=20\n",
    "I=10\n",
    "O=30\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super().__init__()\n",
    "        self.backbone = torch.nn.Linear(in_chan, out_chan,bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)**2\n",
    "model= MyModel(I, O).cuda()\n",
    "x    = torch.randn(B, I).cuda()\n",
    "y    = torch.randn(B, O).cuda()\n",
    "func_model, params = make_functional(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(),1)\n",
    "\n",
    "#optimizer = SGD_Nodel(model.parameters(),1)\n",
    "#optimzer= torch.optim.Adam(model.parameters())\n",
    "\n",
    "accues= []\n",
    "grad_modifier = Nodal_GradientModifier(10,1,100)\n",
    "#weight_beg = model.backbone.weight.cpu().detach().numpy()\n",
    "for _ in tqdm(range(1000)):\n",
    "    optimizer.zero_grad()\n",
    "    # loss = F.mse_loss(model(x),y)\n",
    "    # loss.backward()\n",
    "    #gradient = model.backbone.weight.grad.cpu().detach().numpy()\n",
    "    accu=grad_modifier.backward(model,x,y,return_Normlization_Term_2=True)\n",
    "    optimizer.step()\n",
    "    accues.append(accu.item())\n",
    "#weight_end = model.backbone.weight.cpu().detach().numpy()\n",
    "\n",
    "plt.plot(accues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ca28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fd81633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6432467\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(weight_end - weight_beg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c50946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimzer.param_groups[0]['params'][0].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f91283f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cotangents = torch.ones(*shape).cuda()\n",
    "cotangents_variable  = torch.randint(2,shape).cuda()*2-1\n",
    "cotangents_variables = torch.randint(2,(10,*shape)).cuda()*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605845ca",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Normlization_Term_1 = lambda params,x:((functorch.jvp(lambda x:func_model(params,x), (x,), (cotangents,)\n",
    "                                      )[1]-1)**2).mean()\n",
    "with torch.no_grad():\n",
    "    Derivation_Term_1 = jacrev(Normlization_Term_1, argnums=0)(params, x)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb6a5b5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_\\gamma A_{\\gamma\\gamma}^2=2(||A||_F^2) - Var[Tr_m(A)]=2\\{E[Tr_m(AA^T)] - Var[Tr_m(A)]\\}\n",
    "$$\n",
    "where $A=J(\\mathbf{1}-I)J^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5a905",
   "metadata": {},
   "source": [
    "$$\n",
    "||A||_F^2= Tr(AA^T)=E[< \\vec{v}A|A^T\\vec{v}>]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7175c",
   "metadata": {},
   "source": [
    "$$\n",
    "< \\vec{v}A| = < \\vec{v}J|(\\mathbf{1}-I)J^T|= < \\vec{u}J^T|=|J\\vec{u}>^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0f314a",
   "metadata": {
    "code_folding": [
     0,
     7,
     13,
     18,
     20,
     22,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def TrvJOJv_and_ETrAAT(params,x,cotangents_variable):\n",
    "    _, vJ_fn = functorch.vjp(lambda x:func_model(params,x), x)\n",
    "    vJ   = vJ_fn(cotangents_variable)[0]\n",
    "    dims = list(range(1,len(vJ.shape)))\n",
    "    vJO  = vJ.sum(dims,keepdims=True)-vJ # <vJ|1-I|\n",
    "    vJOJv= (vJ*vJO).sum(dims)#should sum over all dimension except batch\n",
    "    return vJOJv, functorch.jvp(lambda x:func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "def get_TrvJOJv(params,x,cotangents_variable):\n",
    "    _, vJ_fn = functorch.vjp(lambda x:func_model(params,x), x)\n",
    "    vJ   = vJ_fn(cotangents_variable)[0]\n",
    "    vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "    vJOJv= (vJ*vJO).sum(-1)#should sum over all dimension except batch\n",
    "    return vJOJv\n",
    "def get_ETrAAT(params,x,cotangents_variable):\n",
    "    _, vJ_fn = functorch.vjp(lambda x:func_model(params,x), x)\n",
    "    vJ   = vJ_fn(cotangents_variable)[0]\n",
    "    vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "    return functorch.jvp(lambda x:func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "def get_ETrAAT_times(params,x,cotangents_variables):\n",
    "    return vmap(get_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "def get_TrvJOJv_times(params,x,cotangents_variables):\n",
    "    return vmap(get_TrvJOJv, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "def Normlization_Term_2(params,x,cotangents_variables):\n",
    "    TrvJOJvs,ETrAATs =  vmap(TrvJOJv_and_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables)\n",
    "    return ETrAATs.mean() - torch.var(TrvJOJvs,0).mean()\n",
    "def Normlization_Term_2_Full(params,x):\n",
    "    return (((vmap(jacrev(func_model, argnums=1), (None, 0))(params, x)**2).sum(-1)-1)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6368280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Derivation_Term_2 = jacrev(Normlization_Term_2, argnums=0)(params, x,cotangents_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe3b2ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bccff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_from_optimizer = optimizer.param_groups[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64cc7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(p1,p2) in enumerate(zip(params_from_optimizer,params)):\n",
    "    if not torch.allclose(p1,p2):\n",
    "        print(f\"{i:03d}:p1.shape={p1.shape}:p2.shape={p2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11ac2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1e10d45",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# torch.cuda.empty_cache()\n",
    "# Derivation_Term_2=[0]*len(params)\n",
    "# with torch.no_grad():\n",
    "#     for i in tqdm(range(32)):\n",
    "#         for j in tqdm(range(64)):\n",
    "#             small_fun = lambda params,x:func_model(params,x)[:,i,j]\n",
    "#             Normlization_Term_2= lambda params,x:((\n",
    "#                 (vmap(jacrev(small_fun, argnums=1), (None, 0))(params, x)**2).sum(-1)-1\n",
    "#                 )**2).mean()\n",
    "#             Derivation_Term_2_tuple = jacrev(Normlization_Term_2, argnums=0)(params, x)\n",
    "#             for k in range(len(Derivation_Term_2_tuple)):\n",
    "#                 Derivation_Term_2[k]+=Derivation_Term_2_tuple[k]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb91c3",
   "metadata": {},
   "source": [
    "输入 70x32x32 过大, 我们做出近邻假设:\n",
    "```\n",
    "                                     (x-h,y-h) (x  ,y-h) (x+h,y-h)\n",
    "位于 (x,y) 的 pixel 的响应只和他周围 一圈 (x-h,y  ) (x ,y  ) (x+h,y)\n",
    "                                     (x-h,y+h) (x  ,y+h) (x+h,y+h)\n",
    "有关\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859184dc",
   "metadata": {},
   "source": [
    "###### Define a new backward modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7c26fa",
   "metadata": {
    "code_folding": [
     0,
     7,
     11,
     18,
     24,
     29,
     31,
     33,
     36,
     38
    ]
   },
   "outputs": [],
   "source": [
    "class GradientModifier:\n",
    "    def __init__(self,model,lambda1=100,lambda2=100,sample_times=10):\n",
    "        self.func_model, self.params = make_functional(model)\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.sample_times = sample_times\n",
    "        self.cotangents_sum_along_x_dimension = None\n",
    "    def Normlization_Term_1(self,params,x):\n",
    "        if self.cotangents_sum_along_x_dimension is None or self.cotangents_sum_along_x_dimension.shape!=x.shape:\n",
    "            self.cotangents_sum_along_x_dimension = torch.ones_like(x)\n",
    "        return ((functorch.jvp(lambda x:self.func_model(params,x), (x,), (self.cotangents_sum_along_x_dimension,))[1]-1)**2).mean()\n",
    "    def TrvJOJv_and_ETrAAT(self,params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        dims = list(range(1,len(vJ.shape)))\n",
    "        vJO  = vJ.sum(dims,keepdims=True)-vJ # <vJ|1-I|\n",
    "        vJOJv= (vJ*vJO).sum(dims)#should sum over all dimension except batch\n",
    "        return vJOJv, functorch.jvp(lambda x:self.func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "    def get_TrvJOJv(params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "        vJOJv= (vJ*vJO).sum(-1)#should sum over all dimension except batch\n",
    "        return vJOJv\n",
    "    def get_ETrAAT(params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "        return functorch.jvp(lambda x:self.func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "    def get_ETrAAT_times(params,x,cotangents_variables):\n",
    "        return vmap(get_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "    def get_TrvJOJv_times(params,x,cotangents_variables):\n",
    "        return vmap(self.get_TrvJOJv, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "    def Normlization_Term_2(params,x,cotangents_variables):\n",
    "        TrvJOJvs,ETrAATs =  vmap(self.TrvJOJv_and_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables)\n",
    "        return ETrAATs.mean() - torch.var(TrvJOJvs,0).mean()\n",
    "    def Normlization_Term_2_Full(params,x):\n",
    "        return (((vmap(jacrev(self.func_model, argnums=1), (None, 0))(params, x)**2).sum(-1)-1)**2).mean()   \n",
    "    def backward(self,x):\n",
    "        shape = x.shape\n",
    "        cotangents_variables = torch.randint(2,(self.sample_times,*shape)).cuda()*2-1\n",
    "        with torch.no_grad():\n",
    "            Derivation_Term_1 = jacrev(self.Normlization_Term_1, argnums=0)(self.params, _input)\n",
    "            #torch.cuda.empty_cache() # usually not helpful to save memory\n",
    "        with torch.no_grad():\n",
    "            Derivation_Term_2 = jacrev(Normlization_Term_2, argnums=0)(self.params, x,cotangents_variables)\n",
    "            #torch.cuda.empty_cache() # usually not helpful to save memory\n",
    "            for p, delta1, delta2 in zip(self.params,Derivation_Term_1,Derivation_Term_2):\n",
    "                if p.grad is not None:\n",
    "                    p += self.lambda1*delta1 + self.lambda2*delta2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377e4e3",
   "metadata": {},
   "source": [
    "###### Define the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76271014",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479b498",
   "metadata": {
    "code_folding": [
     10,
     138,
     153
    ]
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "from typing import cast, List, Optional, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from .optimizer import Optimizer, _use_grad_for_differentiable\n",
    "\n",
    "__all__ = ['Adam', 'adam']\n",
    "\n",
    "class Adam_Nodal(Optimizer):\n",
    "    def __init__(self, params, lambda1=100,lambda2=100,sample_times=10,lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                 weight_decay=0, amsgrad=False, *, foreach: Optional[bool] = None,\n",
    "                 maximize: bool = False, capturable: bool = False,\n",
    "                 differentiable: bool = False, fused: bool = False):\n",
    "        assert func_model is not None,\"you need provide the function-like model. For example, try `func_model, params = make_functional(model)` \"\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        if not 0.0 <= weight_decay:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, amsgrad=amsgrad,\n",
    "                        maximize=maximize, foreach=foreach, capturable=capturable,\n",
    "                        differentiable=differentiable, fused=fused)\n",
    "        super(Adam, self).__init__(params, defaults)a\n",
    "        assert len(self.param_groups)==1, \"only one group parameter allowed \"\n",
    "        self.params = optimizer.param_groups[0]['params']\n",
    "        self.func_model = func_model\n",
    "        if fused:\n",
    "            if differentiable:\n",
    "                raise RuntimeError(\"`fused` cannot be `differentiable`\")\n",
    "            self._step_supports_amp_scaling = True\n",
    "            # TODO(crcrpar): [low prec params & their higher prec copy]\n",
    "            # Suppor AMP with FP16/BF16 model params which would need\n",
    "            # higher prec copy of params to do update math in higher prec to\n",
    "            # alleviate the loss of information.\n",
    "            if not all(\n",
    "                p.is_cuda and torch.is_floating_point(p)\n",
    "                for pg in self.param_groups for p in pg['params']\n",
    "            ):\n",
    "                raise RuntimeError(\"FusedAdam requires all the params to be CUDA, floating point\")\n",
    "                self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.sample_times = sample_times\n",
    "        self.cotangents_sum_along_x_dimension = None\n",
    "        \n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('amsgrad', False)\n",
    "            group.setdefault('maximize', False)\n",
    "            group.setdefault('foreach', None)\n",
    "            group.setdefault('capturable', False)\n",
    "            group.setdefault('differentiable', False)\n",
    "            group.setdefault('fused', False)\n",
    "        state_values = list(self.state.values())\n",
    "        step_is_tensor = (len(state_values) != 0) and torch.is_tensor(state_values[0]['step'])\n",
    "        if not step_is_tensor:\n",
    "            for s in state_values:\n",
    "                s['step'] = torch.tensor(float(s['step']))\n",
    "\n",
    "                \n",
    "    def Normlization_Term_1(self,params,x):\n",
    "        if self.cotangents_sum_along_x_dimension is None or self.cotangents_sum_along_x_dimension.shape!=x.shape:\n",
    "            self.cotangents_sum_along_x_dimension = torch.ones_like(x)\n",
    "        return ((functorch.jvp(lambda x:self.func_model(params,x), (x,), (self.cotangents_sum_along_x_dimension,))[1]-1)**2).mean()\n",
    "    def TrvJOJv_and_ETrAAT(self,params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        dims = list(range(1,len(vJ.shape)))\n",
    "        vJO  = vJ.sum(dims,keepdims=True)-vJ # <vJ|1-I|\n",
    "        vJOJv= (vJ*vJO).sum(dims)#should sum over all dimension except batch\n",
    "        return vJOJv, functorch.jvp(lambda x:self.func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "    def get_TrvJOJv(self,params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "        vJOJv= (vJ*vJO).sum(-1)#should sum over all dimension except batch\n",
    "        return vJOJv\n",
    "    def get_ETrAAT(self,params,x,cotangents_variable):\n",
    "        _, vJ_fn = functorch.vjp(lambda x:self.func_model(params,x), x)\n",
    "        vJ   = vJ_fn(cotangents_variable)[0]\n",
    "        vJO  = vJ.sum(1,keepdims=True)-vJ # <vJ|1-I|\n",
    "        return functorch.jvp(lambda x:self.func_model(params,x), (x,), (vJO,))[1].norm()# average the batch_size also\n",
    "    def get_ETrAAT_times(self,params,x,cotangents_variables):\n",
    "        return vmap(get_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "    def get_TrvJOJv_times(self,params,x,cotangents_variables):\n",
    "        return vmap(self.get_TrvJOJv, (None, None, 0 ))(params, x,cotangents_variables).mean()\n",
    "    def Normlization_Term_2(self,params,x,cotangents_variables):\n",
    "        TrvJOJvs,ETrAATs =  vmap(self.TrvJOJv_and_ETrAAT, (None, None, 0 ))(params, x,cotangents_variables)\n",
    "        return ETrAATs.mean() - torch.var(TrvJOJvs,0).mean()\n",
    "    def Normlization_Term_2_Full(model, params,x):\n",
    "        return (((vmap(jacrev(self.func_model, argnums=1), (None, 0))(params, x)**2).sum(-1)-1)**2).mean()   \n",
    "    \n",
    "            \n",
    "    @_use_grad_for_differentiable\n",
    "    def step(self, _input,_output, model):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            closure (Callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "            grad_scaler (:class:`torch.cuda.amp.GradScaler`, optional): A GradScaler which is\n",
    "                supplied from ``grad_scaler.step(optimizer)``.\n",
    "        \"\"\"\n",
    "        self._cuda_graph_capture_health_check()\n",
    "\n",
    "        # we will firstly update the grad from regularzation term\n",
    "        # in this case is \n",
    "        #     $L1 = \\sum_\\gamma(\\sum_\\alpha J_\\alpha^{\\gamma}-1)^2$\n",
    "        #     $L2 = \\lambda_2[\\sum_\\gamma A_{\\gamma\\gamma}^2]$ where $A=J(\\mathbf{1}-I)J^T$\n",
    "        #          for L2 part, we will use Hutchinson Method to estimate the value and do backprogation\n",
    "        #          $\\sum_\\gamma A_{\\gamma\\gamma}^2 = 2\\{E[\\Tr_m(AA^T)] - Var[\\Tr_m(A)]\\}$\n",
    "        \n",
    "        self.func_model, params =  make_functional(model)\n",
    "        shape = _output.shape\n",
    "        cotangents_variables = torch.randint(2,(self.sample_times,*shape)).cuda()*2-1\n",
    "        with torch.no_grad():\n",
    "            Derivation_Term_1 = jacrev(self.Normlization_Term_1, argnums=0)(params, _input)\n",
    "            Derivation_Term_2 = jacrev(self.Normlization_Term_2, argnums=0)(params, _input,cotangents_variables)\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            params_with_grad = []\n",
    "            grads = []\n",
    "            exp_avgs = []\n",
    "            exp_avg_sqs = []\n",
    "            max_exp_avg_sqs = []\n",
    "            state_steps = []\n",
    "            beta1, beta2 = group['betas']\n",
    "\n",
    "            grad_scale = None\n",
    "            found_inf = None\n",
    "            if group['fused'] and grad_scaler is not None:\n",
    "                grad_scale = grad_scaler._get_scale_async()\n",
    "                device = grad_scale.device\n",
    "                grad_scale = _MultiDeviceReplicator(grad_scale)\n",
    "                found_inf = _get_fp16AMP_params(optimizer=self, grad_scaler=grad_scaler, device=device)\n",
    "\n",
    "            for p ,d1,d2 in zip(group['params'],Derivation_Term_1,Derivation_Term_2):\n",
    "                if p.grad is not None:\n",
    "                    params_with_grad.append(p)\n",
    "                    if p.grad.is_sparse:\n",
    "                        raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                    grads.append(p.grad+d1+d2)\n",
    "\n",
    "                    state = self.state[p]\n",
    "                    # Lazy state initialization\n",
    "                    if len(state) == 0:\n",
    "                        state['step'] = (\n",
    "                            torch.zeros((1,), dtype=torch.float, device=p.device)\n",
    "                            if self.defaults['capturable'] or self.defaults['fused']\n",
    "                            else torch.tensor(0.)\n",
    "                        )\n",
    "                        # Exponential moving average of gradient values\n",
    "                        state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                        # Exponential moving average of squared gradient values\n",
    "                        state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                        if group['amsgrad']:\n",
    "                            # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                            state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "\n",
    "                    exp_avgs.append(state['exp_avg'])\n",
    "                    exp_avg_sqs.append(state['exp_avg_sq'])\n",
    "\n",
    "                    if group['amsgrad']:\n",
    "                        max_exp_avg_sqs.append(state['max_exp_avg_sq'])\n",
    "                    if group['differentiable'] and state['step'].requires_grad:\n",
    "                        raise RuntimeError('`requires_grad` is not supported for `step` in differentiable mode')\n",
    "                    state_steps.append(state['step'])\n",
    "\n",
    "            adam(params_with_grad,\n",
    "                 grads,\n",
    "                 exp_avgs,\n",
    "                 exp_avg_sqs,\n",
    "                 max_exp_avg_sqs,\n",
    "                 state_steps,\n",
    "                 amsgrad=group['amsgrad'],\n",
    "                 beta1=beta1,\n",
    "                 beta2=beta2,\n",
    "                 lr=group['lr'],\n",
    "                 weight_decay=group['weight_decay'],\n",
    "                 eps=group['eps'],\n",
    "                 maximize=group['maximize'],\n",
    "                 foreach=group['foreach'],\n",
    "                 capturable=group['capturable'],\n",
    "                 differentiable=group['differentiable'],\n",
    "                 fused=group['fused'],\n",
    "                 grad_scale=grad_scale,\n",
    "                 found_inf=found_inf)\n",
    "\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af2e18",
   "metadata": {},
   "source": [
    "#### 如果我们直接计算出来梯度, 是不是可以减少中间变量的占用\n",
    "\n",
    "我们接下来要利用的内置函数 vpj, vjp, pjv 实现的是这几个量\n",
    "- $\\sum_\\alpha J_\\alpha^\\gamma$\n",
    "- $\\sum_\\alpha H_{\\alpha\\beta}^\\gamma$\n",
    "- $\\sum_\\alpha (J_\\alpha^\\gamma)^2$\n",
    "- $\\sum_\\alpha J_\\alpha^\\gamma H_{\\alpha\\beta}^\\gamma$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd47ad3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### $\\sum_\\alpha J_\\alpha^\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "da899e32",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jvp_from_batch_J = batch_J.sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9381bad",
   "metadata": {
    "hidden": true
   },
   "source": [
    "首先比较 torch 原生的和functorch 的 jvp function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4641fc59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_pytorch_jvp,jvp_result_pytorch_jvp = torch.autograd.functional.jvp(model, x, torch.ones(7,3))\n",
    "output_functorch_jvp,jvp_result_functorch_jvp = functorch.jvp(model, (x,), (torch.ones(7,3),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "540633cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<DistBackward0>)\n",
      "tensor(0., grad_fn=<DistBackward0>)\n",
      "tensor(3.4459e-07, grad_fn=<DistBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# result \n",
    "print(torch.dist(output_pytorch_jvp,output_functorch_jvp))\n",
    "print(torch.dist(jvp_result_pytorch_jvp,jvp_result_functorch_jvp))\n",
    "print(torch.dist(jvp_result_pytorch_jvp,jvp_from_batch_J))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c6fb6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "注意到上面的function 没有实现 vmap, 我们现在来尝试用vmap写出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "21ef609a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "func = lambda x:functorch.jvp(model, (x,), (torch.ones(3),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "139f7932",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_batch_functorch_jvp,jvp_batch_result_functorch_jvp = vmap(func)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "daa75c59",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5825e-07, grad_fn=<DistBackward0>)\n",
      "tensor(3.3542e-07, grad_fn=<DistBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.dist(output_batch_functorch_jvp,output_pytorch_jvp))\n",
    "print(torch.dist(jvp_batch_result_functorch_jvp,jvp_from_batch_J))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92d45a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "下面进行压力测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "65507261",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "B=200\n",
    "I=100\n",
    "O=300\n",
    "model= MyModel(I, O)\n",
    "x    = torch.randn(B, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4a23dd5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 µs ± 28.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output_pytorch_jvp,jvp_result_pytorch_jvp = torch.autograd.functional.jvp(model, x, torch.ones(B,I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b1d7bd9d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 µs ± 25.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output_pytorch_jvp,jvp_result_pytorch_jvp = functorch.jvp(model, (x,), (torch.ones(B,I),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d89050f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "func = lambda x:functorch.jvp(model, (x,), (torch.ones(I),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "389a86cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685 µs ± 40.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output_batch_functorch_jvp,jvp_batch_result_functorch_jvp = vmap(func)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858ebcf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "结论: 不用 vmap 会更加好!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82676b",
   "metadata": {},
   "source": [
    "#####  $\\sum_\\alpha H_{\\alpha\\beta}^\\gamma = \\partial_{\\beta}\\sum_\\alpha J^\\gamma_{\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "72fc86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functorch import make_functional, vmap, grad\n",
    "model= MyModel(3, 4)\n",
    "x    = torch.randn(7, 3)\n",
    "func_model, params = make_functional(model)\n",
    "w    = params[0]\n",
    "batch_J= vmap(jacrev(func_model, argnums=1), (None, 0))(params, x)\n",
    "batch_H= jacrev(vmap(jacrev(func_model, argnums=1), (None, 0)), argnums=0)(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "997934a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 3, 4, 3])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_H[0].shape# 后面的 (4,3) 是 weight 的形状, 7 是 batch, 4 是输出的Dim, 3是alpha "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ace874",
   "metadata": {},
   "source": [
    "指标 $\\beta$ 是指代的第几个 parameter, 也就是 `batch_H` 这个 tuple 里面的第几个量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e8a3a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2781e-06, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = lambda params,x:functorch.jvp(lambda x:func_model(params,x), (x,), (torch.ones(7,3),))[1]\n",
    "batch_H_sum_from_jvp= jacrev(func, argnums=0)(params, x)\n",
    "#### full computation\n",
    "batch_H= jacrev(vmap(jacrev(func_model, argnums=1), (None, 0)), argnums=0)(params, x)\n",
    "jvp_from_batch_H = batch_H[0].sum(2)\n",
    "torch.dist(batch_H[0].sum(2),batch_H_sum_from_jvp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7dbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, vjp_fn = vjp(func_model, x)\n",
    "\n",
    "ft_jacobian, = vmap(vjp_fn)(unit_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9b8ca5d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "jvp(f, primals, tangents): Expected primals and tangents to have the same python structure. For example, if primals is a tuple of 3 tensors, tangents also must be. Got primals with structure TreeSpec(tuple, None, [TreeSpec(tuple, None, [*]), *]) and tangents with structure TreeSpec(tuple, None, [*, *])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_J\u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/functorch/_src/vmap.py:365\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 365\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn [148], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs:\u001b[43mjvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:786\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, primals, tangents, strict, has_aux)\u001b[0m\n\u001b[1;32m    784\u001b[0m flat_tangents, tangents_spec \u001b[38;5;241m=\u001b[39m tree_flatten(tangents)\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primals_spec \u001b[38;5;241m!=\u001b[39m tangents_spec:\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjvp_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Expected primals and tangents to have the same python \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstructure. For example, if primals is a tuple of 3 tensors, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtangents also must be. Got primals with structure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprimals_spec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand tangents with structure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtangents_spec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    791\u001b[0m assert_non_empty_list_of_tensors(flat_primals, jvp_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimals\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    792\u001b[0m assert_non_empty_list_of_tensors(flat_tangents, jvp_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtangents\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: jvp(f, primals, tangents): Expected primals and tangents to have the same python structure. For example, if primals is a tuple of 3 tensors, tangents also must be. Got primals with structure TreeSpec(tuple, None, [TreeSpec(tuple, None, [*]), *]) and tangents with structure TreeSpec(tuple, None, [*, *])"
     ]
    }
   ],
   "source": [
    "batch_J= vmap(func, ((None, 0), (None,None)) \n",
    "             )( (params, x), (torch.ones(4),torch.ones(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, vjp_fn = vjp(partial(predict, weight, bias), x)\n",
    "\n",
    "ft_jacobian, = vmap(vjp_fn)(unit_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ce7f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import jvp\n",
    "x = torch.randn(5)\n",
    "y = torch.randn(5)\n",
    "f = lambda x, y: (x * y)\n",
    "_, output = jvp(f, (x, y), (torch.ones(5), torch.ones(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0e460b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.1409, -0.3539, -0.2227, -0.5354, -2.3300])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.optim import Optimizer\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ea9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_constrained_gradient(grad, hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb53a9",
   "metadata": {
    "code_folding": [
     1,
     6,
     19,
     95,
     148,
     229
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "class Adam(Optimizer):\n",
    "    r\"\"\"Implements Adam algorithm.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                 weight_decay=0, amsgrad=False, *, foreach: Optional[bool] = None,\n",
    "                 maximize: bool = False, capturable: bool = False):\n",
    "        if not 0.0 <= lr:raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        if not 0.0 <= weight_decay:raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, amsgrad=amsgrad,\n",
    "                        maximize=maximize, foreach=foreach, capturable=capturable)\n",
    "        super(Adam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('amsgrad', False)\n",
    "            group.setdefault('maximize', False)\n",
    "            group.setdefault('foreach', None)\n",
    "            group.setdefault('capturable', False)\n",
    "        state_values = list(self.state.values())\n",
    "        step_is_tensor = (len(state_values) != 0) and torch.is_tensor(state_values[0]['step'])\n",
    "        if not step_is_tensor:\n",
    "            for s in state_values:\n",
    "                s['step'] = torch.tensor(float(s['step']))\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, hessian,closure=None):\n",
    "        self._cuda_graph_capture_health_check()\n",
    "\n",
    "        loss = None\n",
    "        for group in self.param_groups:\n",
    "            params_with_grad = []\n",
    "            grads = []\n",
    "            exp_avgs = []\n",
    "            exp_avg_sqs = []\n",
    "            max_exp_avg_sqs = []\n",
    "            state_steps = []\n",
    "            beta1, beta2 = group['betas']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    params_with_grad.append(p)\n",
    "                    if p.grad.is_sparse:\n",
    "                        raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                    grads.append(p.grad)\n",
    "\n",
    "                    state = self.state[p]\n",
    "                    # Lazy state initialization\n",
    "                    if len(state) == 0:\n",
    "                        state['step'] = torch.zeros((1,), dtype=torch.float, device=p.device) \\\n",
    "                            if self.defaults['capturable'] else torch.tensor(0.)\n",
    "                        # Exponential moving average of gradient values\n",
    "                        state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                        # Exponential moving average of squared gradient values\n",
    "                        state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                        if group['amsgrad']:\n",
    "                            # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                            state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "\n",
    "                    exp_avgs.append(state['exp_avg'])\n",
    "                    exp_avg_sqs.append(state['exp_avg_sq'])\n",
    "\n",
    "                    if group['amsgrad']:\n",
    "                        max_exp_avg_sqs.append(state['max_exp_avg_sq'])\n",
    "\n",
    "                    state_steps.append(state['step'])\n",
    "\n",
    "            adam(params_with_grad,\n",
    "                 grads,\n",
    "                 exp_avgs,\n",
    "                 exp_avg_sqs,\n",
    "                 max_exp_avg_sqs,\n",
    "                 state_steps,\n",
    "                 amsgrad=group['amsgrad'],\n",
    "                 beta1=beta1,\n",
    "                 beta2=beta2,\n",
    "                 lr=group['lr'],\n",
    "                 weight_decay=group['weight_decay'],\n",
    "                 eps=group['eps'],\n",
    "                 maximize=group['maximize'],\n",
    "                 foreach=group['foreach'],\n",
    "                 capturable=group['capturable'])\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "def adam(params: List[Tensor],\n",
    "         grads: List[Tensor],\n",
    "         exp_avgs: List[Tensor],\n",
    "         exp_avg_sqs: List[Tensor],\n",
    "         max_exp_avg_sqs: List[Tensor],\n",
    "         state_steps: List[Tensor],\n",
    "         # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627\n",
    "         # setting this as kwarg for now as functional API is compiled by torch/distributed/optim\n",
    "         foreach: bool = None,\n",
    "         capturable: bool = False,\n",
    "         *,\n",
    "         amsgrad: bool,\n",
    "         beta1: float,\n",
    "         beta2: float,\n",
    "         lr: float,\n",
    "         weight_decay: float,\n",
    "         eps: float,\n",
    "         maximize: bool):\n",
    "    r\"\"\"Functional API that performs Adam algorithm computation.\n",
    "    See :class:`~torch.optim.Adam` for details.\n",
    "    \"\"\"\n",
    "\n",
    "    if not all([isinstance(t, torch.Tensor) for t in state_steps]):\n",
    "        raise RuntimeError(\"API has changed, `state_steps` argument must contain a list of singleton tensors\")\n",
    "\n",
    "    if foreach is None:\n",
    "        # Placeholder for more complex foreach logic to be added when value is not set\n",
    "        foreach = False\n",
    "\n",
    "    if foreach and torch.jit.is_scripting():\n",
    "        raise RuntimeError('torch.jit.script not supported with foreach optimizers')\n",
    "\n",
    "    if foreach and not torch.jit.is_scripting():\n",
    "        func = _multi_tensor_adam\n",
    "    else:\n",
    "        func = _single_tensor_adam\n",
    "\n",
    "    func(params,\n",
    "         grads,\n",
    "         exp_avgs,\n",
    "         exp_avg_sqs,\n",
    "         max_exp_avg_sqs,\n",
    "         state_steps,\n",
    "         amsgrad=amsgrad,\n",
    "         beta1=beta1,\n",
    "         beta2=beta2,\n",
    "         lr=lr,\n",
    "         weight_decay=weight_decay,\n",
    "         eps=eps,\n",
    "         maximize=maximize,\n",
    "         capturable=capturable)\n",
    "\n",
    "\n",
    "def _single_tensor_adam(params: List[Tensor],\n",
    "                        grads: List[Tensor],\n",
    "                        exp_avgs: List[Tensor],\n",
    "                        exp_avg_sqs: List[Tensor],\n",
    "                        max_exp_avg_sqs: List[Tensor],\n",
    "                        state_steps: List[Tensor],\n",
    "                        *,\n",
    "                        amsgrad: bool,\n",
    "                        beta1: float,\n",
    "                        beta2: float,\n",
    "                        lr: float,\n",
    "                        weight_decay: float,\n",
    "                        eps: float,\n",
    "                        maximize: bool,\n",
    "                        capturable: bool):\n",
    "\n",
    "    for i, param in enumerate(params):\n",
    "\n",
    "        grad       = grads[i] if not maximize else -grads[i]\n",
    "        exp_avg    = exp_avgs[i]\n",
    "        exp_avg_sq = exp_avg_sqs[i]\n",
    "        step_t = state_steps[i]\n",
    "\n",
    "        if capturable:\n",
    "            assert param.is_cuda and step_t.is_cuda, \"If capturable=True, params and state_steps must be CUDA tensors.\"\n",
    "\n",
    "        # update step\n",
    "        step_t += 1\n",
    "\n",
    "        if weight_decay != 0:\n",
    "            grad = grad.add(param, alpha=weight_decay)\n",
    "\n",
    "        # Decay the first and second moment running average coefficient\n",
    "        exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
    "        exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n",
    "\n",
    "        if capturable:\n",
    "            step = step_t\n",
    "\n",
    "            # 1 - beta1 ** step can't be captured in a CUDA graph, even if step is a CUDA tensor\n",
    "            # (incurs \"RuntimeError: CUDA error: operation not permitted when stream is capturing\")\n",
    "            bias_correction1 = 1 - torch.pow(beta1, step)\n",
    "            bias_correction2 = 1 - torch.pow(beta2, step)\n",
    "\n",
    "            step_size = lr / bias_correction1\n",
    "            step_size_neg = step_size.neg()\n",
    "\n",
    "            bias_correction2_sqrt = bias_correction2.sqrt()\n",
    "\n",
    "            if amsgrad:\n",
    "                # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])\n",
    "                # Uses the max. for normalizing running avg. of gradient\n",
    "                # Folds in (admittedly ugly) 1-elem step_size math here to avoid extra param-set-sized read+write\n",
    "                # (can't fold it into addcdiv_ below because addcdiv_ requires value is a Number, not a Tensor)\n",
    "                denom = (max_exp_avg_sqs[i].sqrt() / (bias_correction2_sqrt * step_size_neg)).add_(eps / step_size_neg)\n",
    "            else:\n",
    "                denom = (exp_avg_sq.sqrt() / (bias_correction2_sqrt * step_size_neg)).add_(eps / step_size_neg)\n",
    "\n",
    "            param.addcdiv_(exp_avg, denom)\n",
    "        else:\n",
    "            step = step_t.item()\n",
    "\n",
    "            bias_correction1 = 1 - beta1 ** step\n",
    "            bias_correction2 = 1 - beta2 ** step\n",
    "\n",
    "            step_size = lr / bias_correction1\n",
    "\n",
    "            bias_correction2_sqrt = math.sqrt(bias_correction2)\n",
    "\n",
    "            if amsgrad:\n",
    "                # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])\n",
    "                # Use the max. for normalizing running avg. of gradient\n",
    "                denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n",
    "            else:\n",
    "                denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
    "\n",
    "            param.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "\n",
    "\n",
    "def _multi_tensor_adam(params: List[Tensor],\n",
    "                       grads: List[Tensor],\n",
    "                       exp_avgs: List[Tensor],\n",
    "                       exp_avg_sqs: List[Tensor],\n",
    "                       max_exp_avg_sqs: List[Tensor],\n",
    "                       state_steps: List[Tensor],\n",
    "                       *,\n",
    "                       amsgrad: bool,\n",
    "                       beta1: float,\n",
    "                       beta2: float,\n",
    "                       lr: float,\n",
    "                       weight_decay: float,\n",
    "                       eps: float,\n",
    "                       maximize: bool,\n",
    "                       capturable: bool):\n",
    "    if len(params) == 0:\n",
    "        return\n",
    "\n",
    "    if capturable:\n",
    "        assert all(p.is_cuda and step.is_cuda for p, step in zip(params, state_steps)), \\\n",
    "            \"If capturable=True, params and state_steps must be CUDA tensors.\"\n",
    "\n",
    "    if maximize:\n",
    "        grads = torch._foreach_neg(tuple(grads))  # type: ignore[assignment]\n",
    "\n",
    "    # update steps\n",
    "    torch._foreach_add_(state_steps, 1)\n",
    "\n",
    "    if weight_decay != 0:\n",
    "        torch._foreach_add_(grads, params, alpha=weight_decay)\n",
    "\n",
    "    # Decay the first and second moment running average coefficient\n",
    "    torch._foreach_mul_(exp_avgs, beta1)\n",
    "    torch._foreach_add_(exp_avgs, grads, alpha=1 - beta1)\n",
    "\n",
    "    torch._foreach_mul_(exp_avg_sqs, beta2)\n",
    "    torch._foreach_addcmul_(exp_avg_sqs, grads, grads, 1 - beta2)\n",
    "\n",
    "    if capturable:\n",
    "        # TODO: use foreach_pow if/when foreach_pow is added\n",
    "        bias_correction1 = [torch.pow(beta1, step) for step in state_steps]\n",
    "        bias_correction2 = [torch.pow(beta2, step) for step in state_steps]\n",
    "        # foreach_sub doesn't allow a scalar as the first arg\n",
    "        torch._foreach_sub_(bias_correction1, 1)\n",
    "        torch._foreach_sub_(bias_correction2, 1)\n",
    "        torch._foreach_neg_(bias_correction1)\n",
    "        torch._foreach_neg_(bias_correction2)\n",
    "\n",
    "        # foreach_div doesn't allow a scalar as the first arg\n",
    "        step_size = torch._foreach_div(bias_correction1, lr)\n",
    "        torch._foreach_reciprocal_(step_size)\n",
    "        torch._foreach_neg_(step_size)\n",
    "\n",
    "        bias_correction2_sqrt = torch._foreach_sqrt(bias_correction2)\n",
    "\n",
    "        if amsgrad:\n",
    "            # Maintains the maximum of all 2nd moment running avg. till now\n",
    "            max_exp_avg_sqs = torch._foreach_maximum(max_exp_avg_sqs, exp_avg_sqs)  # type: ignore[assignment]\n",
    "\n",
    "            # Use the max. for normalizing running avg. of gradient\n",
    "            max_exp_avg_sq_sqrt = torch._foreach_sqrt(max_exp_avg_sqs)\n",
    "            # Folds in (admittedly ugly) 1-elem step_size math here to avoid extra param-set-sized read+write\n",
    "            # (can't fold it into addcdiv_ below because addcdiv_ requires value is a Number, not a Tensor)\n",
    "            torch._foreach_div_(max_exp_avg_sq_sqrt, torch._foreach_mul(bias_correction2_sqrt, step_size))\n",
    "            eps_over_step_size = torch._foreach_div(step_size, eps)\n",
    "            torch._foreach_reciprocal_(eps_over_step_size)\n",
    "            denom = torch._foreach_add(max_exp_avg_sq_sqrt, eps_over_step_size)\n",
    "        else:\n",
    "            exp_avg_sq_sqrt = torch._foreach_sqrt(exp_avg_sqs)\n",
    "            torch._foreach_div_(exp_avg_sq_sqrt, torch._foreach_mul(bias_correction2_sqrt, step_size))\n",
    "            eps_over_step_size = torch._foreach_div(step_size, eps)\n",
    "            torch._foreach_reciprocal_(eps_over_step_size)\n",
    "            denom = torch._foreach_add(exp_avg_sq_sqrt, eps_over_step_size)\n",
    "\n",
    "        torch._foreach_addcdiv_(params, exp_avgs, denom)\n",
    "    else:\n",
    "        bias_correction1 = [1 - beta1 ** step.item() for step in state_steps]\n",
    "        bias_correction2 = [1 - beta2 ** step.item() for step in state_steps]\n",
    "\n",
    "        step_size = [(lr / bc) * -1 for bc in bias_correction1]\n",
    "\n",
    "        bias_correction2_sqrt = [math.sqrt(bc) for bc in bias_correction2]\n",
    "\n",
    "        if amsgrad:\n",
    "            # Maintains the maximum of all 2nd moment running avg. till now\n",
    "            max_exp_avg_sqs = torch._foreach_maximum(max_exp_avg_sqs, exp_avg_sqs)  # type: ignore[assignment]\n",
    "\n",
    "            # Use the max. for normalizing running avg. of gradient\n",
    "            max_exp_avg_sq_sqrt = torch._foreach_sqrt(max_exp_avg_sqs)\n",
    "            torch._foreach_div_(max_exp_avg_sq_sqrt, bias_correction2_sqrt)\n",
    "            denom = torch._foreach_add(max_exp_avg_sq_sqrt, eps)\n",
    "        else:\n",
    "            exp_avg_sq_sqrt = torch._foreach_sqrt(exp_avg_sqs)\n",
    "            torch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n",
    "            denom = torch._foreach_add(exp_avg_sq_sqrt, eps)\n",
    "\n",
    "        torch._foreach_addcdiv_(params, exp_avgs, denom, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92215445",
   "metadata": {
    "code_folding": [
     14
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhess_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from .architect import Architect\n",
    "from .history import History\n",
    "\n",
    "\n",
    "def _concat(xs):\n",
    "    return torch.cat([x.view(-1) for x in xs])\n",
    "\n",
    "\n",
    "# TODO: modify to include learnable edge weights.\n",
    "class ArchitectDARTS(Architect):\n",
    "    def __init__(self, model, args, writer):\n",
    "        super(ArchitectDARTS, self).__init__(model, args, writer)\n",
    "\n",
    "        self.network_momentum = args.train.momentum\n",
    "        self.network_weight_decay = args.train.weight_decay\n",
    "        if args.search.gd:\n",
    "            self.optimizer = torch.optim.SGD(\n",
    "                self._arch_parameters,\n",
    "                lr=args.search.arch_learning_rate,\n",
    "                weight_decay=args.search.arch_weight_decay,\n",
    "            )\n",
    "        else:\n",
    "            self.optimizer = torch.optim.Adam(\n",
    "                self._arch_parameters,\n",
    "                lr=args.search.arch_learning_rate,\n",
    "                betas=(0.5, 0.999),\n",
    "                weight_decay=args.search.arch_weight_decay,\n",
    "            )\n",
    "        self.history = History(\n",
    "            model, self, to_save=(\"alphas\", \"l2_norm\", \"l2_norm_from_init\")\n",
    "        )\n",
    "        self.history.dict[\"grads\"] = {}\n",
    "        for v in [\"alphas\", \"edges\"]:\n",
    "            self.history.dict[\"grads\"][v] = {}\n",
    "            for ct in self.cell_types:\n",
    "                self.history.dict[\"grads\"][v][ct] = []\n",
    "\n",
    "    def initialize_alphas(self):\n",
    "        k = self.n_edges\n",
    "        num_ops = self.model._num_ops\n",
    "        for ct in self.cell_types:\n",
    "            self.alphas[ct] = Variable(\n",
    "                1e-3 * torch.randn(k, num_ops).cuda(), requires_grad=True\n",
    "            )\n",
    "        self._arch_parameters = [self.alphas[ct] for ct in self.cell_types]\n",
    "\n",
    "    def initialize_edge_weights(self):\n",
    "        for ct in self.cell_types:\n",
    "            self.edges[ct] = Variable(\n",
    "                torch.ones(self.n_edges).cuda(), requires_grad=False\n",
    "            )\n",
    "\n",
    "    def get_alphas(self):\n",
    "        return {ct: F.softmax(self.alphas[ct], dim=-1) for ct in self.cell_types}\n",
    "\n",
    "    def get_edge_weights(self):\n",
    "        return self.edges\n",
    "\n",
    "    def step(self,input_train,target_train,input_valid, target_valid,eta,network_optimizer,unrolled,**kwargs\n",
    "    ):\n",
    "        self.optimizer.zero_grad()\n",
    "        self.zero_arch_var_grad()\n",
    "        self.set_model_alphas()\n",
    "        self.set_model_edge_weights()\n",
    "\n",
    "        if unrolled:\n",
    "            self._backward_step_unrolled(\n",
    "                input_train,\n",
    "                target_train,\n",
    "                input_valid,\n",
    "                target_valid,\n",
    "                eta,\n",
    "                network_optimizer,\n",
    "            )\n",
    "        else:\n",
    "            self._backward_step(input_valid, target_valid)\n",
    "        self.optimizer.step()\n",
    "        self.steps += 1\n",
    "\n",
    "    def _backward_step(self, input_valid, target_valid):\n",
    "        loss = self.model._loss(input_valid, target_valid)\n",
    "        loss.backward()\n",
    "        for ct in self.cell_types:\n",
    "            self.history.dict[\"grads\"][\"alphas\"][ct].append(\n",
    "                self.alphas[ct].grad.data.cpu().numpy()\n",
    "            )\n",
    "\n",
    "    def _construct_model_from_theta(self, theta):\n",
    "        model_new = self.model.new()\n",
    "        model_dict = self.model.state_dict()\n",
    "\n",
    "        params = {}\n",
    "        offset = 0\n",
    "        for k, v in self.model.named_parameters():\n",
    "            v_length = np.prod(v.size())\n",
    "            params[k] = theta[offset : offset + v_length].view(v.size())\n",
    "            offset += v_length\n",
    "\n",
    "        assert offset == len(theta)\n",
    "        model_dict.update(params)\n",
    "        model_new.load_state_dict(model_dict)\n",
    "        self.initialize_new_model_arch_params(model_new)\n",
    "\n",
    "        return model_new.cuda()\n",
    "\n",
    "    def copy_architecture_params(self):\n",
    "        new_alphas = {\n",
    "            ct: Variable(self.alphas[ct].data.clone().cuda(), requires_grad=True)\n",
    "            for ct in self.cell_types\n",
    "        }\n",
    "        new_edges = {\n",
    "            ct: Variable(self.edges[ct].data.clone().cuda(), requires_grad=False)\n",
    "            for ct in self.cell_types\n",
    "        }\n",
    "        return new_alphas, new_edges\n",
    "\n",
    "    def initialize_new_model_arch_params(self, new_model):\n",
    "        self._new_alphas, self._new_edges = self.copy_architecture_params()\n",
    "        alphas = {ct: F.softmax(self._new_alphas[ct], dim=-1) for ct in self.cell_types}\n",
    "        new_model.set_alphas(alphas)\n",
    "        new_model.set_edge_weights(self._new_edges)\n",
    "        new_model.drop_path_prob = self.model.drop_path_prob\n",
    "\n",
    "    def _compute_unrolled_model(self, input, target, eta, network_optimizer):\n",
    "        loss = self.model._loss(input, target)\n",
    "        theta = _concat(self.model.parameters()).data\n",
    "        try:\n",
    "            moment = _concat(\n",
    "                network_optimizer.state[v][\"momentum_buffer\"]\n",
    "                for v in self.model.parameters()\n",
    "            ).mul_(self.network_momentum)\n",
    "        except:\n",
    "            moment = torch.zeros_like(theta)\n",
    "        dtheta = (\n",
    "            _concat(torch.autograd.grad(loss, self.model.parameters())).data\n",
    "            + self.network_weight_decay * theta\n",
    "        )\n",
    "        self.set_model_alphas()\n",
    "        self.set_model_edge_weights()\n",
    "        unrolled_model = self._construct_model_from_theta(\n",
    "            theta.sub(eta, moment + dtheta)\n",
    "        )\n",
    "        return unrolled_model\n",
    "\n",
    "    def _hessian_vector_product(self, vector, input, target, r=1e-2):\n",
    "        R = r / _concat(vector).norm()\n",
    "        for p, v in zip(self.model.parameters(), vector):\n",
    "            p.data.add_(R, v)\n",
    "        loss = self.model._loss(input, target)\n",
    "        grads_p = torch.autograd.grad(loss, self._arch_parameters)\n",
    "        self.set_model_alphas()\n",
    "        self.set_model_edge_weights()\n",
    "\n",
    "        for p, v in zip(self.model.parameters(), vector):\n",
    "            p.data.sub_(2 * R, v)\n",
    "        loss = self.model._loss(input, target)\n",
    "        grads_n = torch.autograd.grad(loss, self._arch_parameters)\n",
    "        self.set_model_alphas()\n",
    "        self.set_model_edge_weights()\n",
    "\n",
    "        for p, v in zip(self.model.parameters(), vector):\n",
    "            p.data.add_(R, v)\n",
    "\n",
    "        return [(x - y).div_(2 * R) for x, y in zip(grads_p, grads_n)]\n",
    "\n",
    "    def _backward_step_unrolled(\n",
    "        self,\n",
    "        input_train,\n",
    "        target_train,\n",
    "        input_valid,\n",
    "        target_valid,\n",
    "        eta,\n",
    "        network_optimizer,\n",
    "    ):\n",
    "        unrolled_model = self._compute_unrolled_model(\n",
    "            input_train, target_train, eta, network_optimizer\n",
    "        )\n",
    "        unrolled_loss = unrolled_model._loss(input_valid, target_valid)\n",
    "\n",
    "        unrolled_loss.backward()\n",
    "        dalpha = [self._new_alphas[ct].grad for ct in self.cell_types]\n",
    "        vector = [v.grad.data for v in unrolled_model.parameters()]\n",
    "        implicit_grads = self._hessian_vector_product(vector, input_train, target_train)\n",
    "\n",
    "        for g, ig in zip(dalpha, implicit_grads):\n",
    "            g.data.sub_(eta, ig.data)\n",
    "\n",
    "        for v, g in zip(self._arch_parameters, dalpha):\n",
    "            if v.grad is None:\n",
    "                v.grad = Variable(g.data)\n",
    "            else:\n",
    "                v.grad.data.copy_(g.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7097ff29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.8910, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.8857],\n",
       "          [0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000],\n",
       "          [5.9064, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.4972]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pow_reducer(x):\n",
    "    return x.pow(3).sum()\n",
    "inputs = torch.rand(2, 2)\n",
    "torch.autograd.functional.hessian(pow_reducer, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc77af441bfc2c62c4c17d61422da4a44e42f2508bbc97d57f2d3e249317e47a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
