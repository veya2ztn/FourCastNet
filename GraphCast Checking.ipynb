{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a568be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "flag = \"mesh5\"\n",
    "resolution_flag = \"32x64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f7fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.GraphCast import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e343d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"checkpoints/WeathBench7066/GraphCast/ts_2_pretrain-2D706N_per_1_step/02_07_20_53_42435-seed_73001/backbone.best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8bb446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        This is ===> GraphCast Model <===\n",
      "        Information: \n",
      "            total mesh node: 2562 total unique mesh edge:10230 \n",
      "            total grid node 2048+2 = 2050 but activated grid  1926 +  2\n",
      "            from activated grid to mesh, create 4*2562 = 10242 edge\n",
      "            there are 122 unactivated grid node\n",
      "            when mapping node to grid, \n",
      "            from node to activated grid, there are 10242 \n",
      "            from node to unactivated grid, there are 976 edge\n",
      "            thus, totally have 11218 edge. \n",
      "            #notice some grid only have 1-2 linked node but some grid may have 30 lined node\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['layer_grid2mesh.G2M_edge_coef_node_tensor', 'layer_mesh2mesh.0.num_of_linked_nodes', 'layer_mesh2mesh.1.num_of_linked_nodes', 'layer_mesh2mesh.2.num_of_linked_nodes', 'layer_mesh2mesh.3.num_of_linked_nodes', 'layer_mesh2mesh.4.num_of_linked_nodes', 'layer_mesh2mesh.5.num_of_linked_nodes', 'layer_mesh2grid.M2G_edge_coef_grid_tensor'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = GraphCast(img_size=(32,64),in_chans=70,out_chans=70,embed_dim=512,depth=6)\n",
    "model1.load_state_dict(torch.load(best_model_path)['model'],strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e090052",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lets chek GraphCastFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e9baa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        This is ===> GraphCast Model (Fast) <===\n",
      "        Information: \n",
      "            total mesh node: 2562 total unique mesh edge:10230 \n",
      "            total grid node 2048+2 = 2050 but activated grid  1926 +  2\n",
      "            from activated grid to mesh, create 4*2562 = 10242 edge\n",
      "            there are 122 unactivated grid node\n",
      "            when mapping node to grid, \n",
      "            from node to activated grid, there are 10242 \n",
      "            from node to unactivated grid, there are 976 edge\n",
      "            thus, totally have 11218 edge. \n",
      "            #notice some grid only have 1-2 linked node but some grid may have 30 lined node\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "model2 = GraphCastFast(img_size=(32,64),in_chans=70,out_chans=70,embed_dim=512,depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183d0595",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2.grid_rect_embedding_layer      = model1.grid_rect_embedding_layer\n",
    "model2.northsouthembbed.data          = model1.northsouthembbed.data\n",
    "model2.grid_mesh_bond_embedding.data  = model1.grid_mesh_bond_embedding.data[None]\n",
    "model2.mesh_node_embedding.data       =      model1.mesh_node_embedding.data[None] \n",
    "model2.mesh_mesh_bond_embedding.data  = model1.mesh_mesh_bond_embedding.data[None] \n",
    "model2.projection = model1.projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "fb195657",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model2.layer_grid2mesh.STE2E.data    = model1.layer_grid2mesh.MLP_G2M_GM2E.linear.weight.permute(1,0)\n",
    "# model2.layer_grid2mesh.activator1[1] = model1.layer_grid2mesh.MLP_G2M_GM2E.norm\n",
    "# model2.layer_grid2mesh.ET2T.data     = model1.layer_grid2mesh.MLP_G2M_E2M.linear.weight.permute(1,0)\n",
    "# model2.layer_grid2mesh.activator2[1] = model1.layer_grid2mesh.MLP_G2M_E2M.norm\n",
    "# model2.layer_grid2mesh.S2S.data      = model1.layer_grid2mesh.MLP_G2M_G2G.linear.weight.permute(1,0)\n",
    "# model2.layer_grid2mesh.activator3[1] = model1.layer_grid2mesh.MLP_G2M_G2G.norm\n",
    "\n",
    "# for layer1,layer2 in zip(model1.layer_mesh2mesh,model2.layer_mesh2mesh):\n",
    "#     layer2.STE2E.data    = layer1.MLP_M2M_N2E.linear.weight.permute(1,0)\n",
    "#     layer2.activator1[1] = layer1.MLP_M2M_N2E.norm\n",
    "#     layer2.ET2T.data     = layer1.MLP_M2M_E2N.linear.weight.permute(1,0)\n",
    "#     layer2.activator2[1] = layer1.MLP_M2M_E2N.norm\n",
    "\n",
    "# model2.layer_mesh2grid.STE2E.data    = model1.layer_mesh2grid.MLP_M2G_MG2E.linear.weight.permute(1,0)\n",
    "# model2.layer_mesh2grid.activator1[1] = model1.layer_mesh2grid.MLP_M2G_MG2E.norm\n",
    "# model2.layer_mesh2grid.ET2T.data     = model1.layer_mesh2grid.MLP_M2G_E2G.linear.weight.permute(1,0)\n",
    "# model2.layer_mesh2grid.activator2[1] = model1.layer_mesh2grid.MLP_M2G_E2G.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c331b42",
   "metadata": {
    "code_folding": [
     0,
     3,
     10
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(model2.layer_grid2mesh.STE2E_E2E.data,\n",
    " model2.layer_grid2mesh.STE2E_S2E.data,\n",
    " model2.layer_grid2mesh.STE2E_T2E.data)= torch.split(model1.layer_grid2mesh.MLP_G2M_GM2E.linear.weight.permute(1,0).data,512)\n",
    "(model2.layer_grid2mesh.ET2T_T2T.data,\n",
    " model2.layer_grid2mesh.ET2T_E2T.data)= torch.split(model1.layer_grid2mesh.MLP_G2M_E2M.linear.weight.permute(1,0).data,512)\n",
    "model2.layer_grid2mesh.S2S.data      = model1.layer_grid2mesh.MLP_G2M_G2G.linear.weight.permute(1,0)\n",
    "model2.layer_grid2mesh.activator1[1] = model1.layer_grid2mesh.MLP_G2M_GM2E.norm\n",
    "model2.layer_grid2mesh.activator2[1] = model1.layer_grid2mesh.MLP_G2M_E2M.norm\n",
    "model2.layer_grid2mesh.activator3[1] = model1.layer_grid2mesh.MLP_G2M_G2G.norm\n",
    "\n",
    "for layer1,layer2 in zip(model1.layer_mesh2mesh,model2.layer_mesh2mesh):\n",
    "    (layer2.STE2E_E2E.data,\n",
    "     layer2.STE2E_S2E.data,\n",
    "     layer2.STE2E_T2E.data)= torch.split(layer1.MLP_M2M_N2E.linear.weight.permute(1,0).data,512)\n",
    "    (layer2.ET2T_T2T.data,\n",
    "     layer2.ET2T_E2T.data)= torch.split(layer1.MLP_M2M_E2N.linear.weight.permute(1,0).data,512)\n",
    "    layer2.activator1[1] = layer1.MLP_M2M_N2E.norm\n",
    "    layer2.activator2[1] = layer1.MLP_M2M_E2N.norm\n",
    "\n",
    "(model2.layer_mesh2grid.STE2E_E2E.data,\n",
    " model2.layer_mesh2grid.STE2E_S2E.data,\n",
    " model2.layer_mesh2grid.STE2E_T2E.data)= torch.split(model1.layer_mesh2grid.MLP_M2G_MG2E.linear.weight.permute(1,0).data,512)\n",
    "(model2.layer_mesh2grid.ET2T_T2T.data,\n",
    " model2.layer_mesh2grid.ET2T_E2T.data)= torch.split(model1.layer_mesh2grid.MLP_M2G_E2G.linear.weight.permute(1,0).data,512)\n",
    "model2.layer_mesh2grid.activator1[1] = model1.layer_mesh2grid.MLP_M2G_MG2E.norm\n",
    "model2.layer_mesh2grid.activator2[1] = model1.layer_mesh2grid.MLP_M2G_E2G.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f957be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fixed_input = torch.randn(2,70,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "92b724aa",
   "metadata": {
    "code_folding": [
     0,
     20
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    B, P , W, H =fixed_input.shape\n",
    "    feature_along_latlot1     = model1.grid_rect_embedding_layer(fixed_input.permute(0,2,3,1).flatten(1,2))\n",
    "    grid_rect_embedding1      = feature_along_latlot1[:,model1.G2M_grid2LaLotudePos]\n",
    "    grid_rect_embedding1      = torch.cat([model1.northsouthembbed.repeat(B,1,1),grid_rect_embedding1],1)\n",
    "    grid_mesh_bond_embedding1 = model1.grid_mesh_bond_embedding.repeat(B,1,1)\n",
    "    mesh_node_embedding1      = model1.mesh_node_embedding.repeat(B,1,1)\n",
    "    mesh_mesh_bond_embedding1 = model1.mesh_mesh_bond_embedding.repeat(B,1,1)\n",
    "    grid_mesh_bond_embedding1,grid_rect_embedding1,mesh_node_embedding1 = model1.layer_grid2mesh(\n",
    "                                    grid_mesh_bond_embedding1,grid_rect_embedding1,mesh_node_embedding1)\n",
    "#     for mesh2mesh in model1.layer_mesh2mesh:\n",
    "#             mesh_mesh_bond_embedding1, mesh_node_embedding1  = mesh2mesh(mesh_mesh_bond_embedding1, mesh_node_embedding1)\n",
    "    mesh_mesh_bond_embedding1, mesh_node_embedding1  = model1.layer_mesh2mesh[0](mesh_mesh_bond_embedding1, mesh_node_embedding1)\n",
    "\n",
    "    grid_mesh_bond_embedding1 = torch.nn.functional.pad(grid_mesh_bond_embedding1,(0,0,0,model1.num_unactivated_edge))\n",
    "    grid_rect_embedding1      = torch.nn.functional.pad(grid_rect_embedding1,(0,0,0,model1.num_unactivated_grid ))\n",
    "    grid_rect_embedding1      = model1.layer_mesh2grid(grid_mesh_bond_embedding1,grid_rect_embedding1,mesh_node_embedding1)\n",
    "    grid_rect_embedding1      = grid_rect_embedding1[:,model1.M2G_LaLotudePos2grid] #(B,64,128,embed_dim)\n",
    "    out1 = model1.projection(grid_rect_embedding1).permute(0,3,1,2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    B, P , W, H =fixed_input.shape\n",
    "    feature_along_latlot2     = model2.grid_rect_embedding_layer(fixed_input.permute(0,2,3,1).flatten(1,2))\n",
    "    grid_rect_embedding2      = feature_along_latlot2[:,model2.G2M_grid2LaLotudePos]\n",
    "    grid_rect_embedding2      = torch.cat([model2.northsouthembbed.repeat(B,1,1),grid_rect_embedding2],1)\n",
    "    grid_mesh_bond_embedding2 = model2.grid_mesh_bond_embedding\n",
    "    mesh_node_embedding2      = model2.mesh_node_embedding\n",
    "    mesh_mesh_bond_embedding2 = model2.mesh_mesh_bond_embedding\n",
    "    \n",
    "    grid_mesh_bond_embedding2,grid_rect_embedding2,mesh_node_embedding2 = model2.layer_grid2mesh(\n",
    "                                    grid_mesh_bond_embedding2,grid_rect_embedding2,mesh_node_embedding2)\n",
    "#     for mesh2mesh in model2.layer_mesh2mesh:\n",
    "#         mesh_mesh_bond_embedding2, _, mesh_node_embedding2  = mesh2mesh(mesh_mesh_bond_embedding2, mesh_node_embedding2, mesh_node_embedding2)\n",
    "    mesh_mesh_bond_embedding2, _, mesh_node_embedding2  = model2.layer_mesh2mesh[0](mesh_mesh_bond_embedding2, mesh_node_embedding2,mesh_node_embedding2)\n",
    "\n",
    "    grid_mesh_bond_embedding2 = torch.nn.functional.pad(grid_mesh_bond_embedding2,(0,0,0,model2.num_unactivated_edge))\n",
    "    grid_rect_embedding2      = torch.nn.functional.pad(grid_rect_embedding2,(0,0,0,model2.num_unactivated_grid ))\n",
    "    grid_mesh_bond_embedding2,mesh_node_embedding2,grid_rect_embedding2      = model2.layer_mesh2grid(grid_mesh_bond_embedding2,mesh_node_embedding2,grid_rect_embedding2)\n",
    "    grid_rect_embedding2      = grid_rect_embedding2[:,model2.M2G_LaLotudePos2grid] #(B,64,128,embed_dim)\n",
    "    out2 = model2.projection(grid_rect_embedding2).permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363e6c89",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():out1 = model1(fixed_input)\n",
    "with torch.no_grad():out2 = model2(fixed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6651e5ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002)\n"
     ]
    }
   ],
   "source": [
    "print(torch.dist(out1,out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3118a3b5",
   "metadata": {
    "code_folding": [
     1,
     7,
     8,
     28,
     29,
     88,
     115,
     127
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def fastinit1(embed_dim1,embed_dim2):\n",
    "    # for tensor (a,b) `fan_in` deal with b `fan_out` deal with a\n",
    "    # a linear weight is (out_dim, in_dim) and use `fan_in`\n",
    "    # but here we direct do matrix matmul, thus fan_out\n",
    "    return torch.nn.init.kaiming_uniform_(torch.randn(embed_dim1, embed_dim2), mode='fan_out', a=math.sqrt(5)) \n",
    "\n",
    "class Node2Edge2NodeBlock(nn.Module):\n",
    "    def __init__(self,embed_dim=128, do_source_update = False,**kargs):\n",
    "        super().__init__()\n",
    "        initial_weight = fastinit1(3*embed_dim, embed_dim)\n",
    "        STE2E_S2E,STE2E_T2E,STE2E_E2E = torch.split(initial_weight,embed_dim)\n",
    "        self.STE2E_S2E = nn.Parameter(STE2E_S2E)\n",
    "        self.STE2E_T2E = nn.Parameter(STE2E_T2E)\n",
    "        self.STE2E_E2E = nn.Parameter(STE2E_E2E)\n",
    "        self.activator1 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "        \n",
    "        initial_weight = fastinit1(2*embed_dim, embed_dim)\n",
    "        ET2T_E2T,ET2T_T2T = torch.split(initial_weight,embed_dim)\n",
    "        self.ET2T_E2T  = nn.Parameter(ET2T_E2T)\n",
    "        self.ET2T_T2T  = nn.Parameter(ET2T_T2T)\n",
    "        self.activator2 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "        \n",
    "        self.S2S = None\n",
    "        if do_source_update:\n",
    "            self.S2S     = nn.Parameter(fastinit1(embed_dim, embed_dim))\n",
    "            self.activator3 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "\n",
    "class Node2Edge2NodeBlockSingleLevel(Node2Edge2NodeBlock):\n",
    "    def __init__(self, src_tgt_order, edge_order, bond_coef, \n",
    "                 embed_dim=128,do_source_update = False, agg_way='mean',\n",
    "                 **kargs):\n",
    "        super().__init__(embed_dim=embed_dim,do_source_update = do_source_update)\n",
    "        self.src_order = src_tgt_order[:,0]\n",
    "        self.tgt_order = src_tgt_order[:,1]\n",
    "        self.edge_order= edge_order\n",
    "        #self.bond_coef = bond_coef\n",
    "        #self.register_buffer('G2M_edge_coef_node_tensor', G2M_edge_coef_node_tensor)\n",
    "        self.agg_way  = agg_way\n",
    "        self.bond_coef  = bond_coef\n",
    "        # do not use nn.Parameter(bond_coef,requires_grad=False), since we may freeze or unfreeze model\n",
    "        # or use regist('bond_coef',bond_coef) but will bug in multiGPU mode\n",
    "        \n",
    "        self.src_index_limit  = self.src_order.max() + 1\n",
    "        self.tgt_index_limit  = self.tgt_order.max() + 1\n",
    "        self.edge_index_limit = len(self.src_order)\n",
    "    \n",
    "    def node2bond(self,bond_embedding, src_embedding, tgt_embedding,activator):\n",
    "        ## compute delta bond embedding\n",
    "        delta_bond_embedding = (src_embedding @ self.STE2E_S2E)[:,self.src_order] #(B,L,D)\n",
    "        delta_bond_embedding = delta_bond_embedding + (tgt_embedding @ self.STE2E_T2E)[:,self.tgt_order] #(B,L,D)\n",
    "        delta_bond_embedding = delta_bond_embedding + bond_embedding @ self.STE2E_E2E  #(B,1,D)\n",
    "        delta_bond_embedding = activator(delta_bond_embedding) #(B,L,D)\n",
    "        return delta_bond_embedding\n",
    "    \n",
    "    def bond2node(self,bond_embedding, src_embedding, tgt_embedding,activator):\n",
    "        device = self.STE2E_S2E.device\n",
    "        self.bond_coef       = self.bond_coef.to(device)\n",
    "        bond_reduce = bond_embedding@self.ET2T_E2T\n",
    "        if self.agg_way == 'mean':\n",
    "            bond_reduce = (bond_reduce[:,self.edge_order]*self.bond_coef.unsqueeze(-1)).mean(-2)\n",
    "        elif self.agg_way == 'sum':\n",
    "            bond_reduce = (bond_reduce[:,self.edge_order]*self.bond_coef.unsqueeze(-1)).sum(-2)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        delta_tgt_embedding = bond_reduce + tgt_embedding@self.ET2T_T2T\n",
    "        delta_tgt_embedding = activator(delta_tgt_embedding)\n",
    "        return delta_tgt_embedding\n",
    "    \n",
    "    def forward(self, bond_embedding, src_embedding, tgt_embedding):\n",
    "        ### shape checking\n",
    "        ### all the necessary rect of grid is recorded in G2M_grid2LaLotudePos\n",
    "        #### we will plus north south point at the begining torch.cat([north_south_embedding,grid_rect_embedding],1)\n",
    "        assert len(bond_embedding.shape) == len(src_embedding.shape) == len(tgt_embedding.shape) == 3\n",
    "        assert self.src_index_limit  ==  src_embedding.shape[1]\n",
    "        assert self.tgt_index_limit  ==  tgt_embedding.shape[1]\n",
    "        assert self.edge_index_limit == bond_embedding.shape[1] \n",
    "        device = self.STE2E_S2E.device\n",
    "        self.bond_coef = self.bond_coef.to(device)\n",
    "        delta_bond_embedding = self.node2bond(bond_embedding, src_embedding, tgt_embedding, self.activator1)\n",
    "        delta_tgt_embedding  = self.bond2node(delta_bond_embedding, src_embedding, tgt_embedding, self.activator2)\n",
    "        delta_src_embedding  = self.activator3(src_embedding@self.S2S) if self.S2S is not None else 0\n",
    "        bond_embedding= bond_embedding  + delta_bond_embedding\n",
    "        src_embedding = src_embedding   + delta_src_embedding\n",
    "        tgt_embedding = tgt_embedding   + delta_tgt_embedding\n",
    "        \n",
    "        return bond_embedding,src_embedding,tgt_embedding\n",
    "\n",
    "class Node2Edge2NodeBlockMultiLevel(Node2Edge2NodeBlockSingleLevel):\n",
    "    def bond2node(self,bond_embedding, src_embedding, tgt_embedding,activator):\n",
    "        device = self.STE2E_S2E.device\n",
    "        self.bond_coef       = self.bond_coef.to(device)\n",
    "        delta_bond_embedding = bond_embedding@self.ET2T_E2T\n",
    "        delta_bond_embedding = torch.nn.functional.pad(delta_bond_embedding,(0,0,0,1))\n",
    "        # notice the nearby node of each level either 5 or 6, then we use -1 as the padding number.\n",
    "        # notice some node has multi-level nearby,\n",
    "        bond_reduce = torch.zeros_like(tgt_embedding)\n",
    "        for start_node, end_node_list in self.edge_order:\n",
    "            bond_reduce[:,start_node] += delta_bond_embedding[:,end_node_list].sum(-2)\n",
    "        bond_reduce = bond_reduce/self.bond_coef\n",
    "        delta_tgt_embedding = bond_reduce + tgt_embedding@self.ET2T_T2T\n",
    "        delta_tgt_embedding = activator(delta_tgt_embedding)\n",
    "        return delta_tgt_embedding\n",
    "    \n",
    "    def forward(self, bond_embedding, src_embedding, tgt_embedding):\n",
    "        ### shape checking\n",
    "        ### all the necessary rect of grid is recorded in G2M_grid2LaLotudePos\n",
    "        #### we will plus north south point at the begining torch.cat([north_south_embedding,grid_rect_embedding],1)\n",
    "        assert len(bond_embedding.shape) == len(src_embedding.shape) == len(tgt_embedding.shape) == 3\n",
    "        delta_bond_embedding = self.node2bond(bond_embedding, src_embedding, tgt_embedding, self.activator1)\n",
    "        delta_tgt_embedding = self.bond2node(delta_bond_embedding, src_embedding, tgt_embedding, self.activator2)\n",
    "        bond_embedding = bond_embedding + delta_bond_embedding\n",
    "        tgt_embedding  = tgt_embedding  + delta_tgt_embedding\n",
    "        return bond_embedding,None,tgt_embedding\n",
    "\n",
    "class GraphCastFast(MeshCast):\n",
    "    '''\n",
    "    ---> 1.5 speed up\n",
    "    Repreduce of GraphCast in Pytorch.\n",
    "    GraphCast has three part:\n",
    "    - Grid to Mesh\n",
    "    - Mesh to Mesh\n",
    "    - Mesh to Grid\n",
    "    -------------------------------------\n",
    "    the input is a tensor (B, P, W, H), but the internal tensor all with shape (B, L ,P)\n",
    "    where the L equal the node number or edge number.\n",
    "    '''\n",
    "    def __init__(self, img_size=(64,128),  in_chans=70, out_chans=70, depth=6, embed_dim=128, graphflag='mesh5', agg_way='mean', nonlinear='swish', **kargs):\n",
    "        super().__init__()\n",
    "        flag = graphflag\n",
    "        resolution_flag=f'{img_size[0]}x{img_size[1]}'\n",
    "        ROOTPATH=f\"GraphCastStructure/{flag}\"\n",
    "        if not os.path.exists(ROOTPATH):\n",
    "            self.generate_mesh2mesh_graph_static_file(flag)\n",
    "        M2M_node2position                 = np.load(os.path.join(ROOTPATH   ,f\"M2M_node2position.npy\"   ))\n",
    "        M2M_position2node                 = torch.load(os.path.join(ROOTPATH,f\"M2M_position2node.pt\"   )                 )\n",
    "        M2M_node2lined_node               = torch.load(os.path.join(ROOTPATH,f\"M2M_node2lined_node.pt\"   )               )\n",
    "        # M2M_edge2id                       = torch.load(os.path.join(ROOTPATH,f\"M2M_edge2id.pt\"   )                       )\n",
    "\n",
    "        M2M_edgeid2pair                   = np.load(os.path.join(ROOTPATH   ,f\"M2M_edgeid2pair.npy\"   ))\n",
    "        M2M_nearby_edge_per_node_per_level= torch.load(os.path.join(ROOTPATH,f\"M2M_nearby_edge_per_node_per_level.pt\"   ))\n",
    "        #M2M_nearby_node_per_node_per_level= torch.load(os.path.join(ROOTPATH,f\"M2M_nearby_node_per_node_per_level.pt\"   ))\n",
    "\n",
    "        ROOTPATH=f\"GraphCastStructure/{flag}/{resolution_flag}\"\n",
    "        if not os.path.exists(ROOTPATH):self.generate_grid2mesh_graph_static_file(flag,img_size[0])\n",
    "        G2M_grid2LaLotudePos = np.load(os.path.join(ROOTPATH,f\"G2M_grid2LaLotudePos.npy\"   )     )\n",
    "        M2G_LaLotudePos2grid = np.load(os.path.join(ROOTPATH,f\"M2G_LaLotudeGrid2rect_tensor.npy\"))\n",
    "\n",
    "        # G2M_rect_of_node_tensor    = np.load(os.path.join(ROOTPATH,f\"G2M_rect_of_node_tensor.npy\"   ) )\n",
    "        # G2M_rect_distant_tensor    = np.load(os.path.join(ROOTPATH,f\"G2M_rect_distant_tensor.npy\"   ) )\n",
    "        G2M_edge_id_of_node_tensor = np.load(os.path.join(ROOTPATH,f\"G2M_edge_id_of_node_tensor.npy\") )\n",
    "        G2M_edge_coef_node_tensor  = np.load(os.path.join(ROOTPATH,f\"G2M_edge_coef_node_tensor.npy\" ) )\n",
    "        G2M_edge_id2pair_tensor    = np.load(os.path.join(ROOTPATH,f\"G2M_edge_id2pair_tensor.npy\"   ) )\n",
    "        # G2M_edge_pos2_id           = torch.load(os.path.join(ROOTPATH,f\"G2M_edge_pos2_id.pt\"   ))\n",
    "        # M2G_node_of_rect_tensor    = np.load(os.path.join(ROOTPATH,f\"M2G_node_of_rect_tensor.npy\"   ))    \n",
    "        # M2G_node_distant_tensor    = np.load(os.path.join(ROOTPATH,f\"M2G_node_of_rect_tensor.npy\"   ))    \n",
    "        M2G_edge_id_of_grid_tensor= np.load(os.path.join(ROOTPATH,f\"M2G_edge_id_of_grid_tensor.npy\"   ))  \n",
    "        M2G_edge_coef_grid_tensor = np.load(os.path.join(ROOTPATH,f\"M2G_edge_coef_grid_tensor.npy\"   ) )  \n",
    "        M2G_edge_id2pair_tensor   = np.load(os.path.join(ROOTPATH,f\"M2G_edge_id2pair_tensor.npy\")      )  \n",
    "        \n",
    "        embedding_dim = embed_dim\n",
    "        self.num_unactivated_grid = num_unactivated_grid = len(M2G_edge_id_of_grid_tensor) - len(G2M_grid2LaLotudePos) - 2\n",
    "        self.num_unactivated_edge = num_unactivated_edge = len(M2G_edge_id2pair_tensor) - len(G2M_edge_id2pair_tensor)\n",
    "        print(f'''\n",
    "        This is ===> GraphCast Model (Fast) <===\n",
    "        Information: \n",
    "            total mesh node:{len(M2M_node2position):5d} total unique mesh edge:{len(M2M_edgeid2pair):5d} \n",
    "            total grid node {np.prod(img_size)}+2 = {(len(M2G_edge_id_of_grid_tensor))} but activated grid {len(G2M_grid2LaLotudePos):5d} +  2\n",
    "            from activated grid to mesh, create 4*{len(M2M_node2position)} = {len(G2M_edge_id2pair_tensor)} edge\n",
    "            there are {num_unactivated_grid} unactivated grid node\n",
    "            when mapping node to grid, \n",
    "            from node to activated grid, there are {len(G2M_edge_id2pair_tensor)} \n",
    "            from node to unactivated grid, there are {num_unactivated_edge} edge\n",
    "            thus, totally have {len(M2G_edge_id2pair_tensor)} edge. \n",
    "            #notice some grid only have 1-2 linked node but some grid may have 30 lined node\n",
    "        ''')\n",
    "        G2M_edge_id2pair_tensor   = torch.LongTensor(G2M_edge_id2pair_tensor)\n",
    "        G2M_edge_coef_node_tensor = torch.Tensor(G2M_edge_coef_node_tensor).softmax(-1)\n",
    "        \n",
    "\n",
    "        M2M_edgeid2pair                    = torch.LongTensor(M2M_edgeid2pair)\n",
    "        M2M_nearby_edge_per_node_per_level = [[torch.LongTensor(start_node),torch.LongTensor(linked_edge_list)] for start_node,linked_edge_list in M2M_nearby_edge_per_node_per_level]\n",
    "        M2M_num_of_linked_nodes            = torch.FloatTensor([len(M2M_node2lined_node[t]) for t in range(len(M2M_node2lined_node))]).unsqueeze(-1)\n",
    "        \n",
    "        M2G_edge_id2pair_tensor  = torch.LongTensor(M2G_edge_id2pair_tensor) # (L,2)\n",
    "        #notice the M2G_edge_id2pair_tensor record (rect_id , node_id) but in this implement\n",
    "        # the order should be (src,tgt) which is node_id,rect_id\n",
    "        # lets convert it . \n",
    "        M2G_edge_id2pair_tensor  = torch.stack([M2G_edge_id2pair_tensor[:,1],M2G_edge_id2pair_tensor[:,0]],-1)\n",
    "        \n",
    "        M2G_edge_of_rect_tensor  = torch.LongTensor(M2G_edge_id_of_grid_tensor)\n",
    "        M2G_edge_coef_grid_tensor= torch.Tensor(M2G_edge_coef_grid_tensor).softmax(-1)\n",
    "\n",
    "\n",
    "        M2G_LaLotudePos2grid = torch.LongTensor(M2G_LaLotudePos2grid)\n",
    "        G2M_grid2LaLotudePos = torch.LongTensor(G2M_grid2LaLotudePos)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        self.M2G_LaLotudePos2grid = M2G_LaLotudePos2grid\n",
    "        self.G2M_grid2LaLotudePos = G2M_grid2LaLotudePos\n",
    "        \n",
    "        self.layer_grid2mesh = Node2Edge2NodeBlockSingleLevel(G2M_edge_id2pair_tensor,G2M_edge_id_of_node_tensor,G2M_edge_coef_node_tensor, \n",
    "                                    embed_dim=embedding_dim,do_source_update=True,agg_way=agg_way)\n",
    "        \n",
    "        self.layer_mesh2mesh = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.layer_mesh2mesh.append(Node2Edge2NodeBlockMultiLevel(M2M_edgeid2pair, M2M_nearby_edge_per_node_per_level, M2M_num_of_linked_nodes, \n",
    "                                                  embed_dim=embedding_dim))\n",
    "        \n",
    "        self.layer_mesh2grid = Node2Edge2NodeBlockSingleLevel(M2G_edge_id2pair_tensor,M2G_edge_of_rect_tensor,M2G_edge_coef_grid_tensor, \n",
    "                                         embed_dim=embedding_dim,agg_way=agg_way)\n",
    "        \n",
    "        self.grid_rect_embedding_layer = nn.Linear(in_chans,embedding_dim)\n",
    "        self.northsouthembbed = nn.Parameter(torch.randn(2,embedding_dim))\n",
    "        \n",
    "        self.mesh_node_embedding       = nn.Parameter(torch.randn(1,len(M2M_node2position)      ,embedding_dim))\n",
    "        self.mesh_mesh_bond_embedding  = nn.Parameter(torch.randn(1,len(M2M_edgeid2pair)        ,embedding_dim))\n",
    "        self.grid_mesh_bond_embedding  = nn.Parameter(torch.randn(1,len(G2M_edge_id2pair_tensor),embedding_dim))\n",
    "\n",
    "        self.projection      = nn.Linear(embedding_dim,out_chans)\n",
    "\n",
    "    def forward(self, _input):\n",
    "        B, P , W, H =_input.shape\n",
    "        feature_along_latlot     = self.grid_rect_embedding_layer(_input.permute(0,2,3,1).flatten(1,2))\n",
    "        grid_rect_embedding      = feature_along_latlot[:,self.G2M_grid2LaLotudePos]\n",
    "        grid_rect_embedding      = torch.cat([self.northsouthembbed.repeat(B,1,1),grid_rect_embedding],1)\n",
    "        grid_mesh_bond_embedding = self.grid_mesh_bond_embedding\n",
    "        mesh_node_embedding      = self.mesh_node_embedding\n",
    "        mesh_mesh_bond_embedding = self.mesh_mesh_bond_embedding\n",
    "        \n",
    "        grid_mesh_bond_embedding,grid_rect_embedding,mesh_node_embedding = self.layer_grid2mesh(\n",
    "                                        grid_mesh_bond_embedding,grid_rect_embedding,mesh_node_embedding)\n",
    "        for mesh2mesh in self.layer_mesh2mesh:\n",
    "            mesh_mesh_bond_embedding, _, mesh_node_embedding  = mesh2mesh(mesh_mesh_bond_embedding, mesh_node_embedding, mesh_node_embedding)\n",
    "        grid_mesh_bond_embedding = torch.nn.functional.pad(grid_mesh_bond_embedding,(0,0,0,self.num_unactivated_edge))\n",
    "        grid_rect_embedding      = torch.nn.functional.pad(grid_rect_embedding,(0,0,0,self.num_unactivated_grid ))\n",
    "        grid_mesh_bond_embedding,mesh_node_embedding,grid_rect_embedding      = self.layer_mesh2grid(grid_mesh_bond_embedding,mesh_node_embedding,grid_rect_embedding)\n",
    "        grid_rect_embedding      = grid_rect_embedding[:,self.M2G_LaLotudePos2grid] #(B,64,128,embed_dim)\n",
    "        return self.projection(grid_rect_embedding).permute(0,3,1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "20bfd795",
   "metadata": {
    "code_folding": [
     70
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class Node2Edge2NodeBlockSingleLevel(nn.Module):\n",
    "#     def __init__(self, src_tgt_order, edge_order, bond_coef, \n",
    "#                  embed_dim=128,do_source_update = False, agg_way='mean',\n",
    "#                  **kargs):\n",
    "#         super().__init__()\n",
    "#         self.src_order = src_tgt_order[:,0]\n",
    "#         self.tgt_order = src_tgt_order[:,1]\n",
    "#         self.edge_order= edge_order\n",
    "#         #self.bond_coef = bond_coef\n",
    "#         #self.register_buffer('G2M_edge_coef_node_tensor', G2M_edge_coef_node_tensor)\n",
    "#         self.agg_way  = agg_way\n",
    "        \n",
    "#         self.STE2E   = nn.Parameter(fastinit1(3*embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.STE2E_S2E = nn.Parameter(fastinit1(3*embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.STE2E_T2E = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.STE2E_E2E = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         self.activator1 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "#         self.ET2T  = nn.Parameter(fastinit1(2*embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.ET2T_E2T  = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.ET2T_T2T  = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         self.activator2 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "#         self.bond_coef  = bond_coef\n",
    "#         self.S2S = None\n",
    "#         if do_source_update:\n",
    "#             self.S2S     = nn.Parameter(fastinit1(embed_dim, embed_dim))\n",
    "#             self.activator3 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "#         self.src_index_limit  = self.src_order.max() + 1\n",
    "#         self.tgt_index_limit  = self.tgt_order.max() + 1\n",
    "#         self.edge_index_limit = len(self.src_order)\n",
    "#         self.embed_dim = embed_dim\n",
    "#     def forward(self, bond_embedding, src_embedding, tgt_embedding):\n",
    "#         ### shape checking\n",
    "#         ### all the necessary rect of grid is recorded in G2M_grid2LaLotudePos\n",
    "#         #### we will plus north south point at the begining torch.cat([north_south_embedding,grid_rect_embedding],1)\n",
    "#         assert len(bond_embedding.shape) == len(src_embedding.shape) == len(tgt_embedding.shape) == 3\n",
    "#         assert self.src_index_limit  ==  src_embedding.shape[1]\n",
    "#         assert self.tgt_index_limit  ==  tgt_embedding.shape[1]\n",
    "#         assert self.edge_index_limit == bond_embedding.shape[1] \n",
    "#         device = self.STE2E.device\n",
    "        \n",
    "#         ## compute delta bond embedding\n",
    "#         self.STE2E_E2E,self.STE2E_S2E,self.STE2E_T2E = torch.split(self.STE2E,self.embed_dim)\n",
    "#         delta_bond_embedding = src_embedding[:,self.src_order] @ self.STE2E_S2E #(B,L,D)\n",
    "#         delta_bond_embedding = delta_bond_embedding + tgt_embedding[:,self.tgt_order] @ self.STE2E_T2E #(B,L,D)\n",
    "#         delta_bond_embedding = delta_bond_embedding + bond_embedding @ self.STE2E_E2E  #(B,1,D)\n",
    "#         delta_bond_embedding = self.activator1(delta_bond_embedding) #(B,L,D)\n",
    "\n",
    "#         ## compute delta tgt embedding\n",
    "#         if self.agg_way == 'mean':\n",
    "#             bond_reduce = (delta_bond_embedding[:,self.edge_order]*self.bond_coef.unsqueeze(-1).to(device)).mean(-2)\n",
    "#         elif self.agg_way == 'sum':\n",
    "#             bond_reduce = (delta_bond_embedding[:,self.edge_order]*self.bond_coef.unsqueeze(-1).to(device)).sum(-2)\n",
    "#         else:\n",
    "#             raise NotImplementedError\n",
    "#         #bond_reduce = torch.einsum('blnd,ln->bld',\n",
    "#         #                           delta_bond_embedding[:,self.edge_order],\n",
    "#         #                           self.bond_coef) ### 2.6 ms vs 2.2 ms\n",
    "#         self.ET2T_T2T, self.ET2T_E2T = torch.split(self.ET2T,self.embed_dim)\n",
    "#         delta_tgt_embedding = bond_reduce@self.ET2T_E2T\n",
    "#         delta_tgt_embedding = delta_tgt_embedding + tgt_embedding@self.ET2T_T2T\n",
    "#         delta_tgt_embedding = self.activator2(delta_tgt_embedding)\n",
    "        \n",
    "#         delta_src_embedding = self.activator3(src_embedding@self.S2S) if self.S2S is not None else 0\n",
    "        \n",
    "#         bond_embedding= bond_embedding  + delta_bond_embedding\n",
    "#         src_embedding = src_embedding  + delta_src_embedding\n",
    "#         tgt_embedding = tgt_embedding  + delta_tgt_embedding\n",
    "        \n",
    "#         return bond_embedding,src_embedding,tgt_embedding\n",
    "\n",
    "# class Node2Edge2NodeBlockMultiLevel(nn.Module):\n",
    "#     def __init__(self, src_tgt_order, edge_order, num_of_linked_nodes, \n",
    "#                  embed_dim=128,do_source_update = False,\n",
    "#                  **kargs):\n",
    "#         super().__init__()\n",
    "#         self.src_order            = src_tgt_order[:,0]\n",
    "#         self.tgt_order            = src_tgt_order[:,1]\n",
    "#         self.edge_order           = edge_order\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.STE2E   = nn.Parameter(fastinit1(3*embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.STE2E_S2E = nn.Parameter(fastinit1(3*embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.STE2E_T2E = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.STE2E_E2E = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         self.activator1 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "\n",
    "#         self.ET2T  = nn.Parameter(fastinit1(2*embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.ET2T_E2T  = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         # self.ET2T_T2T  = nn.Parameter(fastinit1(embed_dim, embed_dim),requires_grad=True)\n",
    "#         self.activator2 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "#         self.num_of_linked_nodes  = num_of_linked_nodes\n",
    "        \n",
    "#         self.S2S = None\n",
    "#         if do_source_update:\n",
    "#             self.S2S   = nn.Parameter(fastinit1(embed_dim, embed_dim))\n",
    "#             self.activator3 = nn.Sequential(torch.nn.SiLU(),torch.nn.LayerNorm(embed_dim))\n",
    "#         self.embed_dim = embed_dim\n",
    "#     def forward(self, bond_embedding, src_embedding, tgt_embedding):\n",
    "#         ### shape checking\n",
    "#         ### all the necessary rect of grid is recorded in G2M_grid2LaLotudePos\n",
    "#         #### we will plus north south point at the begining torch.cat([north_south_embedding,grid_rect_embedding],1)\n",
    "#         assert len(bond_embedding.shape) == len(src_embedding.shape) == len(tgt_embedding.shape) == 3\n",
    "#         device = self.STE2E.device\n",
    "        \n",
    "        \n",
    "#         ## compute delta bond embedding\n",
    "#         self.STE2E_E2E,self.STE2E_S2E,self.STE2E_T2E = torch.split(self.STE2E,self.embed_dim)\n",
    "#         delta_bond_embedding = src_embedding[:,self.src_order] @ self.STE2E_S2E #(B,L,D)\n",
    "#         delta_bond_embedding = delta_bond_embedding + tgt_embedding[:,self.tgt_order] @ self.STE2E_T2E #(B,L,D)\n",
    "#         delta_bond_embedding = delta_bond_embedding + bond_embedding @ self.STE2E_E2E  #(B,1,D)\n",
    "#         delta_bond_embedding = self.activator1(delta_bond_embedding) #(B,L,D)\n",
    "\n",
    "        \n",
    "#         ## compute delta tgt embedding\n",
    "#         delta_bond_embedding= torch.nn.functional.pad(delta_bond_embedding,(0,0,0,1))\n",
    "#         # notice the nearby node of each level either 5 or 6, then we use -1 as the padding number.\n",
    "#         # notice some node has multi-level nearby,\n",
    "#         bond_reduce = torch.zeros_like(tgt_embedding)\n",
    "#         for start_node, end_node_list in self.edge_order:\n",
    "#             bond_reduce[:,start_node] += delta_bond_embedding[:,end_node_list].sum(-2)\n",
    "#         bond_reduce = bond_reduce/self.num_of_linked_nodes.to(device) #(B,L,D)/(L)\n",
    "\n",
    "#         self.ET2T_T2T, self.ET2T_E2T = torch.split(self.ET2T,self.embed_dim)\n",
    "#         delta_tgt_embedding = bond_reduce@self.ET2T_E2T\n",
    "#         delta_tgt_embedding = delta_tgt_embedding + tgt_embedding@self.ET2T_T2T\n",
    "#         delta_tgt_embedding = self.activator2(delta_tgt_embedding)\n",
    "        \n",
    "#         ## compute delta src embedding\n",
    "#         delta_src_embedding   = self.activator3(src_embedding@self.S2S) if self.S2S is not None else 0\n",
    "        \n",
    "#         bond_embedding = bond_embedding + delta_bond_embedding[:,:-1]\n",
    "#         tgt_embedding  = tgt_embedding  + delta_tgt_embedding\n",
    "        \n",
    "#         return bond_embedding,None,tgt_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb23e84",
   "metadata": {},
   "source": [
    "## Lets check GraphCastDGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c66aaef0",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "from einops import rearrange\n",
    "class Node2Edge2NodeBlockDGL(Node2Edge2NodeBlock):\n",
    "    def __init__(self, src_flag, edgetype, tgt_flag, embed_dim=128,do_source_update=False):\n",
    "        super().__init__(embed_dim=embed_dim,do_source_update = do_source_update)\n",
    "        self.src_flag = src_flag\n",
    "        self.tgt_flag = tgt_flag\n",
    "        self.edgetype = edgetype\n",
    "    def forward(self,g):\n",
    "        src_flag = self.src_flag \n",
    "        tgt_flag = self.tgt_flag \n",
    "        edgetype = self.edgetype \n",
    "        edgeflag = (src_flag,edgetype,tgt_flag)\n",
    "        g.nodes[src_flag].data['src']     = g.nodes[src_flag].data['feat'] @ self.STE2E_S2E\n",
    "        g.nodes[tgt_flag].data['dst']     = g.nodes[tgt_flag].data['feat'] @ self.STE2E_T2E\n",
    "        g.apply_edges(fn.u_add_v('src', 'dst', 'node_to_edge'),etype=edgeflag)\n",
    "        g.edges[edgeflag].data['add_feat'] = self.activator1(g.edges[edgeflag].data['node_to_edge'] + g.edges[edgeflag].data['feat'] @ self.STE2E_E2E)\n",
    "        g.edges[edgeflag].data['feat']  =   g.edges[edgeflag].data['feat'] + g.edges[edgeflag].data['add_feat']\n",
    "        if 'coef' in g.edges[edgeflag].data:g.edges[edgeflag].data['add_feat']*= g.edges[edgeflag].data['coef']\n",
    "        reduce_fun = fn.sum if 'coef' in g.edges[edgeflag].data else fn.mean\n",
    "        g.update_all(fn.copy_e('add_feat','add_feat'),reduce_fun('add_feat', 'add_feat'),etype=edgeflag)\n",
    "        g.nodes[tgt_flag].data['add_feat'] = self.activator2(g.nodes[tgt_flag].data['add_feat'] @ self.ET2T_E2T + \n",
    "                                                             g.nodes[tgt_flag].data['feat'] @ self.ET2T_T2T)\n",
    "        g.nodes[tgt_flag].data['feat']  = g.nodes[tgt_flag].data['feat'] + g.nodes[tgt_flag].data['add_feat']\n",
    "        if self.S2S is not None:g.nodes[src_flag].data['feat'] = g.nodes[src_flag].data['feat']+ self.activator3(g.nodes[src_flag].data['feat']@ self.S2S)\n",
    "        return g\n",
    "\n",
    "class GraphCastDGL(MeshCast):    \n",
    "    '''\n",
    "    ====>  fastest in atom operation test, but slower than GraphCastFast in practice.\n",
    "    ====>  still faster than normal GraphCast\n",
    "    Repreduce of GraphCast in Pytorch.\n",
    "    GraphCast has three part:\n",
    "    - Grid to Mesh\n",
    "    - Mesh to Mesh\n",
    "    - Mesh to Grid\n",
    "    -------------------------------------\n",
    "    the input is a tensor (B, P, W, H), but the internal tensor all with shape (B, L ,P)\n",
    "    where the L equal the node number or edge number.\n",
    "    '''\n",
    "    def __init__(self, img_size=(32,64),  in_chans=70, out_chans=70, depth=6, embed_dim=128, graphflag='mesh5', nonlinear='swish', **kargs):\n",
    "        super().__init__()\n",
    "        flag = graphflag\n",
    "        resolution_flag=f'{img_size[0]}x{img_size[1]}'\n",
    "        ROOTPATH=f\"GraphCastStructure/{flag}\"\n",
    "\n",
    "        M2M_edgeid2pair         = torch.LongTensor(np.load(os.path.join(ROOTPATH,f\"M2M_edgeid2pair.npy\"   )))\n",
    "        ROOTPATH=f\"GraphCastStructure/{flag}/{resolution_flag}\"\n",
    "        G2M_edge_id2pair_tensor = (np.load(os.path.join(ROOTPATH,f\"G2M_edge_id2pair_tensor.npy\")))\n",
    "        #M2G_edge_id2pair_tensor = (np.load(os.path.join(ROOTPATH,f\"M2G_id2edge_max_rank.npy\")))\n",
    "        M2G_edge_id2pair_tensor = (np.load(os.path.join(ROOTPATH,f\"M2G_id2edge_max_rank.npy\")))\n",
    "        self.G2M_grid2LaLotudePos = np.load(os.path.join(ROOTPATH,f\"G2M_grid2LaLotudePos.npy\"   )     )\n",
    "        self.M2G_LaLotudePos2grid = np.load(os.path.join(ROOTPATH,f\"M2G_LaLotudeGrid2rect_tensor.npy\"))\n",
    "\n",
    "        \n",
    "        graph_data = {\n",
    "                    ('mesh', 'M2M', 'mesh')  : (np.concatenate([M2M_edgeid2pair[:,0], M2M_edgeid2pair[:,1]]),\n",
    "                                                np.concatenate([M2M_edgeid2pair[:,1], M2M_edgeid2pair[:,0]])),\n",
    "                    ('grid', 'G2M', 'mesh')  : (G2M_edge_id2pair_tensor[:,0],G2M_edge_id2pair_tensor[:,1]),\n",
    "                    ('mesh', 'M2G', 'grid')  : (M2G_edge_id2pair_tensor[:,1],M2G_edge_id2pair_tensor[:,0]),\n",
    "                    \n",
    "                }\n",
    "        g = dgl.heterograph(graph_data)\n",
    "\n",
    "        total_mesh_node = g.num_nodes('mesh')\n",
    "        total_mesh_edge = g.num_edges('M2M')\n",
    "        total_grid_node = g.num_nodes('grid') - 2\n",
    "        total_G2M_edges = g.num_edges('G2M')\n",
    "        total_M2G_edges = g.num_edges('M2G')\n",
    "        self.activated_gridn  = activated_gridn  = G2M_edge_id2pair_tensor[:,0].max()+1\n",
    "        self.unactivated_grid = unactivated_grid = g.num_nodes('grid') - activated_gridn\n",
    "        \n",
    "        # notice M2G_edge_id2pair_tensor still use (rect_id, node_id)\n",
    "        # we firstly select those pair\n",
    "        shared_index_in_M2G = np.where(M2G_edge_id2pair_tensor[:,0]<=G2M_edge_id2pair_tensor[:,0].max())[0]\n",
    "        shared_pair_u = M2G_edge_id2pair_tensor[shared_index_in_M2G,0]\n",
    "        shared_pair_v = M2G_edge_id2pair_tensor[shared_index_in_M2G,1]\n",
    "        ## now we need find the order of all the ('grid', 'G2M', 'mesh') edge \n",
    "        ## in ('mesh', 'M2G', 'grid') subgraph\n",
    "        ### then we should know the location for each pair in G2M edge list\n",
    "        ##### one thing omit here is that the egde order in M2G is along the M2G_edge_id2pair_tensor index since we use it to create graph\n",
    "        self.reorder_edge_id_of_M2G_from_G2M = g.edge_ids(shared_pair_u,shared_pair_v, etype=('grid', 'G2M', 'mesh')) \n",
    "        self.reorder_edge_id_in_M2G = shared_index_in_M2G\n",
    "        M2G_edge_from_node_to_activate_grid = len(self.reorder_edge_id_of_M2G_from_G2M)\n",
    "        self.num_unactivated_edge = num_unactivated_edge = total_M2G_edges - M2G_edge_from_node_to_activate_grid\n",
    "        print(f'''\n",
    "        This is ===> GraphCast Model(DGL) <===\n",
    "        Information: \n",
    "            total mesh node:{total_mesh_node:5d} total unique mesh edge:{total_mesh_edge//2:5d}*2={total_mesh_edge:5d} \n",
    "            total grid node {total_grid_node}+2 = {total_grid_node+2} but activated grid {activated_gridn} \n",
    "            from activated grid to mesh, create 4*{total_mesh_node} - 6 = {total_G2M_edges} edges. (north and south pole repeat 4 times) \n",
    "            there are {unactivated_grid} unactivated grid node\n",
    "            when mapping node to grid, \n",
    "            from node to activated grid, there are {M2G_edge_from_node_to_activate_grid} edges\n",
    "            from node to unactivated grid, there are {num_unactivated_edge} edges\n",
    "            thus, totally have {total_M2G_edges} edge. \n",
    "            #notice some grid only have 1-2 linked node but some grid may have 30 lined node\n",
    "        ''')\n",
    "\n",
    "        G2M_rect_of_node_tensor= np.load(os.path.join(ROOTPATH,f\"G2M_rect_of_node_tensor.npy\"))  \n",
    "        G2M_rect_distant_tensor= np.load(os.path.join(ROOTPATH,f\"G2M_rect_distant_tensor.npy\") )\n",
    "        G2M_rect_node_tensor= torch.LongTensor(G2M_rect_of_node_tensor)  \n",
    "        G2M_rect_coef_tensor= torch.softmax(torch.FloatTensor(G2M_rect_distant_tensor),axis=-1)\n",
    "\n",
    "        #### create_edge_coef_in_grid2mesh ######\n",
    "        edge_flag = ('grid', 'G2M', 'mesh')\n",
    "        NRC_tensor = torch.Tensor([(node_id, rect_id, coef) for node_id, (rect_list,coef_list) in enumerate(zip(\n",
    "            G2M_rect_node_tensor,G2M_rect_coef_tensor)) for rect_id,coef in zip(rect_list,coef_list)])\n",
    "        edge_idlist = g.edge_ids(NRC_tensor[:,1].long(),NRC_tensor[:,0].long(), etype=edge_flag)    \n",
    "        edge_ids={}\n",
    "        for _id,coef in zip(edge_idlist,NRC_tensor[:,2]):\n",
    "            _id = _id.item()\n",
    "            if _id not in edge_ids:edge_ids[_id]=0\n",
    "            edge_ids[_id] += coef\n",
    "        edge_coef = torch.stack([edge_ids[i] for i in range(len(edge_ids))])\n",
    "        self.G2M_edge_coef = edge_coef.unsqueeze(-1).unsqueeze(-1)\n",
    "        #g.edges[edge_flag].data['coef'] = \n",
    "\n",
    "        #### create_edge_coef_in_mesh2grid ######\n",
    "        edge_flag = ('mesh', 'M2G', 'grid')\n",
    "        M2G_node_of_rect_tensor = np.load(os.path.join(ROOTPATH,f\"M2G_node_of_rect_tensor.npy\"   ))  \n",
    "        M2G_node_distant_tensor = np.load(os.path.join(ROOTPATH,f\"M2G_node_distant_tensor.npy\"   ))  \n",
    "        M2G_node_distant_tensor[M2G_node_distant_tensor<0]=-100\n",
    "        M2G_node_of_rect_tensor = torch.LongTensor(M2G_node_of_rect_tensor)  \n",
    "        M2G_node_distant_tensor = torch.softmax(torch.FloatTensor(M2G_node_distant_tensor),axis=-1)\n",
    "\n",
    "        NRC_tensor = torch.Tensor([(node_id, rect_id, coef) for rect_id, (node_list,coef_list) in enumerate(zip(\n",
    "            M2G_node_of_rect_tensor,M2G_node_distant_tensor)) for node_id,coef in zip(node_list,coef_list) if node_id>=0]  )\n",
    "        edge_idlist = g.edge_ids(NRC_tensor[:,0].long(),NRC_tensor[:,1].long(), etype=edge_flag)  \n",
    "\n",
    "        edge_ids={}\n",
    "        for _id,coef in zip(edge_idlist,NRC_tensor[:,2]):\n",
    "            _id = _id.item()\n",
    "            if _id not in edge_ids:edge_ids[_id]=0\n",
    "            edge_ids[_id] += coef\n",
    "        edge_coef = torch.stack([edge_ids[i] for i in range(len(edge_ids))])\n",
    "        self.M2G_edge_coef = edge_coef.unsqueeze(-1).unsqueeze(-1)\n",
    "        #g.edges[edge_flag].data['coef'] = torch.nn.Parameter(edge_coef ,requires_grad=False) # to automatively go into cuda\n",
    "        edge_flag = ('mesh', 'M2M', 'mesh')\n",
    "        self.grid2mesh = Node2Edge2NodeBlockDGL('grid','G2M','mesh',embed_dim=embed_dim,do_source_update=True)\n",
    "        self.mesh2mesh = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.mesh2mesh.append(Node2Edge2NodeBlockDGL('mesh','M2M','mesh',embed_dim=embed_dim))        \n",
    "        self.mesh2grid = Node2Edge2NodeBlockDGL('mesh','M2G','grid',embed_dim=embed_dim)\n",
    "\n",
    "\n",
    "        self.grid_rect_embedding_layer = nn.Linear(in_chans,embed_dim)\n",
    "\n",
    "        self.projection                = nn.Linear(embed_dim,out_chans)\n",
    "\n",
    "        self.northsouthembbed          = nn.Parameter(torch.randn(2,embed_dim))\n",
    "        self.mesh_node_embedding       = nn.Parameter(torch.randn(g.num_nodes('mesh')               ,1, embed_dim))\n",
    "        self.mesh_mesh_bond_embedding  = nn.Parameter(torch.randn(g.num_edges('M2M')                ,1, embed_dim))\n",
    "        self.grid_mesh_bond_embedding  = nn.Parameter(torch.randn(g.num_edges('G2M'),1, embed_dim))\n",
    "        self.mesh_grid_bond_template   = torch.randn(g.num_edges('M2G'),1, embed_dim)\n",
    "        self.g = g\n",
    "        self.embed_dim = embed_dim\n",
    "    def forward(self, _input):\n",
    "        B, P , W, H =_input.shape\n",
    "        device = next(self.parameters()).device\n",
    "        self.g = self.g.to(device)\n",
    "        # (B,P,W,H) -> (B,W*H,P)\n",
    "        feature_along_latlot     = self.grid_rect_embedding_layer(rearrange(_input,\"B P W H -> (W H) B P\"))\n",
    "        grid_rect_embedding      = feature_along_latlot[self.G2M_grid2LaLotudePos] # (L,B,D)\n",
    "        grid_rect_embedding      = torch.cat([rearrange(self.northsouthembbed.repeat(B,1,1),\"B L D -> L B D\"),\n",
    "                                                grid_rect_embedding]) ## --> (L+2, B, D)\n",
    "\n",
    "        g = self.g\n",
    "        g.nodes['grid'].data['feat']= torch.nn.functional.pad(grid_rect_embedding,(0,0,0,0,0,self.unactivated_grid))\n",
    "        g.nodes['mesh'].data['feat']= self.mesh_node_embedding\n",
    "        g.edges['G2M'].data['feat'] = self.grid_mesh_bond_embedding\n",
    "        g.edges['M2M'].data['feat'] = self.mesh_mesh_bond_embedding      \n",
    "        g.edges['G2M'].data['coef'] = self.G2M_edge_coef.to(device)\n",
    "        g.edges['M2G'].data['coef'] = self.M2G_edge_coef.to(device)\n",
    "        #checknan(g,'initial');\n",
    "        g = self.grid2mesh(g)\n",
    "        #checknan(g,'grid2mesh');\n",
    "        for layer_idx, mesh2mesh in enumerate(self.mesh2mesh):\n",
    "            g = mesh2mesh(g);#checknan(g,f\"mesh2mesh_{layer_idx}\")\n",
    "        g.edges['M2G'].data['feat'] = torch.nn.functional.pad(g.edges['G2M'].data['feat'][self.reorder_edge_id_of_M2G_from_G2M],(0,0,0,0,0,self.num_unactivated_edge))\n",
    "        g  = self.mesh2grid(g);#checknan(g,'mesh2grid');\n",
    "        out = g.nodes['grid'].data['feat'][self.M2G_LaLotudePos2grid] #(64,128,B,embed_dim)\n",
    "        return self.projection(out).permute(2,3,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "84253b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        This is ===> GraphCast Model(DGL) <===\n",
      "        Information: \n",
      "            total mesh node: 2562 total unique mesh edge:10230*2=20460 \n",
      "            total grid node 2048+2 = 2050 but activated grid 1928 \n",
      "            from activated grid to mesh, create 4*2562 - 6 = 10242 edges. (north and south pole repeat 4 times) \n",
      "            there are 122 unactivated grid node\n",
      "            when mapping node to grid, \n",
      "            from node to activated grid, there are 10032 edges\n",
      "            from node to unactivated grid, there are 976 edges\n",
      "            thus, totally have 11008 edge. \n",
      "            #notice some grid only have 1-2 linked node but some grid may have 30 lined node\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "model2 = GraphCastDGL(img_size=(32,64),in_chans=70,out_chans=70,embed_dim=512,depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "98a5f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.grid_rect_embedding_layer      = model1.grid_rect_embedding_layer\n",
    "model2.northsouthembbed.data          = model1.northsouthembbed.data\n",
    "model2.grid_mesh_bond_embedding.data  = model1.grid_mesh_bond_embedding.data.unsqueeze(1)\n",
    "model2.mesh_node_embedding.data       =      model1.mesh_node_embedding.data.unsqueeze(1) \n",
    "model2.mesh_mesh_bond_embedding.data  = model1.mesh_mesh_bond_embedding.data.unsqueeze(1) \n",
    "model2.projection = model1.projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bcaf8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model2.grid2mesh.STE2E_E2E.data,\n",
    " model2.grid2mesh.STE2E_S2E.data,\n",
    " model2.grid2mesh.STE2E_T2E.data)= torch.split(model1.layer_grid2mesh.MLP_G2M_GM2E.linear.weight.permute(1,0).data,512)\n",
    "(model2.grid2mesh.ET2T_T2T.data,\n",
    " model2.grid2mesh.ET2T_E2T.data)= torch.split(model1.layer_grid2mesh.MLP_G2M_E2M.linear.weight.permute(1,0).data,512)\n",
    "model2.grid2mesh.S2S.data      = model1.layer_grid2mesh.MLP_G2M_G2G.linear.weight.permute(1,0)\n",
    "model2.grid2mesh.activator1[1] = model1.layer_grid2mesh.MLP_G2M_GM2E.norm\n",
    "model2.grid2mesh.activator2[1] = model1.layer_grid2mesh.MLP_G2M_E2M.norm\n",
    "model2.grid2mesh.activator3[1] = model1.layer_grid2mesh.MLP_G2M_G2G.norm\n",
    "\n",
    "for layer1,layer2 in zip(model1.layer_mesh2mesh,model2.mesh2mesh):\n",
    "    (layer2.STE2E_E2E.data,\n",
    "     layer2.STE2E_S2E.data,\n",
    "     layer2.STE2E_T2E.data)= torch.split(layer1.MLP_M2M_N2E.linear.weight.permute(1,0).data,512)\n",
    "    (layer2.ET2T_T2T.data,\n",
    "     layer2.ET2T_E2T.data)= torch.split(layer1.MLP_M2M_E2N.linear.weight.permute(1,0).data,512)\n",
    "    layer2.activator1[1] = layer1.MLP_M2M_N2E.norm\n",
    "    layer2.activator2[1] = layer1.MLP_M2M_E2N.norm\n",
    "\n",
    "(model2.mesh2grid.STE2E_E2E.data,\n",
    " model2.mesh2grid.STE2E_S2E.data,\n",
    " model2.mesh2grid.STE2E_T2E.data)= torch.split(model1.layer_mesh2grid.MLP_M2G_MG2E.linear.weight.permute(1,0).data,512)\n",
    "(model2.mesh2grid.ET2T_T2T.data,\n",
    " model2.mesh2grid.ET2T_E2T.data)= torch.split(model1.layer_mesh2grid.MLP_M2G_E2G.linear.weight.permute(1,0).data,512)\n",
    "model2.mesh2grid.activator1[1] = model1.layer_mesh2grid.MLP_M2G_MG2E.norm\n",
    "model2.mesh2grid.activator2[1] = model1.layer_mesh2grid.MLP_M2G_E2G.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5db36955",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_input = torch.randn(2,70,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "02882dab",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    B, P , W, H =fixed_input.shape\n",
    "    feature_along_latlot1     = model1.grid_rect_embedding_layer(fixed_input.permute(0,2,3,1).flatten(1,2))\n",
    "    grid_rect_embedding1      = feature_along_latlot1[:,model1.G2M_grid2LaLotudePos]\n",
    "    grid_rect_embedding1      = torch.cat([model1.northsouthembbed.repeat(B,1,1),grid_rect_embedding1],1)\n",
    "    grid_mesh_bond_embedding1 = model1.grid_mesh_bond_embedding.repeat(B,1,1)\n",
    "    mesh_node_embedding1      = model1.mesh_node_embedding.repeat(B,1,1)\n",
    "    mesh_mesh_bond_embedding1 = model1.mesh_mesh_bond_embedding.repeat(B,1,1)\n",
    "    ###########################################################################################\n",
    "    grid_mesh_bond_embedding1,grid_rect_embedding1,mesh_node_embedding1 = model1.layer_grid2mesh(\n",
    "                                    grid_mesh_bond_embedding1,grid_rect_embedding1,mesh_node_embedding1,\n",
    "                                    edge_agg_fun=torch.sum)\n",
    "    ###   delta_grid_mesh_bond_embedding1 = model1.layer_grid2mesh.MLP_G2M_GM2E(torch.cat([grid_mesh_bond_embedding1,\n",
    "    ###                               grid_rect_embedding1[:,model1.layer_grid2mesh.G2M_edge_id2pair_tensor[:,0]],\n",
    "    ###                               mesh_node_embedding1[:,model1.layer_grid2mesh.G2M_edge_id2pair_tensor[:,1]]],-1))\n",
    "    ###   delta_mesh_node_embedding1      = model1.layer_grid2mesh.MLP_G2M_E2M(torch.cat([mesh_node_embedding1,\n",
    "    ###           torch.sum(delta_grid_mesh_bond_embedding1[:,model1.layer_grid2mesh.G2M_edge_id_of_node_tensor]*model1.layer_grid2mesh.G2M_edge_coef_node_tensor.to(device),\n",
    "    ###                                   -2)],-1))\n",
    "    ###   delta_grid_rect_embedding1      = model1.layer_grid2mesh.MLP_G2M_G2G(grid_rect_embedding1)\n",
    "    ###   grid_mesh_bond_embedding1      += delta_grid_mesh_bond_embedding1\n",
    "    ###   grid_rect_embedding1           += delta_grid_rect_embedding1\n",
    "    ###   mesh_node_embedding1           += delta_mesh_node_embedding1\n",
    "    ###########################################################################################\n",
    "    #mesh_mesh_bond_embedding1, mesh_node_embedding1  = model1.layer_mesh2mesh[0](mesh_mesh_bond_embedding1, mesh_node_embedding1)\n",
    "    device = model1.layer_mesh2mesh[0].MLP_M2M_N2E.linear.weight.device\n",
    "    delta_mesh_mesh_bond_embedding1 = model1.layer_mesh2mesh[0].MLP_M2M_N2E(torch.cat([mesh_mesh_bond_embedding1,\n",
    "                                    mesh_node_embedding1[:,model1.layer_mesh2mesh[0].M2M_edgeid2pair[:,0]],\n",
    "                                    mesh_node_embedding1[:,model1.layer_mesh2mesh[0].M2M_edgeid2pair[:,1]]],-1))\n",
    "    mesh_mesh_bond_embedding1 += delta_mesh_mesh_bond_embedding1\n",
    "    delta_mesh_mesh_bond_embedding1= torch.nn.functional.pad(delta_mesh_mesh_bond_embedding1,(0,0,0,1))\n",
    "    # notice the nearby node of each level either 5 or 6, then we use -1 as the padding number.\n",
    "    mesh_node_aggregration = torch.zeros_like(mesh_node_embedding1)\n",
    "    for start_node, end_node_list in model1.layer_mesh2mesh[0].key_nearbyedge_pair_per_level:\n",
    "        mesh_node_aggregration[:,start_node] += delta_mesh_mesh_bond_embedding1[:,end_node_list].sum(-2)\n",
    "    mesh_node_aggregration = mesh_node_aggregration/model1.layer_mesh2mesh[0].num_of_linked_nodes.to(device)\n",
    "\n",
    "    delta_mesh_node_embedding1 = model1.layer_mesh2mesh[0].MLP_M2M_E2N(torch.cat([mesh_node_embedding1,mesh_node_aggregration],-1))\n",
    "    mesh_node_embedding1      += delta_mesh_node_embedding1    \n",
    "    ###########################################################################################\n",
    "    grid_mesh_bond_embedding1 = torch.nn.functional.pad(grid_mesh_bond_embedding1,(0,0,0,model1.num_unactivated_edge))\n",
    "    grid_rect_embedding1      = torch.nn.functional.pad(grid_rect_embedding1,(0,0,0,model1.num_unactivated_grid ))\n",
    "    ###########################################################################################\n",
    "    #grid_rect_embedding1      = model1.layer_mesh2grid(grid_mesh_bond_embedding1,grid_rect_embedding1,mesh_node_embedding1,\n",
    "    #                                                       edge_agg_fun=torch.sum)\n",
    "    mesh_grid_bond_embedding1,grid_allrect_embedding1,mesh_node_embedding1=grid_mesh_bond_embedding1,grid_rect_embedding1,mesh_node_embedding1\n",
    "    device = model1.layer_mesh2grid.MLP_M2G_MG2E.linear.weight.device\n",
    "    weight = model1.layer_mesh2grid.MLP_M2G_MG2E.linear.weight\n",
    "#     delta_mesh_grid_bond_embedding = model1.layer_mesh2grid.MLP_M2G_MG2E(torch.cat([mesh_grid_bond_embedding1,\n",
    "#                                       mesh_node_embedding1[:,model1.layer_mesh2grid.M2G_edge_id2pair_tensor[:,1]],\n",
    "#                                    grid_allrect_embedding1[:,model1.layer_mesh2grid.M2G_edge_id2pair_tensor[:,0]]],-1))\n",
    "    delta_mesh_grid_bond_embedding1 =(torch.cat([\n",
    "        mesh_grid_bond_embedding1,\n",
    "        mesh_node_embedding1[:,model1.layer_mesh2grid.M2G_edge_id2pair_tensor[:,1]],\n",
    "        grid_allrect_embedding1[:,model1.layer_mesh2grid.M2G_edge_id2pair_tensor[:,0]]],-1)@weight.permute(1,0))\n",
    "    \n",
    "    delta_grid_rect_embedding1 = torch.sum(delta_mesh_grid_bond_embedding1[:,model1.layer_mesh2grid.M2G_edge_id_of_grid_tensor]*model1.layer_mesh2grid.M2G_edge_coef_grid_tensor.to(device)\n",
    "                                           ,-2)\n",
    "    delta_grid_rect_embedding1 =  model1.layer_mesh2grid.MLP_M2G_E2G(\n",
    "        torch.cat([grid_allrect_embedding1,delta_grid_rect_embedding1\n",
    "        ],-1))  # notice  <-- this operation should be sum, but we use mean which cause a extra divide\n",
    "    grid_allrect_embedding1 += delta_grid_rect_embedding1\n",
    "    #grid_rect_embedding1      = grid_rect_embedding1[:,model1.M2G_LaLotudePos2grid] #(B,64,128,embed_dim)\n",
    "    #out1 = model1.projection(grid_rect_embedding1).permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc8ece1f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     layer = model1.layer_grid2mesh.MLP_G2M_E2M\n",
    "#     weight= layer.linear.weight.permute(1,0)\n",
    "#     normer= layer.norm\n",
    "#     activator = layer.activator\n",
    "#     #STE2E_E2E,STE2E_S2E,STE2E_T2E = torch.split(weight,512)\n",
    "# #     edge_contribution1 = \n",
    "# #     node_agg = (edge_contribution+grid_rect_embedding1[:,model1.layer_grid2mesh.G2M_edge_id2pair_tensor[:,0]] @STE2E_S2E +\n",
    "# #                 mesh_node_embedding1[:,model1.layer_grid2mesh.G2M_edge_id2pair_tensor[:,1]] @STE2E_T2E)\n",
    "# #     delta_grid_mesh_bond_embedding0 = normer(activator(node_agg))\n",
    "#     ET2T_T2T, ET2T_E2T = torch.split(weight,512)\n",
    "#     edge_contribution1 = torch.mean(delta_grid_mesh_bond_embedding1[:,model1.layer_grid2mesh.G2M_edge_id_of_node_tensor],-2)\n",
    "#     edge_agg = ( mesh_node_embedding1@ET2T_T2T + edge_contribution1 @ET2T_E2T)\n",
    "#     delta_mesh_node_embedding0= normer(activator(edge_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7adb21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=model2.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3b324575",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(model2.parameters()).device\n",
    "model2.g = model2.g.to(device)\n",
    "# (B,P,W,H) -> (B,W*H,P)\n",
    "\n",
    "G2Mweightorder= g.edge_ids(model1.layer_grid2mesh.G2M_edge_id2pair_tensor[:,0],model1.layer_grid2mesh.G2M_edge_id2pair_tensor[:,1],etype='G2M')\n",
    "\n",
    "grid_mesh_bond_embedding = torch.zeros_like(model2.grid_mesh_bond_embedding)\n",
    "grid_mesh_bond_embedding[G2Mweightorder] = model1.grid_mesh_bond_embedding.data.unsqueeze(1)\n",
    "\n",
    "M2Mweightorder1= g.edge_ids(model1.layer_mesh2mesh[0].M2M_edgeid2pair[:,0],model1.layer_mesh2mesh[0].M2M_edgeid2pair[:,1],etype='M2M')\n",
    "M2Mweightorder2= g.edge_ids(model1.layer_mesh2mesh[0].M2M_edgeid2pair[:,1],model1.layer_mesh2mesh[0].M2M_edgeid2pair[:,0],etype='M2M')\n",
    "\n",
    "L,B,D = model2.mesh_mesh_bond_embedding.shape\n",
    "mesh_mesh_bond_embedding = torch.zeros(2*L,B,D)\n",
    "mesh_mesh_bond_embedding[M2Mweightorder1] = model1.mesh_mesh_bond_embedding.data.unsqueeze(1)    \n",
    "mesh_mesh_bond_embedding[M2Mweightorder2] = model1.mesh_mesh_bond_embedding.data.unsqueeze(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c695e976",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    B, P , W, H =fixed_input.shape\n",
    "    feature_along_latlot     = model2.grid_rect_embedding_layer(rearrange(fixed_input,\"B P W H -> (W H) B P\"))\n",
    "    grid_rect_embedding2      = feature_along_latlot[model2.G2M_grid2LaLotudePos] # (L,B,D)\n",
    "    grid_rect_embedding2      = torch.cat([rearrange(model2.northsouthembbed.repeat(B,1,1),\"B L D -> L B D\"),\n",
    "                                            grid_rect_embedding2]) ## --> (L+2, B, D)\n",
    "\n",
    "    g.nodes['grid'].data['feat']= torch.nn.functional.pad(grid_rect_embedding2,(0,0,0,0,0,model2.unactivated_grid))\n",
    "    g.nodes['mesh'].data['feat']= model2.mesh_node_embedding\n",
    "    g.edges['G2M'].data['feat'] = grid_mesh_bond_embedding\n",
    "    g.edges['M2M'].data['feat'] = mesh_mesh_bond_embedding\n",
    "    g.edges['G2M'].data['coef'] = model2.G2M_edge_coef\n",
    "    g.edges['M2G'].data['coef'] = model2.M2G_edge_coef\n",
    "    ########################################################################################################\n",
    "    g = model2.grid2mesh(g)\n",
    "    ####    src_flag = model2.grid2mesh.src_flag \n",
    "    ####    tgt_flag = model2.grid2mesh.tgt_flag \n",
    "    ####    edgetype = model2.grid2mesh.edgetype \n",
    "    ####    edgeflag = (src_flag,edgetype,tgt_flag)\n",
    "    ####    g.nodes[src_flag].data['src']     = g.nodes[src_flag].data['feat'] @ model2.grid2mesh.STE2E_S2E\n",
    "    ####    g.nodes[tgt_flag].data['dst']     = g.nodes[tgt_flag].data['feat'] @ model2.grid2mesh.STE2E_T2E\n",
    "    ####    g.apply_edges(fn.u_add_v('src', 'dst', 'node_to_edge'),etype=edgeflag)\n",
    "    ####    agg = g.edges[edgeflag].data['node_to_edge'] + g.edges[edgeflag].data['feat'] @ model2.grid2mesh.STE2E_E2E\n",
    "    ####    g.edges[edgeflag].data['add_feat'] = model2.grid2mesh.activator1(g.edges[edgeflag].data['node_to_edge'] + g.edges[edgeflag].data['feat'] @ model2.grid2mesh.STE2E_E2E)    \n",
    "    ####    g.edges[edgeflag].data['feat']  =   g.edges[edgeflag].data['feat'] + g.edges[edgeflag].data['add_feat']\n",
    "    ####    if 'coef' in g.edges[edgeflag].data:g.edges[edgeflag].data['add_feat']*= g.edges[edgeflag].data['coef']\n",
    "    ####    reduce_fun = fn.sum\n",
    "    ####    g.update_all(fn.copy_e('add_feat','add_feat'),reduce_fun('add_feat', 'add_feat'),etype=edgeflag)\n",
    "    ####    g.nodes[tgt_flag].data['add_feat'] = model2.grid2mesh.activator2(g.nodes[tgt_flag].data['add_feat'] @ model2.grid2mesh.ET2T_E2T +\n",
    "    ####                                                                     g.nodes[tgt_flag].data['feat'] @ model2.grid2mesh.ET2T_T2T)\n",
    "    ####    g.nodes[tgt_flag].data['feat']  = g.nodes[tgt_flag].data['feat'] + g.nodes[tgt_flag].data['add_feat']\n",
    "    ####    if model2.grid2mesh.S2S is not None:\n",
    "    ####        g.nodes[src_flag].data['feat'] = g.nodes[src_flag].data['feat']+ model2.grid2mesh.activator3(g.nodes[src_flag].data['feat']@ model2.grid2mesh.S2S)\n",
    "    ########################################################################################################\n",
    "    #g = model2.mesh2mesh[0](g)\n",
    "    src_flag = model2.mesh2mesh[0].src_flag \n",
    "    tgt_flag = model2.mesh2mesh[0].tgt_flag \n",
    "    edgetype = model2.mesh2mesh[0].edgetype \n",
    "    edgeflag = (src_flag,edgetype,tgt_flag)\n",
    "    g.nodes[src_flag].data['src']         = g.nodes[src_flag].data['feat'] @ model2.mesh2mesh[0].STE2E_S2E\n",
    "    g.nodes[tgt_flag].data['dst']         = g.nodes[tgt_flag].data['feat'] @ model2.mesh2mesh[0].STE2E_T2E\n",
    "    g.edges[edgeflag].data['edge_effect'] = g.edges[edgeflag].data['feat'] @ model2.mesh2mesh[0].STE2E_E2E\n",
    "    g.apply_edges(fn.u_add_v('src', 'dst', 'node_effect'),fn.u_add_e('dst', 'add_feat'),etype=edgeflag)\n",
    "    g.edges[edgeflag].data['add_feat'] = model2.mesh2mesh[0].activator1(g.edges[edgeflag].data['node_to_edge'] + \n",
    "                                                                        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d0b57b82",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "    g.edges[edgeflag].data['add_feat'][M2Mweightorder2] = g.edges[edgeflag].data['add_feat'][M2Mweightorder1]\n",
    "\n",
    "    g.edges[edgeflag].data['feat']    =   g.edges[edgeflag].data['feat'] + g.edges[edgeflag].data['add_feat']\n",
    "    if 'coef' in g.edges[edgeflag].data:g.edges[edgeflag].data['add_feat']*= g.edges[edgeflag].data['coef']\n",
    "    reduce_fun = fn.sum if 'coef' in g.edges[edgeflag].data else fn.mean\n",
    "    g.update_all(fn.copy_e('add_feat','add_feat'),reduce_fun('add_feat', 'add_feat'),etype=edgeflag)\n",
    "    g.nodes[tgt_flag].data['add_feat'] = model2.mesh2mesh[0].activator2(g.nodes[tgt_flag].data['add_feat'] @ model2.mesh2mesh[0].ET2T_E2T + \n",
    "                                                            g.nodes[tgt_flag].data['feat'] @ model2.mesh2mesh[0].ET2T_T2T)\n",
    "    g.nodes[tgt_flag].data['feat']  = g.nodes[tgt_flag].data['feat'] + g.nodes[tgt_flag].data['add_feat']\n",
    "    if model2.mesh2mesh[0].S2S is not None:g.nodes[src_flag].data['feat'] = g.nodes[src_flag].data['feat']+ model2.mesh2mesh[0].activator3(g.nodes[src_flag].data['feat']@ model2.mesh2mesh[0].S2S)\n",
    "    ######################################################################################################\n",
    "    if model2.mesh_grid_bond_template is None or model2.mesh_grid_bond_template.shape[1]!=B:\n",
    "        model2.mesh_grid_bond_template = torch.zeros(g.num_edges('M2G'),B,model2.embed_dim).to(g.edges['G2M'].data['feat'].device)\n",
    "    model2.mesh_grid_bond_template[model2.reorder_edge_id_in_M2G] = g.edges['G2M'].data['feat'][model2.reorder_edge_id_of_M2G_from_G2M]\n",
    "    g.edges['M2G'].data['feat'] = model2.mesh_grid_bond_template\n",
    "    g.nodes['grid'].data['feat'][1928:] = 0\n",
    "#     #######################################################################################################\n",
    "#     #g  = model2.mesh2grid(g)\n",
    "    src_flag = model2.mesh2grid.src_flag \n",
    "    tgt_flag = model2.mesh2grid.tgt_flag \n",
    "    edgetype = model2.mesh2grid.edgetype \n",
    "    edgeflag = (src_flag,edgetype,tgt_flag)\n",
    "    g.nodes[src_flag].data['src']     = g.nodes[src_flag].data['feat'] @ model2.mesh2grid.STE2E_S2E\n",
    "    g.nodes[tgt_flag].data['dst']     = g.nodes[tgt_flag].data['feat'] @ model2.mesh2grid.STE2E_T2E\n",
    "    g.apply_edges(fn.u_add_v('src', 'dst', 'node_to_edge'),etype=edgeflag)\n",
    "    g.edges[edgeflag].data['add_feat'] = (g.edges[edgeflag].data['node_to_edge'] + \n",
    "                                          g.edges[edgeflag].data['feat'] @ model2.mesh2grid.STE2E_E2E)\n",
    "    #g.edges[edgeflag].data['feat']    =   g.edges[edgeflag].data['feat'] + g.edges[edgeflag].data['add_feat']\n",
    "    if 'coef' in g.edges[edgeflag].data:g.edges[edgeflag].data['add_feat']*= g.edges[edgeflag].data['coef']\n",
    "    reduce_fun = fn.sum if 'coef' in g.edges[edgeflag].data else fn.mean\n",
    "    g.update_all(fn.copy_e('add_feat','add_feat'),reduce_fun('add_feat', 'add_feat'),etype=edgeflag)\n",
    "    g.nodes[tgt_flag].data['add_feat'] = model2.mesh2grid.activator2(g.nodes[tgt_flag].data['add_feat'] @ model2.mesh2grid.ET2T_E2T + \n",
    "                                                           g.nodes[tgt_flag].data['feat'] @ model2.mesh2grid.ET2T_T2T)\n",
    "    g.nodes[tgt_flag].data['feat']  = g.nodes[tgt_flag].data['feat'] + g.nodes[tgt_flag].data['add_feat']\n",
    "    #if model2.mesh2grid.S2S is not None:g.nodes[src_flag].data['feat'] = g.nodes[src_flag].data['feat']+ model2.mesh2grid.activator3(g.nodes[src_flag].data['feat']@ model2.mesh2grid.S2S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b538d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0007)\n"
     ]
    }
   ],
   "source": [
    "print(torch.dist(delta_grid_rect_embedding1,g.nodes[tgt_flag].data['add_feat'].permute(1,0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "73084f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2G_edge_id2pair_tensor_full   = np.load(\"GraphCastStructure/mesh5/32x64/M2G_edge_id2pair_tensor.npy\")    \n",
    "M2G_edge_id2pair_tensor_sub    = np.load(\"GraphCastStructure/mesh5/32x64/M2G_id2edge_max_rank.npy\") \n",
    "M2G_edge_full_edge2id = {}\n",
    "for u,v in M2G_edge_id2pair_tensor_full:\n",
    "    M2G_edge_full_edge2id[u,v] = len(M2G_edge_full_edge2id)\n",
    "subedgeidinfull = [M2G_edge_full_edge2id[u,v] for u,v in M2G_edge_id2pair_tensor_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b55e6165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1928) must match the size of tensor b (2050) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[287], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1928\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrid_rect_embedding1\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mdist(g\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m),mesh_node_embedding1))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mdist(g\u001b[38;5;241m.\u001b[39medges[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG2M\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m),grid_mesh_bond_embedding1))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1928) must match the size of tensor b (2050) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print(torch.dist(g.nodes['grid'].data['feat'][:1928].permute(1,0,2),grid_rect_embedding1))\n",
    "print(torch.dist(g.nodes['mesh'].data['feat'].permute(1,0,2),mesh_node_embedding1))\n",
    "print(torch.dist(g.edges['G2M'].data['feat'].permute(1,0,2),grid_mesh_bond_embedding1))\n",
    "print(torch.dist(g.edges['M2M'].data['feat'][M2Mweightorder1].permute(1,0,2),mesh_mesh_bond_embedding1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f0fa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((model2.reorder_edge_id_in_M2G[1:]-model2.reorder_edge_id_in_M2G[:1])>0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a8e640f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_effect = torch.sum(delta_mesh_grid_bond_embedding1[:,model1.layer_mesh2grid.M2G_edge_id_of_grid_tensor],-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "170c181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickout = set(model1.M2G_LaLotudePos2grid.flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a53eba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = g.nodes[tgt_flag].data['add_feat'] - node_effect.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "df4c1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad  =set(np.where(np.round(np.linalg.norm(delta.numpy(),axis=(-1,-2)),3)>0.001)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8565e290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b9bed460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pickout&bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2beefcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-11.0468,  -9.5443,   2.4838,  ..., -16.1395, -51.7451,  -7.2725],\n",
       "        [  5.5867, -13.0053, -11.9248,  ...,  -9.9626, -19.4576,  -7.5640]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_mesh_grid_bond_embedding1[:,picked_index].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "04b24731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0046)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(g.edges[edgeflag].data['add_feat'][model2.reorder_edge_id_in_M2G].permute(1,0,2),\n",
    "           delta_mesh_grid_bond_embedding1[:,model2.reorder_edge_id_of_M2G_from_G2M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "33765a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3928.8872)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(g.nodes[tgt_flag].data['add_feat'].permute(1,0,2),node_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f08180cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0019)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(g.edges[edgeflag].data['add_feat'][model2.reorder_edge_id_in_M2G].permute(1,0,2),\n",
    "           delta_mesh_grid_bond_embedding1[:,model2.reorder_edge_id_of_M2G_from_G2M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "678c5eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3583.1536)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(g.edges['M2M'].data['node_to_edge'][M2Mweightorder1],\n",
    "           g.edges['M2M'].data['node_to_edge'][M2Mweightorder2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99d24651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0012)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(g.edges[edgeflag].data['add_feat'][M2Mweightorder1].permute(1,0,2),delta_mesh_mesh_bond_embedding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2c6b92df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0729e-06)\n",
      "tensor(0.0007)\n",
      "tensor(0.0014)\n",
      "tensor(0.0012)\n"
     ]
    }
   ],
   "source": [
    "print(torch.dist(g.nodes['grid'].data['feat'][:1928].permute(1,0,2),grid_rect_embedding1))\n",
    "print(torch.dist(g.nodes['mesh'].data['feat'].permute(1,0,2),mesh_node_embedding1))\n",
    "print(torch.dist(g.edges['G2M'].data['feat'].permute(1,0,2),grid_mesh_bond_embedding1))\n",
    "print(torch.dist(g.edges['M2M'].data['feat'][M2Mweightorder1].permute(1,0,2),mesh_mesh_bond_embedding1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b558eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1806e-06)\n",
      "tensor(223.1196)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.dist(g.nodes['mesh'].data['feat'].permute(1,0,2),mesh_node_embedding1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
